So today I thought we'd talk about generative adversarial networks because they're really cool and they've They can do a lot of really cool things people have used them for all kinds of things Things like you know, you draw a sketch of a shoe and it will render you an actual picture of a shoe or a handbag They're fairly low resolution right now, but it's very impressive the way that they can produce real quite good-looking images You Could make a neural network that's a classifier Right, you give it lots and lots of pictures of cats and lots and lots of pictures of dogs and you say you know you present it with a picture of a cat and It says it outputs a number. Let's say between zero and one And zero represents cats and one represents dogs And so you give it a cat and it puts out one and you say no That's not right should be zero and you keep training it until eventually it can tell the difference, right? So somewhere inside that Network It's it must have formed some model of what cats are and what dogs are at least as far as images of images of them are concerned But That model really you can only really use it to classify things. You can't say okay. Draw me a new cat picture Draw me a cat picture. I haven't seen before It doesn't know how to do that. So quite often you want a model that can generate new samples you have so you give it a bunch of samples from a particular distribution and you want it to Give you more samples, which are also from that same distribution. So it has to learn the underlying Structure of what you've given it and that's kind of tricky actually There's a lot of Well, there's a lot of challenges involved in that well to be honest I think as a human you can find that tricky, you know If I know what a cat looks like, but I'm being not the greatest artist in the world I'm not sure that I could draw you a decent cat So, you know that this is this is not confined to just computing is it this yeah, that's true. That's really true but if you take And Let's do like a really simple example of a generative model say you you give your network one thing It looks like this and then you give it another one You're like these your training samples looks like this and you give it another one that looks like this and then What are those dots in this instance? Instances of something on two dimensions. Yeah, I mean right now it's literally just data We're just it doesn't matter what it is. Just some yeah, these are these are data points And so these are the things you're giving it and then it will learn You can train it. It will learn a model and the model it might learn is something like this, right? It's figured out that these dots all lie along a path and if its model was always to draw a line Then it could learn by adjusting the parameters of that line It would move the line around until it found a line. That was a good fit and generally gave you a good prediction But then if you were to ask this model Okay now make me a new one unless you did something clever what you get is probably this because that is on average The closest to any of these because any of these dots you don't know if they're going to be above or below or you know To the left or the right. There's no pattern there. It's kind of random So the best place you can go that will minimize your error is to go just right on the line every time But anybody looking at this will say well, that's fake that's not a plausible example of something from this distribution, even though for a lot of the Like error functions that people use when training networks. This would perform best. So it's this interesting situation where? There's not just one right answer you know generally speaking the way that neural networks work is you're training them towards a specific you have a label or you have a you have a an output a target output and You get penalty the further away you are from that output whereas in in an application like this There's effective. There's basically an infinite number of perfectly valid Outputs here, but so so to generate this what you'd actually need is to take this model and then apply some randomness You say they're all within you know They they occur randomly and they're normally distributed around this line with this standard deviation or whatever but a lot of models would have a hard time actually picking one of all of the possibilities and they would have this tendency to kind of smooth things out and go for the average whereas We actually just want just pick me one. It doesn't matter. So that's part of the problem of generating adversarial training is is a is a way of training Not just networks actually way of training machine learning systems Which involves focusing on the system's weaknesses So if you if you are learning, let's say let's say you're teaching your Network to recognize Handwritten digits the normal way you would do that. You have your big training sample of labeled samples you've got an array of pixels that looks like a three and then it's labeled with three and so on and the normal way that You would train a network with this is you would just Present all of them pretty much at random You'd present as many ones as twos as threes and just keep throwing examples at it. What's this, you know? Yes, you got that, right? No, you got that wrong. It should really be this And keep doing that and the system will eventually learn but If you were actually teaching a person to recognize the numbers if you were teaching a child you wouldn't do that like if you if you'd been teaching them for a while presenting them and You know getting the response and correcting them and so on and you noticed that they can do You know with with two three four five six eight and nine They're getting like 70 80 percent, you know accuracy recognition rate, but one and seven It's like 50-50 because they keep anytime they get a one or a seven They just guess because they can't tell the difference between them If you notice that you wouldn't keep training those other numbers, right? You would stop and say well, you know what? We're just gonna focus on one and seven because this is an issue for you I'm gonna keep showing you ones and sevens and correcting you until The error rate on ones and sevens comes up comes down to the error rate that you're getting on your other numbers You're focusing the training on the area where the student is failing and there's kind of a balance there when you're teaching humans Because if you keep relentlessly focusing on their weaknesses and making them do stuff, they can't do all the time They will just become super discouraged and give up But neural networks don't have feelings yet, so that's really not an issue you can just continually hammer on the weak points Find whatever they're having trouble with and focus on that and so that behavior and I think some people have had teachers where it feels Like this it feels like an adversary, right? It feels like they want you to fail So in fact You can make them an actual adversary if you have some process Which is genuinely doing its best to make the network give as high an error as possible that will produce this effect where if it spots any weakness it will focus on that and Thereby force the learner to learn to not have that weakness anymore Like one form of adversarial training people sometimes do is if you have a game playing program You make it play itself a lot of times because all the time They are trying to look for weaknesses in their opponent and exploit those weaknesses. And when they do that, they're forced to then Improve or fix those weaknesses in themselves because their opponent is exploiting those weaknesses. So Every time the Every time the system finds a strategy that is extremely good against this opponent the the opponent who's also them has to Learn a way of dealing with that strategy and so on and so on So as the system gets better it forces itself to get better Because it's continuously having to learn how to play a better and better opponent It's quite it's quite elegant, you know This is where we get to generative adversarial networks. Let's say You've got a network you want to Let's say you want cat pictures, you know You want to be able to give it a bunch of pictures of cats and have it? Spit out a new picture of a cat that you've never seen before that looks exactly like a cat the way that degenerative Adversarial network works is it's this architecture where you actually have two networks. One of the networks is the discriminator. Oh, how's my spelling? Yeah, I like that The discriminator network is a classifier, right? it's a straightforward classifier you give it an image and it outputs a number between 0 and 1 and You're training that in standard supervised learning way then you have a generator and the generator is Usually a convolutional neural network, although actually both of these can be other processes But people tend to use neural networks for this and the generator You give it some random noise and that's the random that's where it gets its source of randomness So that it can give multiple answers to the same question effectively you give it some random noise and it generates an image From that noise and the idea is it's supposed to look like a cat So the way that we do this with a generative adversarial network is it's this architecture whereby you have two networks playing a game Effectively, it's a competitive game. It's adversarial between them And in fact, it's a very similar kind of game to the games We talked about in the previous the AlphaGo video, right? It's a min-max game because these two networks are fighting over one number one of them wants the number to be high one of them wants the number to be low and What that number actually is is the error rate of the discriminator? so The discriminator Wants a low error rate the generator wants a higher rate. The discriminators job is to look at an image Which could have come from the original data set? Or it could have come from the generator and its job is to say yes. This is a real image or no. This is fake and it outputs a number between 0 and 1 like 1 for its real and 0 for its fake for example and the generator gets fed as its input just some random noise and it then generates an image from that and its reward, you know, it's training is Pretty much the inverse of what the discriminator says For that image. So if it produces an image which the discriminator can immediately tell is fake it gets a negative reward You know, it's a that's it's trained not to do that if it manages to produce an image that the discriminator Can't tell is fake Then that's really good. So you train them in a in a cycle effectively you you give the discriminator a real image Get its output then you generate a fake image and give the discriminator that and Then you give it a real so the discriminator gets alternating real image fake image real image fake image Usually I mean there are things you can do where you Train them at different rates and whatever but by default does the generator get any help with this at all, or is it purely? Yes, so if you this is this is like part of what makes this especially clever actually the generator does get help because If you set up the networks, right you can use the gradient of the discriminator To train the generator So when I know you done back propagation before about how neural networks are trained it's gradient descent right and in fact, we talked about this in like 2014 if you're if you're a You're a blind person climbing a mountain or you're it's really foggy and you're climbing a mountain You can only see directly what's underneath your own feet You can still climb that mountain if you just follow the gradient you just look directly under me which way is the You know, which way is the ground sloping this is what we did the hill climb algorithm exactly Yeah, sometimes people call it hill climbing. Sometimes people call it gradient descent It's the same metaphor Upside down effectively if we're climbing up or we're climbing down you're training them by gradient descent, which means that You're not just you're not just able to say Yes, that's good. No, that's bad You're actually able to say and you should adjust yours You should adjust your weights in this direction so that you'll move down the gradient, right? So generally you're trying to move down the gradient of error for the network if you're like if you're training if you're training a thing to just recognize cats and dogs, you're just Moving it you're moving it down the gradient towards the correct label whereas in this case The generator is being moved Sort of up the gradient for the discriminators error So it can find out not just you did well you did badly But here's how to tweak your weights so that you will so that the discriminator would have been more wrong So so that you can confuse the discriminator more so you can think of this whole thing an analogy people sometimes use is like a Forger and An expert investigator person, right at the beginning, you know, let's assume there's one forger and there's one investigator and all of the art buyers of the world are idiots at the beginning the The level of the the quality of the forgeries is going to be quite low, right? The guy just go get some paint and he then he just writes, you know, Picasso on it And he can sell it for a lot of money and the investigator comes along and says, yeah, I'm not sure I died I don't think that's right. Maybe it is. I'm not sure. I haven't really figured it out and then as time goes on the investigator who's the discriminator will start to spot certain things that are different between the things that the forger produces and real paintings and then they'll start to be able To reliably spot. Oh, this is a fake, you know, this use is the wrong type of paint or whatever So it's fake and once that happens, the forger is forced to get better, right? He can't sell his fakes anymore He has to find that kind of paint so he goes and you know digs up Egyptian mummies or whatever to get the legit paint and now he can forge again and now the discriminator or the investigator is fooled and They have to find a new thing that distinguishes the real from the fakes and so on and so on in a cycle They force each other to improve and it's the same thing here So at the beginning the generator is making just random Noise basically because it's it's it's getting random noise in and it's doing something to it Who knows what and it spits out an image and the discriminator goes that looks nothing like a cat, you know and then eventually because the discriminator is also not very smart at the beginning, right and And they just they both get better and better The generator gets better at producing cat looking things and the discriminator gets better and better at identifying them until Eventually in principle if you run this for long enough theoretically you end up with a situation where? The generator is creating images that look exactly indistinguishable from Images from the real data set and the discriminator if it's given a real image or a fake image always outputs 0.5 5050 I Don't know could be either these things are literally indistinguishable Then you pretty much can throw away the discriminator and you've got a generator which you give random noise to and it outputs Brand new indistinguishable images of cats. There's another cool thing about this Which is Every every time we ask the generator to generate a new image. We're giving it some random data, right? We give it just this vector of random numbers Which you can think of as being a randomly selected point in a space because you know if you give it If you give it ten random numbers, you know between zero and one or whatever. That is effectively a point in a ten-dimensional space And the thing that's cool is that As the generator learns it's forced to You it's it the generator is effectively making a mapping from that space into cat pictures This is called a latent space by the way, generally Any two nearby points in that latent space will when you put them through the generator produce? Similar cat pictures, you know similar pictures in general Which means sort of as you move Around if you sort of take that point and smoothly move it around the latent space you get a smoothly varying picture of a cat and so the directions you can move in the space actually end up corresponding to Something that we as humans might consider meaningful about cats So there's one, you know, there's one direction and it's not necessarily One dimension of the space or whatever, but And it's not necessarily linear or a straight line or anything But there will be a direction in that space which corresponds to how big the cat is in the frame For example, or another dimension will be there the color of the cat or whatever so That's really cool because it means that by Intuitively you think Intuitively you think The fact that the generator can reliably produce a very large number of images of cats means it must have some like understanding understanding of What cats are right or at least what images of cats are and it's nice to see that it has actually Structured its latent space in this way that it's by looking at a huge number of pictures of cats. It has actually extracted Some of the structure of cat pictures in general in a way which is Meaningful when you look at it, so and that means you can do some really cool things So one example was they trained a net one of these systems on a really large Database of just face photographs and so it could generate Arbitrarily large number of well as a largest the input space Number of different faces and so they found that actually by doing basic Arithmetic like just adding and subtracting vectors on the latent space Would actually produce meaningful changes in the image if you took a bunch of latent vectors which when you give them to the generator produce pictures of men and a bunch of them that produce pictures of women and average those you get a point in your latent space which Corresponds to a picture of a man or a picture of a woman which is not one of your input points but it's sort of representative and Then you could do the same thing and say oh, I only want Give me the average point of all of the things that correspond to pictures of men wearing sunglasses Right and then if you take your sunglass vector Your your men wearing sunglasses vector Subtract the man vector and add the woman vector You get a point in your space and if you run that through the generator you get a woman wearing sunglasses right so doing doing basic vector arithmetic in your input space actually is Meaningful in terms of images in a way that humans would recognize which means that There's there's a sense in which the generator really does Have an understanding of wearing sunglasses or not or being a man or being a woman Which is kind of an impressive result But it's not a truly random thing because if I know the key and I've got I can still want to generate the same Yeah, I'm so I mean that about unfortunately is the problem with cryptography is that we couldn't ever use truly random because we wouldn't be Able to decrypt it again. We have our message bits which are you know, not one one not something different And we X all these together one bit at a time and that's how we encrypt 