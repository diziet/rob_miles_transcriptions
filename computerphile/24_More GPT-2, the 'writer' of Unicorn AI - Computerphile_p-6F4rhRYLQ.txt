We're six paragraphs in and it knows about this point. I've covered the first sentence of this initial paragraph now it's time to talk about this second sentence of the lead even more surprising to the researchers of the fact that they spoke English and It completely ignored the speaking English part until it got to the part of the news article where that comes in and now it's talking About it, which is the kind of thing that these kinds of systems would have real trouble doing I've known journalists who can't write that well If that ties into Something that I think is kind of fundamental to the way that people think about AI Like we used to think that you had to be really clever to be good at chess And if you could play chess, then you were a real intelligence You had to be and then we realized that like playing chess to a superhuman level doesn't require something that we would call Intelligence and it's slightly unsettling to find that like writing coherent and plausible news prose Apparently also doesn't require general intelligence Like if you just learn the statistical relationships between words But do that really really well that seems to be enough I mean obviously any journalist would would say that the truth is kind of important in this as well But yeah to make it sound plausible. You're absolutely right, right? yeah, so there's there's definitely questions about like directing this towards producing a specific article that is correct, but Just the generating of the of the prose itself apparently requires less like Philosophical sophistication then we thought Then many thought anyway, I think ten years ago people would have a really hard time believing that Something that's just learning from data and learning these relative probabilities could produce something this coherent You would expect it to have all sorts of conditions and formula and Encoded you would look at this and say oh this must have like a database of names and countries and locations and Cities and everything else because it's using that information But it turns out all of that is already represented in the data set because we're talking about all these things Here's a recipe for some kind of peppermint chocolate cake and it's got a bunch of different completions So it can just spit these out arbitrarily So, you know those recipe blogs where like you Google the recipe for something and you go to the blog and there's like seven Paragraphs of like my mother used to make this for me back in our home in Indiana I always remember sitting out on the porch with my dog He used to you know the important thing is I had an onion on my belt, which was the style at the time and and It's doing that. It's like talking about different Backstory. Yeah, just backstory and only if anyone's tried to make any of these recipes Yeah, it's dangerous this one So this is this is a recipe for meringue cookies One and three-quarter cups butter softened a cup of sugar an egg yolk three T of heavy creases just capital T What unit is that three tons heavy cream? That's usually a lowercase T. I don't know what it that is three tons of heavy cream. Let's say Three and a half to four cups of flour a pinch of salt peppermint Jojo topping which like I have no idea what that is But peppermint Jojo's is mentioned in the prompt So one and a quarter cups powdered sugar a cup of chopped pecans a half a cup finely chopped mint leaves half cup chopped Fresh mint about a half sheet so it's like it doesn't quite make sense, but it's right on the edge of making sense like we have half a cup of chopped mint leaves and Then also half a cup of chopped fresh mint are these potentially cherry-picked out of a huge number of horrendous Right. Yes, so this is these ones specifically are not so the unicorn one and this is something that I like and it's standard practice But I like this the unicorn one. It says they specifically said right now We're gonna make a sample for the paper They made ten of them and they picked the one they liked which was this one but for the recipes here These are not cherry-picked at all. That's why they're showing six. They just gone This is the first six that we generated and here they are and they're so that gives you a like a better idea of the General quality of what it's putting out. They're all fairly sensible I like look at this one run This one comes in and says I do not substitute it with something else blah blah and then like this I don't know if that is like here's an image or yeah, please like this on Facebook and then it goes on I found this really cute card with cute little kittens on and then it's the samples cut off So it's just like next post in the blog or you know, this is why GPT 2 is so cool to me Let's see. The first thing they tested on is a children's book test where this is. I think it's like a closed thing Where you just have it have a data set with some children's books and then you like remove one word and Then the system has to predict Which of the words is the correct? Like you give it you give it ten words that it might be or something like that and it has to pick what word fits In this space, so that's a standard kind of language model type task. The one thing that they did have to do is they had to run analysis to check about overlap and it turns out that one of the Children's books is the jungle book by Rudyard Kipling Which was actually in in its entirety was in the data set that they trained the thing on so it just knew that one So then they threw that out because obviously that's not fair if you've already seen the entire book before and Its performance on that was was good by the time they guts up to the to the very large-scale models. It's scoring. What is that 80? 89 percent where humans tend to get like 90 92 93 percent it's like nearly a human level for guessing one missing word from a sentence in a children's book pretty good Lambada is designed to test long-range dependencies Which is what I've been talking about a lot The task is to predict the final word of sentences which require at least 50 tokens of context for a human to successfully predict It's like 50 words is a pretty long sentence and So this kind of long-term dependency thing is a standard way of testing language models and It ends up with an accuracy of 63 percent Which is an improvement over state-of-the-art by 4 percent. So it's state-of-the-art on lambada Without it's being specifically trained on that just running in general the winograd schema. I don't know if it's quite, you know, Vinny Vinograd. Who knows? Maybe it's somebody's name Whatever. This is about resolving ambiguities, which is really especially important in Translation tasks and things like that It's very easy for sentences to be ambiguous in a way that makes translating them Very difficult or even impossible and I have like I have an example of this check this out. So consider a sentence like The chicken didn't cross the road because it was too blank. Okay, and then we can consider different versions of this sentence suppose that this is Wide chicken didn't cross the road because it was too wide, right? That's like one possible completion for this or you might say The chicken didn't cross the road because it was too scared another perfectly sensible sentence, then the question is It in one of these it is referring to the chicken and in one of them It is referring to the road kind of throw a third in sure stormy Stormy. Oh, yeah. All right. That's a good one. So stormy means it is actually neither of the things in the sentence the other one that's fun is something like busy Right. Is it a busy road or did the chicken just have better things to do than crossing the road? We don't know. I mean like I Would say probably the road but this could be a children's book, right? We are running this thing on children's books. The rabbit the rabbit was too busy. It was late for an important date Why can't the chicken be busy? So the point is suppose we're trying to translate this into a language that genders everything as many languages do and Maybe chicken is like a is a masculine noun and road is a feminine noun and it has to know What it's about right? Is this like is this ill or L or whatever? So the idea of this benchmark is Measuring how well it can resolve ambiguities because if this says wide if you're trying to do Translation the old old-fashioned way where you're like parsing Trees and looking things up in dictionaries and stuff like that This kind of sentence is a hell nightmare because you can't you don't know I mean, you just don't know the information is not really present in the Text it's not present grammatically. It's present in your understanding of the world and chickens and roads, right? So translating this if this is that was too wide and you translate it Into something which is the equivalent of the English sentence the chicken didn't cross the road because the chicken was too wide You've screwed up right? That's a bad translation, but at the same time Like there's nothing in the sentence that tells you that it shouldn't be right So what you need to do is the same is the thing that we've already seen that GPT 2 is super good at Which is pulling in knowledge of the world like knowing that the University of La Paz is going to be near the Andes or in The Andes right that kind of thing. It's going to know That roads being wide is a thing much more than chickens being wide is a thing and so on And that like roads don't get scared if it's scared friends are fearless So again on this kind of thing, it does very well It beats the state of the art by a lot you can see on this graph here So so the way that this graph is laid out, by the way, this is the same in all of them This is the size of the model. They made four different Sizes of model and these are like the same sizes that previous Language models were so they were like make sense to compare them the previous to the small ones They do worse than the state-of-the-art, but then the 762 million parameter and the 1.5 billion parameter Significantly pass state-of-the-art they're getting like 70% So the state-of-the-art is the straight line across right? Yes And the thing that is also kind of fun about some of these graphs is so some of them there's seven six two million and the 1.5 billion end up doing about as well as each other, which means you've like hit the limit of I get maybe your data set or your whatever whereas in this one, there's still growth which means an even bigger model We might expect to do even better. Maybe reading comprehension. This is another thing You have some text you then you have to answer questions about that text, right? the thing that's fun is How do you do this? Without modifying your model. That's just a generative model. So this is where we start getting into These that's you by the time it's ready. It's modified itself based upon what you've given it to me. Is that what you mean? No, what I mean is the Way that GPT to works is you give it the sequence of tokens and it gives you a probability distribution for the next token and So they're like type signature of that Is is totally fine with if you're trying to fill in a missing word or I guess I don't know how they did it for these for this test But You have to take you have to take the challenge that you're given and try and express it in terms of This like predict the next word type setup because otherwise you're sort of cheating, right? The whole thing is they're trying to go at this and not not modify the system at all. So for reading comprehension the way they do it is they give the thing that's to be comprehended and Then they give Q colon a question a colon the correct answer to that question new line Q colon a new question they give like three or four example questions and then Q colon the question they actually want answered a colon let it generate so they sort of prime it I think we have some examples of this. So this is how they did the question-answer thing. They gave these two paragraphs about the Olympic Games the torch relay moving the Olympic torch I don't have some news story and then a bunch of questions right question What was the theme that's a one world one dream and so on and so on and then at the end question? And did they climb any mountains and then a colon? Generate me the next word. So they've used This the the input text to kind of prime the model Now we're doing question-answer pairs. This is how it works, right? And The interesting thing about this is it actually ends up giving kind of a better answer than that human generated answers So the question did they climb any mountains the responses they got from humans were unknown. Yes. Yes, and yes because they did climb mountains but GPT to Their answer is Everest so GPT twos answer is actually kind of better than the humans. The humans just said yes, they did and The machine learning system has named the mountain that they climbed so I don't know if that's If that counts is not quite understanding the question or if that counts is actually providing a high-quality answer It's up for debate because it has this ability with attention to do the long-range It has to look back past all of the previous questions To the actual paragraph and find the relevant information and it can do it and it performs reasonably well at that But the thing I love about that is that they have to like come up with tricks To get it to actually do the task that they're trying to get it to do. So the summarization one is brilliant I love the way they did this with the summarization See if you can guess how they did this right you want to get a summary of a piece of text How do you how do you get that given a huge data set of reddit? content what you do is you write the whole long piece of text and then you put like a new line and then you put TLDR too long didn't read in this data set there will be thousands and thousands of examples of long pieces of text followed by a short summary of that text and In the middle is this string TLDR? I would love to have been in the room when they thought of that So yeah, it's really Really cool really powerful technology. I like it a lot So an executable binary the net effect of slotting that T diagram against here slightly downwards is to show you That the C you've written gets converted into binary and the net output from this Process it produces out a program that you probably store in the 