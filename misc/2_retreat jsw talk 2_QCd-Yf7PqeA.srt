1
00:00:00,000 --> 00:00:02,960
So, where we left off, we had talked about

2
00:00:02,960 --> 00:00:04,560
underdetermined optimization.

3
00:00:05,440 --> 00:00:07,400
We had talked about a couple of ways

4
00:00:07,400 --> 00:00:10,040
in which the structure of optimization problems

5
00:00:10,040 --> 00:00:12,840
in general leads to things like compression

6
00:00:12,840 --> 00:00:15,640
and efficient use of resources and that sort of thing.

7
00:00:17,520 --> 00:00:21,320
Then we were mostly in the section on what humans want

8
00:00:21,320 --> 00:00:26,240
and this notion of selection theorems.

9
00:00:26,360 --> 00:00:31,360
So, we believe that the principles of behaving

10
00:00:33,000 --> 00:00:34,600
in optimal ways in general,

11
00:00:34,600 --> 00:00:37,040
so like the sorts of things we expect to evolve,

12
00:00:38,480 --> 00:00:40,280
imply certain structure.

13
00:00:40,280 --> 00:00:41,760
The big one we talked about yesterday

14
00:00:41,760 --> 00:00:46,580
was coherence arguments, implying Pareto optimality

15
00:00:46,580 --> 00:00:50,580
and this idea of Bayesian utility maximizing sub-agents.

16
00:00:50,980 --> 00:00:51,820
All right.

17
00:00:54,540 --> 00:00:57,980
That is the main piece which we currently know

18
00:00:57,980 --> 00:01:01,260
how to derive from something like a selection theorem.

19
00:01:01,260 --> 00:01:04,380
The next couple of pieces are going to be things

20
00:01:04,380 --> 00:01:08,340
where we don't yet have the full mathematical arguments,

21
00:01:08,340 --> 00:01:10,020
but we can make a pretty good guess

22
00:01:10,020 --> 00:01:12,020
as to what the shape of them is gonna be

23
00:01:12,020 --> 00:01:13,940
by looking at the things we do have,

24
00:01:13,940 --> 00:01:16,940
like coherence or information theoretic arguments

25
00:01:17,980 --> 00:01:19,840
and then cross-referencing that

26
00:01:19,840 --> 00:01:23,200
with how humans actually think in practice.

27
00:01:23,200 --> 00:01:24,040
Make sense?

28
00:01:25,280 --> 00:01:29,920
So, the two big pieces here are going to be world models

29
00:01:29,920 --> 00:01:33,120
and then latent variables.

30
00:01:34,080 --> 00:01:38,280
So, world models.

31
00:01:39,520 --> 00:01:42,260
In general, markers, where are they?

32
00:01:43,180 --> 00:01:44,020
There.

33
00:01:46,980 --> 00:01:51,180
In general, we're gonna be assuming from here on out

34
00:01:51,180 --> 00:01:52,740
a Bayesian viewpoint.

35
00:01:54,420 --> 00:01:56,980
We already saw, so the coherence arguments

36
00:01:56,980 --> 00:01:59,940
gave us one reason to expect that,

37
00:01:59,940 --> 00:02:01,540
like we expect Bayesian sub-agents

38
00:02:01,540 --> 00:02:03,020
from the coherence arguments,

39
00:02:03,020 --> 00:02:05,840
but they're somewhat underdetermined

40
00:02:05,840 --> 00:02:08,340
from the coherence arguments alone.

41
00:02:08,340 --> 00:02:10,620
Generally, coherence only really tells us

42
00:02:10,620 --> 00:02:13,940
about probabilities over actual observables

43
00:02:13,940 --> 00:02:16,260
or actual worlds.

44
00:02:16,260 --> 00:02:17,660
It doesn't really tell us much

45
00:02:17,660 --> 00:02:20,420
about the internal structure of models.

46
00:02:20,420 --> 00:02:23,780
We can get more of that from information theory,

47
00:02:23,780 --> 00:02:25,800
particular in order to compress efficiently,

48
00:02:25,800 --> 00:02:29,100
you have to be doing something Bayesian-ish,

49
00:02:29,100 --> 00:02:32,740
but we're not actually going to go through the math on that.

50
00:02:32,740 --> 00:02:35,060
Mainly because the math on that,

51
00:02:35,060 --> 00:02:36,580
I don't know of anyone who spelled it out

52
00:02:36,580 --> 00:02:38,260
particularly well yet.

53
00:02:38,260 --> 00:02:40,500
Although it is certainly something

54
00:02:41,340 --> 00:02:42,240
that should work in principle.

55
00:02:44,860 --> 00:02:47,340
The other big thing here is gonna be causality.

56
00:02:48,220 --> 00:02:51,260
So in general, we live in a world

57
00:02:51,260 --> 00:02:53,600
where cause and effect are things.

58
00:02:54,740 --> 00:02:56,780
And this has a big influence

59
00:02:56,780 --> 00:02:58,980
on what sort of world models we use in practice,

60
00:02:58,980 --> 00:03:01,480
what sort of world models work well in practice.

61
00:03:01,480 --> 00:03:06,480
So to start with, gonna just give a little bit of a primer

62
00:03:07,400 --> 00:03:10,540
on causal models, keep that pretty short.

63
00:03:10,540 --> 00:03:14,360
And then we'll talk about how to use causal models

64
00:03:14,360 --> 00:03:16,360
to model worlds that are bigger than us.

65
00:03:18,560 --> 00:03:20,440
Because like our brains themselves

66
00:03:20,440 --> 00:03:21,400
are embedded in the world.

67
00:03:21,400 --> 00:03:23,760
So necessarily we need to be modeling worlds

68
00:03:23,760 --> 00:03:25,520
that are bigger than our brains.

69
00:03:28,120 --> 00:03:33,120
So first things first, standard causal model.

70
00:03:33,280 --> 00:03:35,280
This is like the example you'd find

71
00:03:35,280 --> 00:03:38,560
on page one of Perl or whatever.

72
00:03:38,560 --> 00:03:40,520
Actually, no, that's not quite the example.

73
00:03:40,520 --> 00:03:41,520
This is the example.

74
00:03:42,640 --> 00:03:44,940
These are both good causal models.

75
00:03:44,940 --> 00:03:45,780
There we go.

76
00:03:47,400 --> 00:03:48,240
Is that it?

77
00:03:48,240 --> 00:03:50,080
No, it was this one, cool.

78
00:03:50,080 --> 00:03:51,680
Two causal models, sure.

79
00:03:53,520 --> 00:03:56,720
Let's say, yeah, this is it.

80
00:03:56,720 --> 00:03:58,760
So let's say we have a season.

81
00:03:59,760 --> 00:04:04,760
Season influences how likely it is to be raining

82
00:04:05,120 --> 00:04:08,320
and how likely it is that the sprinkler runs.

83
00:04:08,320 --> 00:04:10,360
So like in the summer, I turn on the sprinkler,

84
00:04:10,360 --> 00:04:11,620
in the winter, I don't.

85
00:04:13,000 --> 00:04:16,040
And then rain will depend more on your region, but whatever.

86
00:04:16,040 --> 00:04:19,920
And then these influence whether the sidewalk is wet,

87
00:04:20,880 --> 00:04:23,780
which in turn influences whether the sidewalk is slippery.

88
00:04:24,140 --> 00:04:29,140
So causal model, five variables.

89
00:04:30,860 --> 00:04:33,340
Main things to emphasize here.

90
00:04:37,340 --> 00:04:41,340
The arrows indicate like direct cause and effect.

91
00:04:41,340 --> 00:04:44,100
We also have a notion of indirect cause and effect.

92
00:04:44,100 --> 00:04:46,540
So like the season influences the chance

93
00:04:46,540 --> 00:04:47,980
that the sidewalk is wet,

94
00:04:47,980 --> 00:04:50,940
but it only does so indirectly via other things

95
00:04:50,940 --> 00:04:53,200
in the model like sprinkler or the rain.

96
00:04:54,780 --> 00:04:58,100
Symbolically, we could show that

97
00:04:58,100 --> 00:04:59,620
in a couple of different ways.

98
00:04:59,620 --> 00:05:01,140
I'll draw it like this.

99
00:05:03,500 --> 00:05:06,260
This is a cut through the graph.

100
00:05:06,260 --> 00:05:08,900
We call it a Markov blanket in this context.

101
00:05:08,900 --> 00:05:11,900
It says that things on this side

102
00:05:11,900 --> 00:05:13,820
only interact with things on this side

103
00:05:13,820 --> 00:05:16,100
via the variables it's cutting through.

104
00:05:16,100 --> 00:05:18,100
So in this case, the variable it's cutting through

105
00:05:18,100 --> 00:05:21,940
is this outgoing edge carrying the value of rain.

106
00:05:22,020 --> 00:05:24,820
So this edge says, is it raining or not?

107
00:05:24,820 --> 00:05:27,500
And this outgoing edge carrying the value of sprinkler.

108
00:05:27,500 --> 00:05:30,760
So this says, is the sprinkler on or not?

109
00:05:31,860 --> 00:05:36,500
So the mathematical statement that corresponds to this cut

110
00:05:36,500 --> 00:05:41,500
is that season is independent of wet and slippery

111
00:05:52,780 --> 00:05:57,780
given rain and sprinkler.

112
00:06:04,820 --> 00:06:06,100
Yes, exactly.

113
00:06:08,320 --> 00:06:11,340
And this doesn't have to be like a cut

114
00:06:12,300 --> 00:06:15,620
through what we'd call a time slice like this.

115
00:06:15,620 --> 00:06:19,820
We could also have a cut that goes vertical.

116
00:06:19,820 --> 00:06:21,800
Wouldn't be very interesting in this particular graph,

117
00:06:22,660 --> 00:06:23,920
but you could have something like that.

118
00:06:23,920 --> 00:06:27,280
You can have cuts that are like circular

119
00:06:27,280 --> 00:06:29,120
around a chunk of the graph.

120
00:06:29,120 --> 00:06:30,040
However you wanna do it,

121
00:06:30,040 --> 00:06:32,680
as long as you're cutting the graph into two pieces.

122
00:06:38,560 --> 00:06:41,320
Let's see, is there anything else we need to say about that?

123
00:06:42,360 --> 00:06:47,360
So physically, the way to think about causality

124
00:06:47,640 --> 00:06:51,480
for our purposes is mostly talking about locality.

125
00:06:52,560 --> 00:06:55,720
So this is about which things directly interact

126
00:06:55,720 --> 00:06:58,420
with each other things and what the structure of that is.

127
00:06:58,420 --> 00:07:02,040
So like, if I'm interacting with this chair,

128
00:07:02,040 --> 00:07:05,040
I'm not really directly interacting with it from here.

129
00:07:05,040 --> 00:07:07,800
There's like photons propagating between us.

130
00:07:07,800 --> 00:07:10,080
If I stomp, the waves will travel

131
00:07:10,080 --> 00:07:11,760
through the floor to the chair.

132
00:07:11,760 --> 00:07:14,720
And that's like, all that stuff is mediating

133
00:07:14,720 --> 00:07:16,920
the interaction between me and the chair.

134
00:07:16,920 --> 00:07:20,400
And I could imagine a Markov blanket,

135
00:07:20,440 --> 00:07:25,280
which is sort of like a shell of space time around the chair

136
00:07:25,280 --> 00:07:26,880
and all of my interactions with it

137
00:07:26,880 --> 00:07:29,280
are mediated by that Markov blanket.

138
00:07:29,280 --> 00:07:31,360
That's exactly the sort of thing we're gonna do.

139
00:07:31,360 --> 00:07:33,560
We're gonna be imagining as we go forward.

140
00:07:40,160 --> 00:07:42,400
That was causal models 101.

141
00:07:42,400 --> 00:07:44,200
Now for causal models one of two.

142
00:07:45,200 --> 00:07:47,800
The interesting question here is gonna be,

143
00:07:47,800 --> 00:07:51,680
how do we use these sorts of models

144
00:07:51,680 --> 00:07:54,660
to represent a world which is bigger than us?

145
00:07:56,480 --> 00:07:58,880
So I'll start with an example.

146
00:08:01,720 --> 00:08:03,200
We'll Python function.

147
00:08:05,280 --> 00:08:07,560
The, let's say,

148
00:08:08,920 --> 00:08:09,760
fact.

149
00:08:13,280 --> 00:08:15,080
That's an

150
00:08:17,800 --> 00:08:18,960
n equals zero.

151
00:08:25,360 --> 00:08:26,200
One.

152
00:08:29,640 --> 00:08:30,800
Turn n times

153
00:08:34,080 --> 00:08:38,080
fact of n minus one.

154
00:08:39,240 --> 00:08:40,080
All right.

155
00:08:41,400 --> 00:08:45,680
How would we represent this Python function

156
00:08:45,680 --> 00:08:46,880
as a causal model?

157
00:08:46,880 --> 00:08:49,760
What causal model would correspond to the Python function?

158
00:08:50,880 --> 00:08:52,680
Anyone wanna take a guess?

159
00:08:55,240 --> 00:08:56,280
A chain.

160
00:08:56,280 --> 00:08:57,360
Wanna try drawing it?

161
00:09:17,240 --> 00:09:20,640
How much are you about to do with arrows?

162
00:09:20,640 --> 00:09:24,040
Can you just have like input and arrow output?

163
00:09:24,040 --> 00:09:24,880
Good question.

164
00:09:24,880 --> 00:09:27,880
As a general rule, the key thing is that the arrows

165
00:09:28,840 --> 00:09:29,680
should be local.

166
00:09:29,680 --> 00:09:31,520
So they should have small number of inputs,

167
00:09:31,520 --> 00:09:32,880
small number of outputs.

168
00:09:34,640 --> 00:09:36,960
What we're actually going to do for something like a program

169
00:09:36,960 --> 00:09:39,800
is just have them do basic operations.

170
00:09:39,800 --> 00:09:43,260
So things like comparison or multiplication.

171
00:09:44,260 --> 00:09:46,020
All right.

172
00:09:46,020 --> 00:09:48,020
We're going to unpack it more than that.

173
00:09:49,340 --> 00:09:52,820
So it's not that fact one causes the value.

174
00:09:52,820 --> 00:09:55,020
Well, it is true in some sense that fact one

175
00:09:55,020 --> 00:09:57,580
causes the value of fact two causes the value of fact three,

176
00:09:57,580 --> 00:09:59,900
but we're gonna unpack more of the operations.

177
00:10:01,180 --> 00:10:03,700
So if I'm like just following through

178
00:10:03,700 --> 00:10:05,380
what happens in this program,

179
00:10:05,380 --> 00:10:09,020
the very first thing that happens is I have a value of n,

180
00:10:09,020 --> 00:10:11,780
goes n, I compare n to zero.

181
00:10:11,780 --> 00:10:12,920
So here's n.

182
00:10:14,500 --> 00:10:16,580
I say, is n equal to zero?

183
00:10:19,140 --> 00:10:21,580
If it is, then I return one.

184
00:10:25,860 --> 00:10:27,300
Let's say that's the result.

185
00:10:28,300 --> 00:10:33,300
If not, then I return n times fact n minus one.

186
00:10:35,780 --> 00:10:40,780
So that'll be n times fact n minus one.

187
00:10:42,500 --> 00:10:43,340
Something.

188
00:10:46,300 --> 00:10:50,800
Also take n, and then that'll be a return value.

189
00:10:50,800 --> 00:10:51,860
All right.

190
00:10:51,860 --> 00:10:53,180
Now, how do I get this?

191
00:10:53,180 --> 00:10:56,500
Well, I'll be taking an n minus one.

192
00:10:57,700 --> 00:11:00,020
Okay, where's the n minus one go?

193
00:11:01,140 --> 00:11:02,780
Let's add one more node for that.

194
00:11:02,780 --> 00:11:03,600
Okay.

195
00:11:09,020 --> 00:11:12,340
And then I'm gonna have basically a copy of this block.

196
00:11:21,100 --> 00:11:23,420
So this guy is gonna go there.

197
00:11:23,420 --> 00:11:25,620
I have n minus one here.

198
00:11:25,620 --> 00:11:27,640
I'll be comparing that to zero.

199
00:11:29,980 --> 00:11:30,820
Zero.

200
00:11:31,820 --> 00:11:34,280
I'll have a return value here.

201
00:11:38,180 --> 00:11:43,180
And then n minus one times like.

202
00:11:51,340 --> 00:11:53,420
Well, sorry, that's not right.

203
00:11:53,420 --> 00:11:56,540
Here, n minus two.

204
00:11:58,220 --> 00:11:59,860
Okay, did that get everything?

205
00:12:00,940 --> 00:12:02,020
And that arrow.

206
00:12:03,100 --> 00:12:03,940
There we go.

207
00:12:07,100 --> 00:12:09,900
And then I'm gonna have another copy of the same block.

208
00:12:15,180 --> 00:12:18,540
So we're sort of unpacking the whole thing as a circuit.

209
00:12:21,020 --> 00:12:23,860
And as a circuit, what's going on is we have

210
00:12:23,860 --> 00:12:26,660
a sequence of identical blocks

211
00:12:26,660 --> 00:12:29,420
where each block sort of feeds some stuff

212
00:12:29,420 --> 00:12:32,660
into the next block and then takes answers back

213
00:12:32,660 --> 00:12:35,660
and does a little bit of computation inside of it, right?

214
00:12:36,780 --> 00:12:38,140
And if we unroll this whole thing,

215
00:12:38,140 --> 00:12:40,340
it's going to be an infinite line,

216
00:12:40,340 --> 00:12:42,100
but in practice at some point,

217
00:12:42,100 --> 00:12:43,940
n is going to be equal to zero.

218
00:12:43,940 --> 00:12:46,700
So even though the whole circuit is infinite,

219
00:12:46,700 --> 00:12:49,900
it is going to like terminate, right?

220
00:12:49,900 --> 00:12:51,320
In the sense that we don't have to calculate

221
00:12:51,320 --> 00:12:53,020
the whole thing to get the result.

222
00:12:54,740 --> 00:12:59,060
And we get effectively an infinite circuit

223
00:12:59,700 --> 00:13:00,860
with a symmetry to it.

224
00:13:00,860 --> 00:13:02,540
The symmetry here would be,

225
00:13:08,460 --> 00:13:10,580
if we look at this whole thing,

226
00:13:13,060 --> 00:13:17,260
there is an exact copy of it here.

227
00:13:19,940 --> 00:13:21,140
So that's the symmetry.

228
00:13:23,100 --> 00:13:26,500
So the idea here is, what's that?

229
00:13:29,580 --> 00:13:31,020
It's a screen, a symmetric screen

230
00:13:31,020 --> 00:13:33,540
where you can take something out of the screen

231
00:13:33,540 --> 00:13:37,540
and then what's left is exactly the same thing.

232
00:13:37,540 --> 00:13:38,500
Take something out of the stream

233
00:13:38,500 --> 00:13:40,020
and what's left is exactly the same thing.

234
00:13:40,020 --> 00:13:40,860
Yes.

235
00:13:42,420 --> 00:13:45,700
Yeah, that's a reasonable way to think about it.

236
00:13:45,700 --> 00:13:48,580
The important point here is like, in general,

237
00:13:48,580 --> 00:13:51,340
we can write programs which are doing

238
00:13:51,340 --> 00:13:54,420
some standard computation,

239
00:13:54,420 --> 00:13:56,860
same way you would in any C-like programming language,

240
00:13:56,860 --> 00:14:00,180
set variable equal to function of other variables,

241
00:14:00,180 --> 00:14:01,980
so on and so forth.

242
00:14:01,980 --> 00:14:06,980
And then for simple operations, it's just basic circuits.

243
00:14:07,540 --> 00:14:11,580
For recursion, we have this sort of symmetry thing going on.

244
00:14:11,580 --> 00:14:13,180
And then that's all you really need

245
00:14:13,180 --> 00:14:14,780
to define most functions, right?

246
00:14:15,740 --> 00:14:18,140
You can go from there all the way to Turing completeness

247
00:14:18,140 --> 00:14:21,060
if you have the right data structures in your language.

248
00:14:21,060 --> 00:14:21,900
Make sense?

249
00:14:22,900 --> 00:14:27,900
So this is the basic trick that lets us take a causal model

250
00:14:30,300 --> 00:14:32,420
or a probabilistic causal model

251
00:14:32,420 --> 00:14:37,100
and use it to represent a world much larger

252
00:14:37,100 --> 00:14:39,460
than the model itself, right?

253
00:14:39,460 --> 00:14:41,780
So you could imagine like,

254
00:14:41,780 --> 00:14:44,540
this could be literally the world

255
00:14:44,540 --> 00:14:45,700
that you're thinking about, right?

256
00:14:45,700 --> 00:14:47,020
There's this infinite world,

257
00:14:47,020 --> 00:14:50,860
which is just consists of this giant factorial circuit.

258
00:14:52,340 --> 00:14:53,340
And we can represent it

259
00:14:53,340 --> 00:14:55,500
with something nice and compact like that.

260
00:14:56,740 --> 00:14:57,780
Does that make sense?

261
00:14:59,860 --> 00:15:02,820
But then this gets in,

262
00:15:02,820 --> 00:15:05,140
then sort of the natural next question is like,

263
00:15:05,140 --> 00:15:09,140
okay, so you can represent very large worlds efficiently

264
00:15:09,140 --> 00:15:10,540
in this way,

265
00:15:10,540 --> 00:15:13,820
but then how do you actually compute with them?

266
00:15:13,820 --> 00:15:15,900
Like, this is a model, I want to query it.

267
00:15:15,900 --> 00:15:16,740
I want to be like,

268
00:15:16,740 --> 00:15:19,580
well, I've observed something over here in the world.

269
00:15:19,580 --> 00:15:21,220
What does that tell me about the probabilities

270
00:15:21,340 --> 00:15:23,380
of stuff over here, right?

271
00:15:23,380 --> 00:15:24,220
So first of all,

272
00:15:24,220 --> 00:15:26,980
it presumably has to be a lazy data structure

273
00:15:26,980 --> 00:15:29,860
because we definitely don't want to compute everything.

274
00:15:29,860 --> 00:15:31,340
And in general,

275
00:15:32,740 --> 00:15:34,540
if we're using this to model the world

276
00:15:34,540 --> 00:15:37,900
rather than just a way to write functions in Python,

277
00:15:37,900 --> 00:15:39,900
these things don't necessarily terminate.

278
00:15:39,900 --> 00:15:42,980
They can just be infinite data structures and that's fine.

279
00:15:45,900 --> 00:15:48,380
So yeah, how do we do that?

280
00:15:49,380 --> 00:15:53,620
Basic idea here is what we're gonna talk about

281
00:15:53,620 --> 00:15:55,620
in the next section, abstraction.

282
00:15:56,900 --> 00:16:01,660
In general, abstraction lets you calculate small summaries

283
00:16:01,660 --> 00:16:04,260
from which you can calculate probabilities

284
00:16:04,260 --> 00:16:06,100
of things far away in the model.

285
00:16:06,100 --> 00:16:09,300
So that generally lets you get around

286
00:16:09,300 --> 00:16:12,500
dealing with very large models in principle.

287
00:16:12,500 --> 00:16:13,340
Make sense?

288
00:16:15,140 --> 00:16:16,300
All right, cool.

289
00:16:19,380 --> 00:16:20,220
Yeah.

290
00:16:24,180 --> 00:16:26,220
Two more things to cover here.

291
00:16:26,220 --> 00:16:28,700
I'm going through this section a little faster

292
00:16:28,700 --> 00:16:29,540
than originally planned

293
00:16:29,540 --> 00:16:31,940
because I want to do the next section in detail.

294
00:16:37,340 --> 00:16:39,940
In terms of like how we would imagine this

295
00:16:39,940 --> 00:16:42,900
actually being implemented in something like a human brain,

296
00:16:44,060 --> 00:16:46,420
most of this structure you could find

297
00:16:46,460 --> 00:16:47,460
is basically equivalent

298
00:16:47,460 --> 00:16:49,180
to something like predictive processing.

299
00:16:49,180 --> 00:16:51,820
Like that's how you would do it in a distributed way.

300
00:16:51,820 --> 00:16:53,820
It's pretty straightforward.

301
00:16:53,820 --> 00:16:55,740
Predictive processing basically tells you

302
00:16:55,740 --> 00:17:00,500
how to take any generative model like this or like this

303
00:17:00,500 --> 00:17:05,380
and turn it into a sort of distributed implementation.

304
00:17:05,380 --> 00:17:06,220
Make sense?

305
00:17:09,180 --> 00:17:11,820
Yeah, I'm not going to explain how that works,

306
00:17:11,820 --> 00:17:14,780
but yeah, that is conceptually,

307
00:17:15,100 --> 00:17:16,740
like if you want to go into

308
00:17:16,740 --> 00:17:18,100
how you would implement something like this,

309
00:17:18,100 --> 00:17:19,460
that's the direction to go.

310
00:17:21,660 --> 00:17:24,540
Then the other thing to mention is

311
00:17:25,460 --> 00:17:27,660
if we're using this to model the world,

312
00:17:27,660 --> 00:17:29,380
then a lot of our variables in here

313
00:17:29,380 --> 00:17:30,580
are not going to be things

314
00:17:30,580 --> 00:17:32,700
that we can directly observe in the world.

315
00:17:32,700 --> 00:17:37,180
So like if I'm thinking about my mental model of this room,

316
00:17:37,180 --> 00:17:39,940
my mental model includes things like

317
00:17:40,940 --> 00:17:43,900
that chair is made of wood.

318
00:17:43,900 --> 00:17:45,180
The wood is not hollow.

319
00:17:45,180 --> 00:17:46,540
There's an inside to the wood,

320
00:17:46,540 --> 00:17:48,580
even though I can't directly observe that.

321
00:17:48,580 --> 00:17:49,780
The wood is made of cells.

322
00:17:49,780 --> 00:17:51,380
At a lower level, it's made of atoms.

323
00:17:51,380 --> 00:17:53,580
None of that I directly observe, right?

324
00:17:54,540 --> 00:17:57,380
I just directly observe some photons coming from the wood.

325
00:17:59,700 --> 00:18:02,500
In probabilistic model terms,

326
00:18:02,500 --> 00:18:04,220
you can think of that as

327
00:18:05,140 --> 00:18:07,700
we have this great big causal model

328
00:18:08,300 --> 00:18:09,140
and

329
00:18:14,620 --> 00:18:16,100
like somewhere in there,

330
00:18:16,100 --> 00:18:18,260
there's a bunch of stuff that I observe.

331
00:18:21,380 --> 00:18:25,100
Maybe observe that, observe this, observe this guy,

332
00:18:25,100 --> 00:18:27,220
but like most of the stuff in this model

333
00:18:27,220 --> 00:18:29,180
is not stuff that I observe directly.

334
00:18:31,700 --> 00:18:34,220
Everything that I don't directly observe

335
00:18:34,220 --> 00:18:37,580
and can't directly observe in general is latent variables.

336
00:18:38,340 --> 00:18:42,220
And the key thing there is whenever a variable is latent,

337
00:18:44,780 --> 00:18:48,220
there's not necessarily any way for me to say

338
00:18:48,220 --> 00:18:50,660
that it exists in an objective sense.

339
00:18:51,620 --> 00:18:53,700
So for instance,

340
00:18:56,300 --> 00:18:58,180
let's say I have a clustering problem.

341
00:18:59,020 --> 00:18:59,860
Okay.

342
00:19:06,940 --> 00:19:09,140
And I'm like, okay,

343
00:19:10,620 --> 00:19:12,620
there's a cluster here

344
00:19:14,140 --> 00:19:16,700
and a cluster there.

345
00:19:16,700 --> 00:19:20,220
And I can talk about the shapes of these clusters

346
00:19:20,220 --> 00:19:21,700
and their positions.

347
00:19:22,740 --> 00:19:23,580
Okay.

348
00:19:24,580 --> 00:19:28,140
The high level cluster parameters,

349
00:19:28,140 --> 00:19:30,860
like the shapes and the positions of the clusters,

350
00:19:32,020 --> 00:19:33,420
these are latent variables.

351
00:19:35,580 --> 00:19:38,420
And in principle,

352
00:19:38,420 --> 00:19:42,420
there's not really an objective sense in which

353
00:19:42,420 --> 00:19:45,500
like these are the right ways to model it, right?

354
00:19:45,500 --> 00:19:49,140
So like the shape and position of this cluster

355
00:19:49,140 --> 00:19:50,580
is not a thing which exists in the world,

356
00:19:50,580 --> 00:19:52,460
is the thing which exists in my mind.

357
00:19:52,540 --> 00:19:53,700
And that's what we're talking about

358
00:19:53,700 --> 00:19:56,940
when we're talking about latent variables in these models.

359
00:19:56,940 --> 00:19:59,020
In fact, the causal structure for,

360
00:19:59,020 --> 00:20:00,660
if we just look at one cluster,

361
00:20:02,660 --> 00:20:04,180
would look like this,

362
00:20:05,820 --> 00:20:07,500
where these are all the points

363
00:20:09,820 --> 00:20:14,020
and this guy is the high level cluster stuff.

364
00:20:14,020 --> 00:20:14,860
Okay.

365
00:20:19,420 --> 00:20:21,420
So we would say, in this case,

366
00:20:21,420 --> 00:20:24,220
we're observing all of these

367
00:20:24,220 --> 00:20:25,620
and then this guy is latent.

368
00:20:28,340 --> 00:20:29,180
Yes.

369
00:20:29,180 --> 00:20:30,580
This question, like your last statement,

370
00:20:30,580 --> 00:20:33,380
that it's not really there in the world.

371
00:20:33,380 --> 00:20:36,060
Do you mean something like it's a generator

372
00:20:36,060 --> 00:20:38,940
of the thing that you see in the world?

373
00:20:38,940 --> 00:20:41,660
That's exactly what we're about to address.

374
00:20:41,660 --> 00:20:46,660
So the main reason I'm bringing up this example

375
00:20:48,220 --> 00:20:49,660
is because it's sort of the setup

376
00:20:49,660 --> 00:20:50,940
for the pointers problem.

377
00:20:55,460 --> 00:20:56,300
Claim

378
00:21:03,580 --> 00:21:08,580
inputs to human values

379
00:21:12,660 --> 00:21:15,980
are latent variables

380
00:21:19,700 --> 00:21:24,700
in human world models.

381
00:21:30,140 --> 00:21:31,740
And that's the pointers problem.

382
00:21:38,540 --> 00:21:39,780
All right.

383
00:21:39,780 --> 00:21:42,180
Anybody wanna tell me why this would be a problem?

384
00:21:47,780 --> 00:21:48,620
Go ahead.

385
00:21:51,740 --> 00:21:52,580
Can't observe them.

386
00:21:52,580 --> 00:21:53,420
In what sense?

387
00:21:58,540 --> 00:21:59,380
There we go.

388
00:22:07,620 --> 00:22:08,460
There you go.

389
00:22:08,460 --> 00:22:09,300
Good.

390
00:22:09,820 --> 00:22:10,980
So let's do an example.

391
00:22:12,180 --> 00:22:13,740
Pick some objects.

392
00:22:13,740 --> 00:22:14,580
What's that?

393
00:22:19,300 --> 00:22:20,420
That's the cute way to say it.

394
00:22:20,420 --> 00:22:21,260
Yes.

395
00:22:24,420 --> 00:22:25,260
All right.

396
00:22:25,260 --> 00:22:27,420
Let's do an example with some markers.

397
00:22:27,420 --> 00:22:32,420
So here I have four markers.

398
00:22:33,500 --> 00:22:38,180
You could imagine that these were the only four markers

399
00:22:38,180 --> 00:22:40,220
someone had ever seen in their life.

400
00:22:40,220 --> 00:22:42,060
And from their standpoint,

401
00:22:42,060 --> 00:22:46,100
they're like space of markers.

402
00:22:51,700 --> 00:22:56,700
Looks like one, two, three, four markers.

403
00:22:56,820 --> 00:22:57,660
All right.

404
00:22:58,620 --> 00:23:01,380
So in their mind, their notion of marker,

405
00:23:01,380 --> 00:23:03,820
maybe they have like a little cluster around that

406
00:23:03,820 --> 00:23:07,540
and they're like, ah, this is what marker is.

407
00:23:07,620 --> 00:23:09,620
And if this person comes along and says,

408
00:23:09,620 --> 00:23:12,980
I would like an orange marker, please.

409
00:23:12,980 --> 00:23:16,580
Then they're imagining that I'm going to generate

410
00:23:16,580 --> 00:23:19,620
an orange marker somewhere like there.

411
00:23:20,940 --> 00:23:22,540
All right.

412
00:23:22,540 --> 00:23:23,580
On the other hand,

413
00:23:24,460 --> 00:23:26,020
we could now imagine someone

414
00:23:26,020 --> 00:23:27,780
who had seen slightly more markers.

415
00:23:30,620 --> 00:23:32,420
Here we have slightly more markers.

416
00:23:33,380 --> 00:23:35,500
So they've seen these little Sharpies here.

417
00:23:35,500 --> 00:23:36,700
They've seen these big markers.

418
00:23:36,700 --> 00:23:38,380
Maybe they've seen some of the whiteboard markers

419
00:23:38,380 --> 00:23:39,220
over there.

420
00:23:40,900 --> 00:23:42,180
And now this person,

421
00:23:42,180 --> 00:23:47,180
they still have these four points in their marker space,

422
00:23:47,700 --> 00:23:51,860
but now they also have some points that are like over here.

423
00:23:51,860 --> 00:23:54,100
And maybe they have some markers over there.

424
00:23:55,060 --> 00:23:59,620
And if this person says, bring me an orange marker,

425
00:23:59,620 --> 00:24:03,700
they're hoping for something more like, I don't know,

426
00:24:04,700 --> 00:24:07,260
over here-ish maybe.

427
00:24:11,980 --> 00:24:14,020
And it's not really clear

428
00:24:14,020 --> 00:24:16,900
that either of these people is wrong, right?

429
00:24:16,900 --> 00:24:19,020
Like they're both,

430
00:24:19,020 --> 00:24:21,420
they both have a notion of marker,

431
00:24:21,420 --> 00:24:25,660
which is like, you know, valid in some sense.

432
00:24:25,660 --> 00:24:27,620
They both have a clear thing that they want

433
00:24:27,620 --> 00:24:30,700
and yet they're like disagreeing on what the thing is

434
00:24:30,700 --> 00:24:33,060
that I want an orange marker is asking for.

435
00:24:34,300 --> 00:24:36,980
And you can imagine this would be a much bigger issue

436
00:24:36,980 --> 00:24:39,180
if like you're building an AI

437
00:24:39,180 --> 00:24:41,100
and is confused about what you even mean

438
00:24:41,100 --> 00:24:43,260
by I would like an orange marker, please.

439
00:24:43,260 --> 00:24:44,860
That could get screwy real fast

440
00:24:44,860 --> 00:24:47,900
if it's working in a really different world model.

441
00:24:47,900 --> 00:24:48,740
Okay?

442
00:24:49,700 --> 00:24:53,260
So this is the basis of the pointers problem.

443
00:24:53,260 --> 00:24:55,980
And from a selection theorem standpoint,

444
00:24:55,980 --> 00:24:58,620
the big question is basically

445
00:24:59,580 --> 00:25:04,580
what sort of latent variable structures are selected for?

446
00:25:06,100 --> 00:25:10,660
If we know what kinds of latent variables are useful

447
00:25:10,660 --> 00:25:12,620
in whatever ways,

448
00:25:12,620 --> 00:25:15,220
then we can make predictions

449
00:25:15,220 --> 00:25:18,780
about what kinds of latent variables humans probably use

450
00:25:18,780 --> 00:25:20,140
and thereby make predictions

451
00:25:20,140 --> 00:25:22,100
about like what kinds of things

452
00:25:22,100 --> 00:25:24,860
we typically recognize as things in the world

453
00:25:24,860 --> 00:25:27,100
or what types of objects

454
00:25:27,140 --> 00:25:29,700
we typically recognize as types of objects, right?

455
00:25:35,060 --> 00:25:37,420
Let's see, other comments on that.

456
00:25:45,540 --> 00:25:47,820
One more thing on type signatures here,

457
00:25:47,820 --> 00:25:49,700
throwing a little bit more math on it.

458
00:25:51,420 --> 00:25:53,500
If we just think about a single sub-agent

459
00:25:54,460 --> 00:25:57,940
wants to maximize on X

460
00:25:59,260 --> 00:26:04,100
expectation of utility

461
00:26:05,180 --> 00:26:08,900
of let's say model.y

462
00:26:09,900 --> 00:26:13,100
given, I'll write it as

463
00:26:13,100 --> 00:26:18,100
do model.x equals X.

464
00:26:18,940 --> 00:26:23,940
This is like the standard utility maximization problem

465
00:26:25,420 --> 00:26:27,220
on a causal model

466
00:26:27,220 --> 00:26:29,820
where do model.x equals X

467
00:26:29,820 --> 00:26:32,220
is basically saying we go into the causal model

468
00:26:32,220 --> 00:26:35,140
and we make the thing we're calling X equal to this value.

469
00:26:38,900 --> 00:26:41,860
In terms of type signatures here,

470
00:26:41,860 --> 00:26:45,940
if Y is a latent variable in our model,

471
00:26:46,900 --> 00:26:51,900
then it's not clear how Y maps to the world.

472
00:26:52,700 --> 00:26:53,780
Like in terms of type,

473
00:26:53,780 --> 00:26:56,340
it is a thing which lives in the model

474
00:26:56,340 --> 00:26:57,900
and we're able to work with it

475
00:26:57,900 --> 00:27:01,060
because it's inside of this expectation symbol.

476
00:27:01,060 --> 00:27:03,100
We're taking an expectation over it.

477
00:27:03,100 --> 00:27:04,020
We don't really have a way

478
00:27:04,020 --> 00:27:06,060
to take it outside the expectation symbol.

479
00:27:06,060 --> 00:27:08,260
If we're just like, ah, what's Y?

480
00:27:08,260 --> 00:27:10,300
Go look in the world and tell me what Y is.

481
00:27:10,300 --> 00:27:11,940
That doesn't really work.

482
00:27:11,940 --> 00:27:14,460
There's just not necessarily anything in the world

483
00:27:14,460 --> 00:27:15,660
that it corresponds to.

484
00:27:17,060 --> 00:27:19,060
So for example,

485
00:27:19,060 --> 00:27:21,340
in the

486
00:27:24,460 --> 00:27:26,780
17th century,

487
00:27:26,780 --> 00:27:29,220
people thought that

488
00:27:30,380 --> 00:27:34,180
a lot of illness was caused by miasma, right?

489
00:27:34,180 --> 00:27:38,260
Which didn't really map particularly perfectly

490
00:27:38,260 --> 00:27:41,460
to any particular thing in the physical world, right?

491
00:27:41,460 --> 00:27:44,420
They had this concept, this thing in their world model

492
00:27:45,260 --> 00:27:47,020
that didn't perfectly correspond to anything.

493
00:27:48,620 --> 00:27:51,540
Now that's an issue if you're like building AI

494
00:27:51,540 --> 00:27:53,260
and you're like, well,

495
00:27:53,260 --> 00:27:57,380
I want you to go get rid of the miasma, please.

496
00:27:57,380 --> 00:28:00,500
And the AI is like, what's a miasma?

497
00:28:00,500 --> 00:28:02,180
There's not actually anything in the world

498
00:28:02,180 --> 00:28:03,220
that corresponds to that.

499
00:28:03,220 --> 00:28:05,180
So there's just like not really a way

500
00:28:05,180 --> 00:28:06,780
for it to map the thing you want

501
00:28:06,780 --> 00:28:09,020
onto the thing in the world, right?

502
00:28:09,860 --> 00:28:12,260
And going through the world,

503
00:28:12,260 --> 00:28:14,100
we experience different things.

504
00:28:14,100 --> 00:28:16,780
We try to come up with explanations of these things.

505
00:28:16,780 --> 00:28:17,620
Yep.

506
00:28:17,620 --> 00:28:18,740
With these causal models,

507
00:28:18,740 --> 00:28:20,580
we cluster things together.

508
00:28:21,980 --> 00:28:24,220
One example of coming up with an explanation.

509
00:28:24,220 --> 00:28:28,500
And we kind of somehow have a sense of

510
00:28:28,500 --> 00:28:30,380
this is the way things should be.

511
00:28:30,380 --> 00:28:31,220
Yep.

512
00:28:31,220 --> 00:28:33,300
In terms of the pattern,

513
00:28:33,300 --> 00:28:34,740
stories, explanations,

514
00:28:34,740 --> 00:28:36,700
clusters of sound in the world.

515
00:28:36,700 --> 00:28:39,260
This cluster should exist or should be more

516
00:28:39,260 --> 00:28:41,060
or should be changed more like that.

517
00:28:43,060 --> 00:28:46,420
And we take actions that can,

518
00:28:47,620 --> 00:28:51,380
the world such that the thing we experience

519
00:28:51,380 --> 00:28:55,860
is more like the way we think the abstractions should be.

520
00:28:55,860 --> 00:29:00,260
But the abstractions are fundamentally not real.

521
00:29:00,260 --> 00:29:02,780
They're fundamentally an explanation.

522
00:29:02,780 --> 00:29:03,620
Right.

523
00:29:03,620 --> 00:29:05,620
They're also not exactly unreal,

524
00:29:05,620 --> 00:29:07,300
but they're not,

525
00:29:07,300 --> 00:29:10,380
they don't have the status of a thing in the world.

526
00:29:13,780 --> 00:29:15,220
And therefore,

527
00:29:15,220 --> 00:29:18,340
we can't just go ask something else to change them

528
00:29:18,340 --> 00:29:20,700
separate from the thing in our heads.

529
00:29:20,700 --> 00:29:21,540
Right.

530
00:29:21,540 --> 00:29:24,180
Any obvious operationalization of this thing

531
00:29:24,180 --> 00:29:27,060
is probably going to go through the concept in our heads.

532
00:29:27,060 --> 00:29:28,540
And then you risk the AI,

533
00:29:28,540 --> 00:29:30,260
like manipulating the thing in your head

534
00:29:30,260 --> 00:29:32,660
rather than manipulating the thing in the world.

535
00:29:33,660 --> 00:29:35,980
We can use tools.

536
00:29:35,980 --> 00:29:38,420
We might build a bulldozer

537
00:29:38,420 --> 00:29:40,060
or we might build the internet.

538
00:29:40,060 --> 00:29:43,980
Or we might even build a clever market regulation system

539
00:29:43,980 --> 00:29:45,740
or a high frequency trading system.

540
00:29:45,740 --> 00:29:47,860
Or we can build these complicated

541
00:29:47,860 --> 00:29:49,780
and kind of intelligent systems.

542
00:29:49,780 --> 00:29:50,620
Yep.

543
00:29:58,820 --> 00:30:00,460
But now we're trying to

544
00:30:01,260 --> 00:30:05,260
do that without having to be involved with them.

545
00:30:05,260 --> 00:30:07,780
So we can do that autonomously.

546
00:30:07,780 --> 00:30:08,620
Yep.

547
00:30:08,620 --> 00:30:11,540
Without getting some kind of direction

548
00:30:11,540 --> 00:30:14,620
or some kind of correction from us.

549
00:30:14,620 --> 00:30:16,220
That's where it's hard.

550
00:30:16,220 --> 00:30:17,060
Yep.

551
00:30:17,060 --> 00:30:17,900
Bingo.

552
00:30:19,300 --> 00:30:20,140
Yes.

553
00:30:20,140 --> 00:30:24,620
But why is it that we can take an expectation of this

554
00:30:24,620 --> 00:30:28,100
and we can't just find out what it is

555
00:30:28,100 --> 00:30:29,300
and then use it?

556
00:30:29,300 --> 00:30:30,140
Great question.

557
00:30:31,140 --> 00:30:33,740
Let's use the clustering example.

558
00:30:33,740 --> 00:30:34,580
That'll work.

559
00:30:35,740 --> 00:30:40,740
So if we have a probabilistic clustering model,

560
00:30:41,540 --> 00:30:43,260
part of what goes into that model

561
00:30:43,260 --> 00:30:47,660
is we have a prior P of mu sigma.

562
00:30:47,660 --> 00:30:48,500
Right?

563
00:30:49,940 --> 00:30:52,980
And then we also have in the model something like

564
00:30:55,060 --> 00:30:56,300
for each I,

565
00:30:56,300 --> 00:30:58,620
so like for each data point XI,

566
00:30:59,220 --> 00:31:03,380
we're going to be taking a product on those.

567
00:31:03,380 --> 00:31:05,740
What's the probability that we observe XI

568
00:31:05,740 --> 00:31:07,540
given this particular mu and sigma?

569
00:31:09,220 --> 00:31:10,060
Like in this case,

570
00:31:10,060 --> 00:31:11,780
I'm just sort of ignoring the other cluster,

571
00:31:11,780 --> 00:31:12,940
but whatever.

572
00:31:14,020 --> 00:31:17,700
So the only part of this,

573
00:31:17,700 --> 00:31:20,580
which is like in the world, so to speak,

574
00:31:20,580 --> 00:31:23,740
are the XIs themselves.

575
00:31:23,740 --> 00:31:25,700
The rest of this is all stuff that lives in the model,

576
00:31:25,700 --> 00:31:26,740
the mus and the sigmas.

577
00:31:26,740 --> 00:31:29,060
And in particular, the prior

578
00:31:29,060 --> 00:31:32,340
and actually the shape of the model itself.

579
00:31:32,340 --> 00:31:33,580
So this factorization.

580
00:31:34,860 --> 00:31:38,980
All of that is stuff that's essentially prior information.

581
00:31:38,980 --> 00:31:40,860
Like we talk about the prior distribution,

582
00:31:40,860 --> 00:31:42,060
but the shape of the model itself

583
00:31:42,060 --> 00:31:44,500
is also really part of your prior information.

584
00:31:46,140 --> 00:31:48,300
So when you take this expectation,

585
00:31:49,560 --> 00:31:52,260
that's all stuff that you're effectively summing over.

586
00:31:53,540 --> 00:31:56,340
And that's sort of the magic juice

587
00:31:56,980 --> 00:31:58,420
that lets you take the expectation

588
00:31:58,420 --> 00:32:00,260
over a thing that doesn't live in the world.

589
00:32:00,260 --> 00:32:01,940
Is you have all this sort of model

590
00:32:01,940 --> 00:32:04,900
that you were implicitly or explicitly assuming

591
00:32:04,900 --> 00:32:05,740
from the start.

592
00:32:07,620 --> 00:32:08,700
Does that make sense?

593
00:32:15,460 --> 00:32:16,300
Exactly.

594
00:32:18,660 --> 00:32:20,300
Cool.

595
00:32:20,300 --> 00:32:21,140
All right.

596
00:32:21,140 --> 00:32:26,140
And so this all motivates yet another thing

597
00:32:28,260 --> 00:32:31,300
that motivates the next section on abstraction.

598
00:32:33,380 --> 00:32:34,500
Before we get to that,

599
00:32:34,500 --> 00:32:38,620
I'm just gonna like throw out a quick like bullet list

600
00:32:38,620 --> 00:32:41,500
of things that we're not talking about

601
00:32:41,500 --> 00:32:43,880
more in the selection theorems department.

602
00:32:45,980 --> 00:32:47,940
So other things.

603
00:32:52,140 --> 00:32:54,180
Some of these are more important.

604
00:32:54,180 --> 00:32:55,420
Some of these are less important.

605
00:32:55,420 --> 00:32:56,500
The common theme on them

606
00:32:56,500 --> 00:32:59,100
is that I'm not the right person to talk about them.

607
00:33:00,100 --> 00:33:01,580
So top of the list,

608
00:33:01,580 --> 00:33:06,580
most important things probably are decision theory

609
00:33:11,100 --> 00:33:12,740
and counterfactuals.

610
00:33:13,740 --> 00:33:18,740
So here's a question I don't know the answer to.

611
00:33:21,900 --> 00:33:24,300
What decision theory does evolution select for?

612
00:33:26,580 --> 00:33:28,100
That really seems like a question

613
00:33:28,100 --> 00:33:29,980
we should know the answer to by now, doesn't it?

614
00:33:29,980 --> 00:33:31,100
But I don't know it.

615
00:33:34,380 --> 00:33:39,380
Also in this department is just sort of general

616
00:33:42,780 --> 00:33:47,780
principles for linking actions to world models.

617
00:34:00,700 --> 00:34:03,860
Or I guess Flint would call it the knowledge problem

618
00:34:03,860 --> 00:34:05,780
or part of the knowledge problem.

619
00:34:05,780 --> 00:34:08,700
This I think of as a subset of the decision theory

620
00:34:08,700 --> 00:34:10,140
and counterfactual problems.

621
00:34:10,140 --> 00:34:12,700
Like if part of figuring out what decision theory

622
00:34:13,540 --> 00:34:15,300
evolution selects for is figuring out

623
00:34:15,300 --> 00:34:19,540
like how the actions that something can take

624
00:34:19,540 --> 00:34:23,540
are going to be wired into its decision-making process.

625
00:34:26,820 --> 00:34:28,420
So that I would say is probably the biggest thing

626
00:34:28,420 --> 00:34:30,580
that we're not gonna be talking about much.

627
00:34:31,700 --> 00:34:35,780
Other than that, another big one is logical uncertainty.

628
00:34:43,660 --> 00:34:48,660
Yeah, you guys probably have heard stuff about that before.

629
00:34:53,620 --> 00:34:58,620
And then neurological bases, that's an interesting one.

630
00:35:00,820 --> 00:35:03,620
We briefly mentioned predictive processing,

631
00:35:03,620 --> 00:35:07,020
but like in general, tying this all to,

632
00:35:07,580 --> 00:35:12,580
yeah, neurological, tying this all to like

633
00:35:12,980 --> 00:35:15,700
the actual physical mechanisms in the brain

634
00:35:15,700 --> 00:35:19,020
is just sort of wide open territory, very useful.

635
00:35:19,020 --> 00:35:22,260
Like that would be great stuff to have in general.

636
00:35:22,260 --> 00:35:24,540
Similarly, there's a lot of pieces

637
00:35:24,540 --> 00:35:26,140
where we don't yet have selection theorems.

638
00:35:26,140 --> 00:35:27,700
We don't have selection theorems

639
00:35:27,700 --> 00:35:29,820
for the parts we need in this.

640
00:35:29,820 --> 00:35:31,260
We don't have selection theorems

641
00:35:31,260 --> 00:35:33,860
for like causal world models in particular.

642
00:35:33,860 --> 00:35:36,500
We don't have selection theorems yet for abstractions.

643
00:35:36,940 --> 00:35:39,100
Like really the, sure.

644
00:35:39,100 --> 00:35:41,700
Like really the only part we do have selection theorems

645
00:35:41,700 --> 00:35:44,300
for at this point is coherence.

646
00:35:44,300 --> 00:35:48,820
So we really like building out all that is important.

647
00:35:48,820 --> 00:35:52,180
The selection theorem is an explanation

648
00:35:52,180 --> 00:35:56,380
about the way that, in this case, the way that agents work

649
00:35:56,380 --> 00:36:01,380
in terms of, in terms of the algorithm goes

650
00:36:02,380 --> 00:36:06,660
in the long run, all the agents that survive

651
00:36:06,660 --> 00:36:07,500
will look like this.

652
00:36:07,500 --> 00:36:09,940
So the agents that dominate the marketplace

653
00:36:09,940 --> 00:36:11,700
of evolutionary landscape,

654
00:36:11,700 --> 00:36:15,500
the agents that appear in the long run look like this.

655
00:36:15,500 --> 00:36:16,340
Yep, exactly.

656
00:36:16,340 --> 00:36:20,340
The agents that are in the world look like this.

657
00:36:20,340 --> 00:36:21,180
Yep.

658
00:36:24,580 --> 00:36:27,220
Other than that, just like more generally,

659
00:36:28,220 --> 00:36:33,220
knowing what else to ask is always an important one.

660
00:36:35,700 --> 00:36:37,540
We don't necessarily know that,

661
00:36:39,100 --> 00:36:40,660
we don't know that we know all the things here.

662
00:36:40,660 --> 00:36:42,760
There are probably unknown, unknown still.

663
00:36:44,460 --> 00:36:45,500
Welcome to alignment.

664
00:36:47,100 --> 00:36:47,940
Yeah.

665
00:36:49,780 --> 00:36:50,620
Cool.

666
00:36:50,620 --> 00:36:51,460
Yeah.

667
00:36:57,580 --> 00:36:58,420
Yep.

668
00:37:03,260 --> 00:37:04,100
Yep.

669
00:37:08,540 --> 00:37:09,380
Yeah.

670
00:37:15,820 --> 00:37:17,580
Yeah, I mean, I think that's straightforwardly

671
00:37:17,580 --> 00:37:18,620
a mistake on their part,

672
00:37:18,620 --> 00:37:21,140
but like there are still useful things there

673
00:37:21,140 --> 00:37:25,100
that like are, some of them are close enough

674
00:37:25,100 --> 00:37:27,020
that it would probably produce a selection theorem

675
00:37:27,020 --> 00:37:28,380
if you tried.

676
00:37:28,380 --> 00:37:33,220
Like Abram's thing on Dutch booking agents

677
00:37:33,220 --> 00:37:36,380
where the CDT isn't equal to EDT

678
00:37:36,380 --> 00:37:39,020
is one that you could probably turn

679
00:37:39,020 --> 00:37:40,980
into a selection theorem pretty easily.

680
00:37:43,460 --> 00:37:47,740
All right, so I kind of rushed through that last bit

681
00:37:47,740 --> 00:37:50,820
to get to abstractions.

682
00:37:50,820 --> 00:37:55,260
Any questions before we move on?

683
00:38:04,980 --> 00:38:05,820
Cool.

684
00:38:06,580 --> 00:38:07,420
All right.

685
00:38:16,700 --> 00:38:17,540
All right.

686
00:38:17,540 --> 00:38:19,860
This section is stuff we've talked about

687
00:38:19,860 --> 00:38:20,980
a little bit before,

688
00:38:20,980 --> 00:38:23,980
but I wanna flesh out the math a bit more

689
00:38:23,980 --> 00:38:27,740
and also talk more about how it ties into the bigger picture.

690
00:38:27,740 --> 00:38:30,940
So first things first.

691
00:38:31,820 --> 00:38:34,580
Reminder for why we're talking about abstraction.

692
00:38:34,580 --> 00:38:36,060
First of all, there's the pointers problem.

693
00:38:36,060 --> 00:38:37,140
We just covered that.

694
00:38:39,020 --> 00:38:42,100
More generally, we want to be able to measure

695
00:38:42,100 --> 00:38:43,460
all this human value stuff.

696
00:38:43,460 --> 00:38:45,860
Like we talked a bunch about type signatures.

697
00:38:45,860 --> 00:38:48,260
We talked a bunch about like

698
00:38:48,260 --> 00:38:49,980
what kind of thing we're looking for,

699
00:38:49,980 --> 00:38:53,220
but we still need the tools to go out and look for it.

700
00:38:53,220 --> 00:38:56,820
So the question is, how do we go measure

701
00:38:56,820 --> 00:38:59,820
any of these parts of an agent

702
00:38:59,820 --> 00:39:02,900
or things an agent cares about or any of that?

703
00:39:05,220 --> 00:39:10,220
And as a sort of corollary of that,

704
00:39:10,940 --> 00:39:12,620
if we can go measure these things,

705
00:39:12,620 --> 00:39:15,380
then we can get feedback signals on them.

706
00:39:15,380 --> 00:39:18,500
Like once you can go start to measure,

707
00:39:18,500 --> 00:39:20,220
like is there an agent here at all,

708
00:39:20,220 --> 00:39:23,060
or measure values, measure utilities,

709
00:39:23,060 --> 00:39:26,380
measure probabilities within the system

710
00:39:26,380 --> 00:39:27,780
in which they're embedded,

711
00:39:27,780 --> 00:39:30,060
then we can start to do empirical work

712
00:39:30,060 --> 00:39:32,540
on the agency theory, right?

713
00:39:32,540 --> 00:39:34,660
We can start to go directly check

714
00:39:34,660 --> 00:39:37,780
how all this very abstract stuff actually plays out.

715
00:39:38,700 --> 00:39:39,820
Make sense?

716
00:39:39,820 --> 00:39:41,940
So a big part of the goal here

717
00:39:41,940 --> 00:39:45,740
is just generally being able to go from

718
00:39:45,740 --> 00:39:48,340
all this crazy theory stuff to actually doing science.

719
00:39:48,340 --> 00:39:49,860
That's the happy world.

720
00:39:52,460 --> 00:39:57,460
So general version of the problem,

721
00:39:58,380 --> 00:40:01,420
what are abstract objects?

722
00:40:01,460 --> 00:40:05,100
Why do we recognize the things we do as objects?

723
00:40:05,100 --> 00:40:08,580
For instance, we have this coconut cup.

724
00:40:08,580 --> 00:40:10,420
Why do we recognize this coconut cup

725
00:40:10,420 --> 00:40:12,700
as a natural thing to think of as an object

726
00:40:12,700 --> 00:40:15,020
rather than thinking of, say,

727
00:40:16,020 --> 00:40:18,780
this half of the coconut cup as an object

728
00:40:18,780 --> 00:40:22,300
and this half of the coconut cup as a separate object?

729
00:40:22,300 --> 00:40:26,460
Or why do we think of this coconut cup as an object

730
00:40:26,460 --> 00:40:29,600
rather than this coconut cup plus that chair

731
00:40:29,600 --> 00:40:32,720
plus this particular floorboard as an object?

732
00:40:32,720 --> 00:40:35,480
What makes this thing more a natural object than those?

733
00:40:41,440 --> 00:40:43,200
Interesting piece of evidence here.

734
00:40:45,560 --> 00:40:47,600
Whatever principle it is that we're using

735
00:40:47,600 --> 00:40:50,480
to recognize these things as objects,

736
00:40:50,480 --> 00:40:54,080
it can't be that complex in some sense

737
00:40:55,400 --> 00:40:58,160
because when you have a baby

738
00:40:58,160 --> 00:41:01,360
and the baby's learning the concept of what an apple is,

739
00:41:01,360 --> 00:41:02,920
how many examples does it take?

740
00:41:05,120 --> 00:41:08,640
Like maybe two, three tops, right?

741
00:41:08,640 --> 00:41:11,240
It takes very few examples for a baby

742
00:41:11,240 --> 00:41:12,760
to learn to recognize apples.

743
00:41:12,760 --> 00:41:15,800
And yet, if you think about,

744
00:41:16,840 --> 00:41:18,840
let's say we're building an apple classifier.

745
00:41:18,840 --> 00:41:19,880
I feed it an image.

746
00:41:19,880 --> 00:41:22,280
It tells me, is there an apple here?

747
00:41:22,280 --> 00:41:26,680
Well, the space of functions which take in a megabyte image

748
00:41:26,680 --> 00:41:28,920
and spit out a bool,

749
00:41:28,920 --> 00:41:31,200
there's something like two to the two

750
00:41:31,200 --> 00:41:35,580
to a million possible functions that do that, right?

751
00:41:35,580 --> 00:41:37,320
Like just absurdly huge space.

752
00:41:37,320 --> 00:41:39,000
There is no way in hell that you're going to learn

753
00:41:39,000 --> 00:41:40,980
to recognize apples by brute force

754
00:41:40,980 --> 00:41:42,960
given two or three examples.

755
00:41:42,960 --> 00:41:45,880
Brute force figuring that out would require

756
00:41:45,880 --> 00:41:49,520
like two to a million examples

757
00:41:49,520 --> 00:41:52,240
or some ridiculous number like that, right?

758
00:41:52,240 --> 00:41:56,320
So clearly, there's something going on here

759
00:41:56,960 --> 00:41:59,520
which is baked in.

760
00:41:59,520 --> 00:42:01,200
It's baked into the way we think

761
00:42:01,200 --> 00:42:03,840
and it requires very few examples.

762
00:42:03,840 --> 00:42:07,480
So like most of the work of recognizing what an apple is,

763
00:42:07,480 --> 00:42:11,280
the baby must already be doing before it hears the word,

764
00:42:11,280 --> 00:42:12,120
right?

765
00:42:13,440 --> 00:42:16,800
And then the key question is, well, how is it doing that?

766
00:42:18,680 --> 00:42:23,160
So we're gonna go through three different

767
00:42:23,160 --> 00:42:24,600
mathematical views here

768
00:42:24,600 --> 00:42:26,680
with different intuitions underlying them

769
00:42:26,680 --> 00:42:28,880
that end up all pointing in the same place.

770
00:42:30,160 --> 00:42:33,160
The first one is gonna be about

771
00:42:33,160 --> 00:42:35,080
information relevant far away.

772
00:42:35,080 --> 00:42:40,080
So this is the idea that my concept of this coconut cup

773
00:42:41,880 --> 00:42:44,840
is basically a summary of all the information

774
00:42:44,840 --> 00:42:46,200
about this cup,

775
00:42:46,200 --> 00:42:48,440
which is relevant in lots of other places

776
00:42:48,440 --> 00:42:49,600
far off in the world.

777
00:42:50,600 --> 00:42:53,040
Second concept we'll go through

778
00:42:53,040 --> 00:42:57,120
is that my concept of anything,

779
00:42:57,120 --> 00:42:59,480
concept of the coconut cup, for instance,

780
00:42:59,480 --> 00:43:03,560
is a summary of information which is redundant.

781
00:43:03,560 --> 00:43:06,080
So for instance, we have the coconut cup now,

782
00:43:06,080 --> 00:43:07,280
we have the coconut cup now,

783
00:43:07,280 --> 00:43:08,520
we have the coconut cup now,

784
00:43:08,520 --> 00:43:10,720
we have the coconut cup three hours ago.

785
00:43:10,720 --> 00:43:12,320
We have the image of the coconut cup,

786
00:43:12,320 --> 00:43:13,920
which is hitting Flint's retina.

787
00:43:14,840 --> 00:43:17,920
We have probably,

788
00:43:18,760 --> 00:43:23,760
probably similar coconut cups available for sale online.

789
00:43:25,680 --> 00:43:29,320
All of this is information that's redundant

790
00:43:29,320 --> 00:43:30,360
in the sense that like,

791
00:43:30,360 --> 00:43:33,520
if I hide the coconut cup by my back right now,

792
00:43:33,520 --> 00:43:35,600
you can make a pretty good guess as to what's there.

793
00:43:35,600 --> 00:43:37,680
You can reconstruct it with the information you have

794
00:43:37,680 --> 00:43:39,400
about the coconut cup earlier

795
00:43:39,400 --> 00:43:40,920
and the coconut cup later, right?

796
00:43:40,920 --> 00:43:42,520
Object permanence, it's a thing.

797
00:43:44,240 --> 00:43:46,320
So that's gonna be the second approach.

798
00:43:47,280 --> 00:43:49,800
The third approach we'll take

799
00:43:49,800 --> 00:43:51,480
is going to be to think about

800
00:43:52,680 --> 00:43:54,600
sort of the universality of abstractions.

801
00:43:54,600 --> 00:43:57,840
Like the simple fact that we're able

802
00:43:57,840 --> 00:44:00,080
to learn similar abstractions

803
00:44:00,080 --> 00:44:03,880
suggests that there's some sort of universality principle

804
00:44:03,880 --> 00:44:05,200
going on here.

805
00:44:05,200 --> 00:44:09,240
And it turns out that that basically narrows it down

806
00:44:09,240 --> 00:44:11,880
to one possible way of doing it, okay?

807
00:44:17,160 --> 00:44:18,000
Whew.

808
00:44:19,760 --> 00:44:23,960
So, we'll start off with a causal model

809
00:44:23,960 --> 00:44:25,160
and we're gonna assume that this is

810
00:44:25,160 --> 00:44:27,640
some ridiculously large causal model.

811
00:44:27,640 --> 00:44:30,920
I'll draw a bunch of arrows and then some dot, dot, dots.

812
00:44:46,320 --> 00:44:47,160
Okay.

813
00:44:52,360 --> 00:44:57,320
So, to talk about information far away,

814
00:44:57,320 --> 00:45:00,920
we're going to look at sequences of Markov blankets

815
00:45:00,920 --> 00:45:02,600
in this causal graph.

816
00:45:02,600 --> 00:45:05,960
So maybe here's one sequence.

817
00:45:17,320 --> 00:45:18,160
Okay.

818
00:45:20,040 --> 00:45:25,040
We'll call this one M1, M2, M3, M4, dot, dot, dot.

819
00:45:30,200 --> 00:45:33,960
And just assume that this model goes on for a while.

820
00:45:39,040 --> 00:45:39,880
Okay.

821
00:45:41,880 --> 00:45:44,280
So, we're talking about information far away.

822
00:45:44,280 --> 00:45:45,920
The way we're operationalizing that,

823
00:45:45,920 --> 00:45:48,160
we're not necessarily talking about far away

824
00:45:48,160 --> 00:45:49,800
in like space time.

825
00:45:49,800 --> 00:45:52,800
We're talking about far away in this causal graph.

826
00:45:52,800 --> 00:45:57,520
So, like there are many causal intermediates

827
00:45:57,520 --> 00:45:59,240
between me and the thing.

828
00:46:00,560 --> 00:46:03,280
And we're representing that using

829
00:46:03,280 --> 00:46:05,360
these sequential layers of Markov blankets.

830
00:46:05,360 --> 00:46:08,560
We're saying like, look, between me and Rob,

831
00:46:08,560 --> 00:46:11,440
I can carve out lots of layers of air

832
00:46:12,600 --> 00:46:14,760
or layers of floor or whatever.

833
00:46:14,760 --> 00:46:16,960
And if anything wants to propagate from me to him,

834
00:46:16,960 --> 00:46:19,480
it's going to have to go through all those layers.

835
00:46:21,480 --> 00:46:26,480
And then the key theorem here is the telephone theorem.

836
00:46:33,040 --> 00:46:38,040
So, we're going to imagine that there's a message passing

837
00:46:38,160 --> 00:46:41,280
from me to Rob through each of these layers of air.

838
00:46:42,280 --> 00:46:47,280
There is in fact, right now, I know it's so difficult

839
00:46:48,440 --> 00:46:51,720
to imagine, but we're going to imagine

840
00:46:51,720 --> 00:46:55,320
that the layer of air is perhaps not quite so good

841
00:46:55,320 --> 00:46:58,160
at passing messages as we usually imagine.

842
00:46:58,160 --> 00:47:00,640
So, instead we're going to replace the layers of air

843
00:47:00,640 --> 00:47:01,480
with people.

844
00:47:01,480 --> 00:47:03,200
Hey, you two, come here.

845
00:47:06,760 --> 00:47:09,400
This would work better with more people,

846
00:47:09,400 --> 00:47:10,720
but the actual way it's going to work

847
00:47:11,120 --> 00:47:12,280
is if I'm going to give my message to Adam,

848
00:47:12,280 --> 00:47:14,720
then Adam's going to turn around and give it to Flint.

849
00:47:14,720 --> 00:47:17,560
And then ideally we'd have a very long line of people here.

850
00:47:17,560 --> 00:47:18,720
And then the last person in line

851
00:47:18,720 --> 00:47:20,720
would pass the message to Rob, right?

852
00:47:20,720 --> 00:47:22,400
This is the game of telephone.

853
00:47:22,400 --> 00:47:24,720
Maybe you played this in elementary school.

854
00:47:24,720 --> 00:47:25,880
As you pass the message along,

855
00:47:25,880 --> 00:47:27,720
it gets more and more garbled, right?

856
00:47:29,440 --> 00:47:31,440
I actually want to try this now with four people

857
00:47:31,440 --> 00:47:33,400
and see how garbled it gets, come here.

858
00:47:36,800 --> 00:47:38,760
Dinner's in an hour and a half.

859
00:47:39,600 --> 00:47:41,160
How much can I drink?

860
00:47:41,160 --> 00:47:42,000
Hmm?

861
00:47:42,000 --> 00:47:42,840
How much can I drink?

862
00:47:42,840 --> 00:47:44,160
Go ahead, pass it on.

863
00:47:55,760 --> 00:47:57,360
All right, what message did you hear?

864
00:47:57,360 --> 00:47:59,640
I got dinner is in the hours.

865
00:47:59,640 --> 00:48:02,800
Huh, I said dinner is in an hour and a half.

866
00:48:02,800 --> 00:48:05,360
Yeah, the funny thing is the air itself is too good.

867
00:48:06,200 --> 00:48:07,040
Too good.

868
00:48:08,440 --> 00:48:10,440
Maybe some trolls in the middle here.

869
00:48:11,400 --> 00:48:13,160
Yeah, yeah, all right, go sit down.

870
00:48:15,320 --> 00:48:18,360
So the important point here is that

871
00:48:18,360 --> 00:48:20,400
there's sort of a duality

872
00:48:20,400 --> 00:48:22,280
when you're playing the game of telephone,

873
00:48:22,280 --> 00:48:24,920
which is any information

874
00:48:24,920 --> 00:48:27,520
is either going to be perfectly conserved

875
00:48:27,520 --> 00:48:30,440
or it's going to be completely lost, right?

876
00:48:30,440 --> 00:48:34,680
So like, there are ways we could make the message

877
00:48:34,720 --> 00:48:37,240
perfectly conserved even though our hearing is imperfect.

878
00:48:37,240 --> 00:48:39,560
Like we could just repeat ourselves

879
00:48:39,560 --> 00:48:42,320
enough times that the damn message gets through

880
00:48:42,320 --> 00:48:43,800
at each single step, right?

881
00:48:45,480 --> 00:48:49,000
But absent that, if there's any loss

882
00:48:49,000 --> 00:48:51,360
as we pass the message through enough people,

883
00:48:51,360 --> 00:48:53,400
it's just going to be hopelessly garbled.

884
00:48:54,320 --> 00:48:57,680
And that's exactly what the telephone theorem says.

885
00:48:57,680 --> 00:49:01,360
Basically, we think about how much information

886
00:49:01,360 --> 00:49:04,400
each of the messages gives us about the original

887
00:49:07,320 --> 00:49:09,360
in an information theoretic sense.

888
00:49:09,360 --> 00:49:11,280
So we're looking at mutual information

889
00:49:12,320 --> 00:49:13,920
and this has to go down.

890
00:49:16,000 --> 00:49:18,680
Eventually it will approach a limit

891
00:49:18,680 --> 00:49:21,840
because mutual information is non-negative.

892
00:49:21,840 --> 00:49:24,160
So it has to approach a limit at some point.

893
00:49:25,120 --> 00:49:28,800
And once it's arbitrarily close to that limit,

894
00:49:28,800 --> 00:49:30,920
that means the information is arbitrarily

895
00:49:30,920 --> 00:49:33,000
perfectly conserved from step to step.

896
00:49:36,080 --> 00:49:40,280
So the English language version of this

897
00:49:40,280 --> 00:49:43,520
is the only information conserved

898
00:49:43,520 --> 00:49:47,560
over a long distance in our graph

899
00:49:47,560 --> 00:49:49,880
is exactly the information

900
00:49:49,880 --> 00:49:52,880
which in the limit is perfectly conserved.

901
00:49:52,880 --> 00:49:55,240
So we may lose some of it at first,

902
00:49:55,240 --> 00:49:56,960
but eventually we have to stop losing

903
00:49:57,000 --> 00:49:59,760
and whatever's left has to be conserved.

904
00:49:59,760 --> 00:50:00,600
Make sense?

905
00:50:00,600 --> 00:50:01,760
It can be zero.

906
00:50:01,760 --> 00:50:03,280
It can absolutely be zero.

907
00:50:03,280 --> 00:50:05,240
Oh yeah, that is correct.

908
00:50:05,240 --> 00:50:06,760
It's longer than zero, I feel like.

909
00:50:06,760 --> 00:50:08,320
Yes.

910
00:50:08,320 --> 00:50:09,600
It is often zero.

911
00:50:09,600 --> 00:50:11,160
Yeah, it's bounded below.

912
00:50:11,160 --> 00:50:13,520
So you know that it's going to be, it's decreasing.

913
00:50:13,520 --> 00:50:14,920
So you know it's going to converge.

914
00:50:14,920 --> 00:50:16,400
No such thing as negative.

915
00:50:16,400 --> 00:50:17,600
Yeah, you know it's going to converge,

916
00:50:17,600 --> 00:50:19,320
but you don't know where.

917
00:50:19,320 --> 00:50:21,560
All right, so that's the telephone theorem.

918
00:50:22,560 --> 00:50:26,360
A few problems with the telephone theorem.

919
00:50:27,520 --> 00:50:31,720
First of all, these messages are just very high dimensional.

920
00:50:31,720 --> 00:50:33,240
These Markov blankets,

921
00:50:33,240 --> 00:50:35,760
so just generally hard to work with,

922
00:50:35,760 --> 00:50:38,240
you know, algorithmically or whatever.

923
00:50:38,240 --> 00:50:41,240
Second, exactly which information is conserved

924
00:50:41,240 --> 00:50:43,960
depends on which sequence of Markov blankets we take.

925
00:50:43,960 --> 00:50:45,800
So if I'm thinking about information

926
00:50:45,800 --> 00:50:47,800
propagating from the stove to the fridge,

927
00:50:47,800 --> 00:50:50,000
that's going to be potentially very different

928
00:50:50,000 --> 00:50:52,080
from information propagating from me to Rob

929
00:50:52,080 --> 00:50:54,480
and different conserved quantities will apply.

930
00:50:56,680 --> 00:50:59,400
Oh, I should explicitly write the formula

931
00:50:59,400 --> 00:51:00,960
for perfect conservation.

932
00:51:00,960 --> 00:51:01,800
Okay.

933
00:51:19,680 --> 00:51:24,400
So these are the perfectly conserved quantities

934
00:51:24,400 --> 00:51:27,000
which carry our information in the limit.

935
00:51:27,440 --> 00:51:31,880
So they are just straightforward functions

936
00:51:31,880 --> 00:51:34,800
of each Markov blanket.

937
00:51:36,760 --> 00:51:37,600
Okay.

938
00:51:38,520 --> 00:51:41,800
So the way we can get around this issue

939
00:51:41,800 --> 00:51:44,320
with like having different Markov blankets

940
00:51:44,320 --> 00:51:47,960
and also just get a much more elegant model in general

941
00:51:47,960 --> 00:51:52,960
is to think about natural abstractions

942
00:51:54,000 --> 00:51:56,280
instead in terms of redundancy.

943
00:51:56,280 --> 00:52:00,880
So part of the thing here is if the information

944
00:52:00,880 --> 00:52:03,000
is in each of the messages in the limits,

945
00:52:03,000 --> 00:52:06,760
like it's in mn, it's in mn plus one, it's in mn plus two,

946
00:52:06,760 --> 00:52:09,520
that means it's extremely redundant, right?

947
00:52:09,520 --> 00:52:12,720
There's lots of separate sets of variables in the model

948
00:52:12,720 --> 00:52:15,320
and we can back out the information exactly

949
00:52:15,320 --> 00:52:17,560
from any of those variables.

950
00:52:17,560 --> 00:52:21,440
So if we just like forget the values of some variables

951
00:52:21,440 --> 00:52:25,560
and then regenerate, then we must get the same value back

952
00:52:25,560 --> 00:52:27,600
because like we can pull it out of that constraint.

953
00:52:27,600 --> 00:52:30,480
Like if I forget mn plus one, that's fine.

954
00:52:30,480 --> 00:52:35,480
I can get the relevant information back by looking at mn.

955
00:52:35,560 --> 00:52:37,600
And this is exactly the same thing we were talking about

956
00:52:37,600 --> 00:52:39,280
with this coconut cup,

957
00:52:39,280 --> 00:52:41,360
where like if I hide it behind my back,

958
00:52:41,360 --> 00:52:42,720
you still know what it looks like

959
00:52:42,720 --> 00:52:44,800
because object permanence and all that, right?

960
00:52:44,800 --> 00:52:47,680
The information that's conserved here

961
00:52:47,680 --> 00:52:50,560
is exactly like whatever you can figure out

962
00:52:50,560 --> 00:52:53,560
about the mug behind my back from having looked at it before.

963
00:52:54,560 --> 00:52:56,560
So to formalize that,

964
00:52:58,560 --> 00:53:02,560
we'll take same causal graph as before,

965
00:53:04,560 --> 00:53:06,560
which is not actually gonna be the same

966
00:53:06,560 --> 00:53:08,560
because I'm not taking the time to copy it that carefully,

967
00:53:08,560 --> 00:53:11,560
but you get the idea.

968
00:53:12,560 --> 00:53:15,560
And we're just gonna imagine a process

969
00:53:15,560 --> 00:53:19,560
where we forget the value of one variable

970
00:53:19,560 --> 00:53:22,560
and then we resample it conditioned

971
00:53:22,560 --> 00:53:24,560
on all of its neighbors.

972
00:53:28,560 --> 00:53:30,560
So this would be equivalent

973
00:53:30,560 --> 00:53:33,560
to like taking the coconut cup and copying it,

974
00:53:33,560 --> 00:53:35,560
but we're not gonna do that.

975
00:53:35,560 --> 00:53:37,560
We're just gonna copy it.

976
00:53:37,560 --> 00:53:39,560
So this would be equivalent

977
00:53:39,560 --> 00:53:42,560
to like taking the coconut mug

978
00:53:42,560 --> 00:53:47,560
and deleting coconut mug at right now from my model

979
00:53:47,560 --> 00:53:52,560
and then resampling what I think the coconut mug was like

980
00:53:52,560 --> 00:53:54,560
based on what I know of it from before

981
00:53:54,560 --> 00:53:55,560
and what I know of it after.

982
00:53:55,560 --> 00:53:57,560
Make sense?

983
00:53:57,560 --> 00:53:59,560
And then we're gonna repeat this.

984
00:53:59,560 --> 00:54:02,560
We're gonna do it over and over again,

985
00:54:02,560 --> 00:54:05,560
resampling all of the different variables.

986
00:54:05,560 --> 00:54:10,560
Sometimes we'll double resample over and over again

987
00:54:11,560 --> 00:54:14,560
until this whole process converges.

988
00:54:17,560 --> 00:54:21,560
If you've done Markov chain Monte Carlo before,

989
00:54:21,560 --> 00:54:24,560
this is exactly the standard method.

990
00:54:26,560 --> 00:54:31,560
Fun fact, as the model gets large,

991
00:54:31,560 --> 00:54:33,560
it no longer converges

992
00:54:33,560 --> 00:54:36,560
to just like a trivial stationary distribution.

993
00:54:36,560 --> 00:54:38,560
If the model is large

994
00:54:40,560 --> 00:54:43,560
or if we have like conserved quantities like this,

995
00:54:43,560 --> 00:54:45,560
these two go together,

996
00:54:45,560 --> 00:54:48,560
then these sorts of quantities

997
00:54:48,560 --> 00:54:51,560
will be conserved by the resampling process.

998
00:54:52,560 --> 00:54:54,560
In fact, that's all that will be conserved

999
00:54:54,560 --> 00:54:56,560
by the resampling process.

1000
00:54:57,560 --> 00:55:01,560
So once we take this process to convergence,

1001
00:55:01,560 --> 00:55:03,560
we resample for long enough,

1002
00:55:05,560 --> 00:55:09,560
everything will sort of smooth out to our prior distribution

1003
00:55:09,560 --> 00:55:14,560
except that we'll have these guys left over.

1004
00:55:16,560 --> 00:55:17,560
Okay?

1005
00:55:18,560 --> 00:55:19,560
What you're saying is

1006
00:55:20,560 --> 00:55:23,560
there's like crazy causal structure in the world.

1007
00:55:24,560 --> 00:55:28,560
And information probably in this crazy way

1008
00:55:28,560 --> 00:55:30,560
comes information at last.

1009
00:55:30,560 --> 00:55:32,560
It's very difficult to take a track of

1010
00:55:33,560 --> 00:55:36,560
what's there, but there's something that's not lost.

1011
00:55:36,560 --> 00:55:38,560
There's something that's not lost and it's not,

1012
00:55:38,560 --> 00:55:40,560
so it's sort of like not ever lost.

1013
00:55:42,560 --> 00:55:44,560
There's like a qualitative difference

1014
00:55:44,560 --> 00:55:46,560
compared to the things that like

1015
00:55:48,560 --> 00:55:49,560
fritter away.

1016
00:55:49,560 --> 00:55:50,560
Yep.

1017
00:55:50,560 --> 00:55:51,560
And it's not lost.

1018
00:55:51,560 --> 00:55:54,560
There's two different processes in which it's not lost.

1019
00:55:54,560 --> 00:55:56,560
One is just like kind of,

1020
00:55:56,560 --> 00:55:58,560
you could think of it as moving through space.

1021
00:55:58,560 --> 00:55:59,560
Yep.

1022
00:55:59,560 --> 00:56:00,560
Or through time.

1023
00:56:00,560 --> 00:56:01,560
Of course, there's space-time in general.

1024
00:56:01,560 --> 00:56:02,560
Yep.

1025
00:56:02,560 --> 00:56:03,560
Movement.

1026
00:56:03,560 --> 00:56:05,560
I guess it's always through time, right?

1027
00:56:05,560 --> 00:56:07,560
It could be time or space or both.

1028
00:56:07,560 --> 00:56:08,560
Either way.

1029
00:56:09,560 --> 00:56:11,560
And then there's this other process

1030
00:56:11,560 --> 00:56:14,560
which is like a resample.

1031
00:56:14,560 --> 00:56:15,560
Yep.

1032
00:56:15,560 --> 00:56:16,560
Resampling.

1033
00:56:16,560 --> 00:56:19,560
These are two processes through which

1034
00:56:20,560 --> 00:56:23,560
the thing that's not lost is in fact not lost.

1035
00:56:23,560 --> 00:56:24,560
Yep, exactly.

1036
00:56:25,560 --> 00:56:28,560
So what you end up with at the end of this,

1037
00:56:30,560 --> 00:56:33,560
you still have the same graph structure.

1038
00:56:34,560 --> 00:56:35,560
So you haven't,

1039
00:56:36,560 --> 00:56:39,560
you've simplified what's in the data structure,

1040
00:56:39,560 --> 00:56:41,560
but you haven't simplified the data structure, right?

1041
00:56:41,560 --> 00:56:42,560
Yes.

1042
00:56:42,560 --> 00:56:44,560
So let me write out a bit

1043
00:56:45,560 --> 00:56:47,560
of what's in the data structure.

1044
00:56:49,560 --> 00:56:53,560
So we'll say this original graph,

1045
00:56:55,560 --> 00:56:57,560
the distribution was p of x,

1046
00:56:57,560 --> 00:57:01,560
and then that factors according to the graph structure.

1047
00:57:02,560 --> 00:57:03,560
Okay.

1048
00:57:05,560 --> 00:57:07,560
Everybody good with that?

1049
00:57:07,560 --> 00:57:10,560
I didn't actually talk about factorization earlier.

1050
00:57:12,560 --> 00:57:13,560
Okay.

1051
00:57:13,560 --> 00:57:16,560
When you have a probability distribution

1052
00:57:16,560 --> 00:57:18,560
on a causal DAG,

1053
00:57:19,560 --> 00:57:23,560
the key fact about the probability distribution itself

1054
00:57:24,560 --> 00:57:27,560
is that the distribution factors

1055
00:57:27,560 --> 00:57:30,560
we say it factors over the graph,

1056
00:57:30,560 --> 00:57:32,560
meaning that we can write it

1057
00:57:32,560 --> 00:57:35,560
in terms of the probability of each thing

1058
00:57:35,560 --> 00:57:37,560
given its parents in the graph.

1059
00:57:37,560 --> 00:57:40,560
So like this thing given its parent,

1060
00:57:40,560 --> 00:57:43,560
and then we take a giant product of all those,

1061
00:57:43,560 --> 00:57:46,560
and that's the overall joint distribution.

1062
00:57:47,560 --> 00:57:48,560
All right.

1063
00:57:48,560 --> 00:57:49,560
So down here,

1064
00:57:50,560 --> 00:57:53,560
we've now introduced a couple of different x's.

1065
00:57:53,560 --> 00:57:55,560
We have some,

1066
00:57:56,560 --> 00:57:57,560
I'll call it,

1067
00:57:59,560 --> 00:58:02,560
call it x is just like the same original thing.

1068
00:58:02,560 --> 00:58:05,560
It was like whatever actual stuff is out there.

1069
00:58:05,560 --> 00:58:08,560
And then we have what I'll call x infinity,

1070
00:58:09,560 --> 00:58:13,560
which is a totally different set of values

1071
00:58:14,560 --> 00:58:17,560
generated by running this resampling process

1072
00:58:17,560 --> 00:58:19,560
with x as our initial condition.

1073
00:58:20,560 --> 00:58:21,560
Okay.

1074
00:58:21,560 --> 00:58:23,560
And the key thing here,

1075
00:58:25,560 --> 00:58:29,560
if I look at the distribution of x given x infinity,

1076
00:58:33,560 --> 00:58:35,560
this guy is still going to have

1077
00:58:35,560 --> 00:58:38,560
all of the information about conserved quantities,

1078
00:58:38,560 --> 00:58:40,560
but it's going to have nothing else,

1079
00:58:40,560 --> 00:58:43,560
which means this distribution,

1080
00:58:44,560 --> 00:58:46,560
within this distribution,

1081
00:58:46,560 --> 00:58:49,560
mutual information is always going to go to zero.

1082
00:58:49,560 --> 00:58:52,560
This distribution is always going to go to zero

1083
00:58:52,560 --> 00:58:54,560
over a long distance.

1084
00:58:56,560 --> 00:58:58,560
This distribution right here.

1085
00:59:08,560 --> 00:59:09,560
Hang on.

1086
00:59:09,560 --> 00:59:12,560
Let me, let me spell that out a bit more.

1087
00:59:12,560 --> 00:59:13,560
So,

1088
00:59:15,560 --> 00:59:17,560
hold on, hold on.

1089
00:59:17,560 --> 00:59:19,560
This distribution, first of all,

1090
00:59:19,560 --> 00:59:22,560
it turns out to factor on the same graph.

1091
00:59:22,560 --> 00:59:25,560
So p of x given x infinity

1092
00:59:25,560 --> 00:59:28,560
will be equal to

1093
00:59:30,560 --> 00:59:31,560
product on i

1094
00:59:33,560 --> 00:59:35,560
p of x i

1095
00:59:36,560 --> 00:59:38,560
given x parents of i

1096
00:59:40,560 --> 00:59:42,560
and x infinity.

1097
00:59:43,560 --> 00:59:44,560
So,

1098
00:59:45,560 --> 00:59:48,560
all the graph structure is still conserved.

1099
00:59:48,560 --> 00:59:49,560
And now,

1100
00:59:49,560 --> 00:59:53,560
when we take our layers of Markov blankets

1101
00:59:53,560 --> 00:59:55,560
through that graph,

1102
00:59:57,560 --> 00:59:59,560
what we're going to use,

1103
00:59:59,560 --> 01:00:01,560
rather than using this distribution,

1104
01:00:01,560 --> 01:00:03,560
the unconditional distribution,

1105
01:00:03,560 --> 01:00:07,560
we're using the distribution conditional on x infinity.

1106
01:00:07,560 --> 01:00:09,560
So we're effectively conditioning

1107
01:00:09,560 --> 01:00:11,560
on these conserved quantities.

1108
01:00:12,560 --> 01:00:14,560
And given those conserved quantities,

1109
01:00:14,560 --> 01:00:17,560
our mutual information graph

1110
01:00:17,560 --> 01:00:20,560
will always look like this.

1111
01:00:21,560 --> 01:00:23,560
It's always going to

1112
01:00:23,560 --> 01:00:26,560
drop down arbitrarily close to zero in the limit.

1113
01:00:30,560 --> 01:00:31,560
Exactly.

1114
01:00:40,560 --> 01:00:41,560
Yep.

1115
01:00:41,560 --> 01:00:42,560
Exactly.

1116
01:00:43,560 --> 01:00:44,560
So,

1117
01:00:44,560 --> 01:00:46,560
conceptually,

1118
01:00:46,560 --> 01:00:48,560
a useful way to think about this

1119
01:00:48,560 --> 01:00:51,560
is you can sort of think of this x infinity

1120
01:00:51,560 --> 01:00:55,560
as capturing the abstract information from x.

1121
01:00:55,560 --> 01:00:58,560
So there's sort of this high level information in x infinity,

1122
01:00:58,560 --> 01:01:00,560
like all these values,

1123
01:01:00,560 --> 01:01:04,560
and condition on that high level information,

1124
01:01:05,560 --> 01:01:10,560
all interactions within this model are short range.

1125
01:01:11,560 --> 01:01:13,560
That high level information summarizes

1126
01:01:13,560 --> 01:01:15,560
all of the information

1127
01:01:15,560 --> 01:01:17,560
that propagates over long distances

1128
01:01:17,560 --> 01:01:19,560
anywhere in the model.

1129
01:01:19,560 --> 01:01:20,560
Make sense?

1130
01:01:22,560 --> 01:01:23,560
Now...

1131
01:01:28,560 --> 01:01:30,560
Yes, that's a great way to think of it.

1132
01:01:41,560 --> 01:01:43,560
Also a good way to think of it.

1133
01:01:51,560 --> 01:01:53,560
It is like high frequency

1134
01:01:53,560 --> 01:01:56,560
in the sense of distance in the graph,

1135
01:01:56,560 --> 01:02:00,560
which is often physically spatial, in fact.

1136
01:02:01,560 --> 01:02:02,560
This question is like,

1137
01:02:02,560 --> 01:02:03,560
if we really look,

1138
01:02:03,560 --> 01:02:05,560
will we find any signal?

1139
01:02:06,560 --> 01:02:08,560
Like, is anything really there?

1140
01:02:09,560 --> 01:02:10,560
What do you mean?

1141
01:02:12,560 --> 01:02:14,560
I mean, if you really look carefully,

1142
01:02:14,560 --> 01:02:17,560
we're going to find some signal with some noise, right?

1143
01:02:17,560 --> 01:02:18,560
Yep.

1144
01:02:18,560 --> 01:02:20,560
We're going to maybe find out

1145
01:02:20,560 --> 01:02:22,560
is the signal,

1146
01:02:22,560 --> 01:02:24,560
is there more than zero signal?

1147
01:02:24,560 --> 01:02:25,560
Really?

1148
01:02:25,560 --> 01:02:26,560
Like really,

1149
01:02:26,560 --> 01:02:28,560
when we get the real,

1150
01:02:28,560 --> 01:02:30,560
for real, is there anything like that?

1151
01:02:37,560 --> 01:02:39,560
It's surprisingly good at predicting things far away.

1152
01:02:50,560 --> 01:02:52,560
I'm still a little confused about

1153
01:02:52,560 --> 01:02:56,560
what x infinity looks like.

1154
01:02:56,560 --> 01:02:58,560
Like, I have a sense of like what,

1155
01:02:58,560 --> 01:02:59,560
that like this,

1156
01:02:59,560 --> 01:03:03,560
this causal graph represents the world,

1157
01:03:03,560 --> 01:03:04,560
as it is.

1158
01:03:04,560 --> 01:03:06,560
And x infinity is like very,

1159
01:03:06,560 --> 01:03:08,560
it's the exact same shape of thing.

1160
01:03:08,560 --> 01:03:12,560
And so it feels like it should be a world in a way.

1161
01:03:12,560 --> 01:03:13,560
It's like, what is that world?

1162
01:03:13,560 --> 01:03:14,560
So that was,

1163
01:03:14,560 --> 01:03:17,560
gets at something I was about to bring up next,

1164
01:03:17,560 --> 01:03:18,560
which is,

1165
01:03:18,560 --> 01:03:21,560
this isn't a very efficient representation.

1166
01:03:21,560 --> 01:03:23,560
This x infinity,

1167
01:03:23,560 --> 01:03:26,560
it's like a value for every single variable in the world.

1168
01:03:26,560 --> 01:03:29,560
That's like the part of the point of this is that

1169
01:03:29,560 --> 01:03:31,560
the only information we really need

1170
01:03:31,560 --> 01:03:32,560
is these conserved quantities.

1171
01:03:32,560 --> 01:03:35,560
So we should be able to collapse it down.

1172
01:03:38,560 --> 01:03:39,560
Yes.

1173
01:03:42,560 --> 01:03:44,560
So in particular,

1174
01:03:44,560 --> 01:03:47,560
what we'd expect is

1175
01:03:48,560 --> 01:03:52,560
p of x given x infinity

1176
01:03:52,560 --> 01:03:56,560
is equal to 1 over z

1177
01:03:56,560 --> 01:03:59,560
e to the lambda transpose

1178
01:03:59,560 --> 01:04:02,560
sum on i,

1179
01:04:02,560 --> 01:04:05,560
fi, xi,

1180
01:04:05,560 --> 01:04:08,560
x parents of i.

1181
01:04:12,560 --> 01:04:16,560
Lambda is a function of x infinity.

1182
01:04:17,560 --> 01:04:22,560
Times probability of x

1183
01:04:22,560 --> 01:04:26,560
given a fixed value of x infinity.

1184
01:04:28,560 --> 01:04:30,560
I call that x star.

1185
01:04:30,560 --> 01:04:31,560
All right,

1186
01:04:31,560 --> 01:04:33,560
let's talk about what that means real quick.

1187
01:04:33,560 --> 01:04:35,560
So where this is coming from

1188
01:04:35,560 --> 01:04:37,560
is the Koopman-Pittman-Darmois theorem,

1189
01:04:37,560 --> 01:04:39,560
the KPD.

1190
01:04:39,560 --> 01:04:43,560
The general idea of the KPD theorem

1191
01:04:43,560 --> 01:04:47,560
is anytime you have a summary statistic

1192
01:04:47,560 --> 01:04:51,560
that's much smaller than the thing it's summarizing.

1193
01:04:51,560 --> 01:04:55,560
So you can take all of the information in x

1194
01:04:55,560 --> 01:04:58,560
that's relevant to x infinity

1195
01:04:58,560 --> 01:05:01,560
and summarize it by these much lower dimensional constraints.

1196
01:05:01,560 --> 01:05:03,560
Anytime you have that,

1197
01:05:03,560 --> 01:05:07,560
it gives you this factorization, basically.

1198
01:05:07,560 --> 01:05:15,560
So it's saying that we have this exponential form

1199
01:05:15,560 --> 01:05:18,560
and essentially all of the abstract information

1200
01:05:18,560 --> 01:05:21,560
is in these sums right here.

1201
01:05:21,560 --> 01:05:24,560
We're not actually going to use this

1202
01:05:24,560 --> 01:05:25,560
for anything in particular.

1203
01:05:25,560 --> 01:05:27,560
I'm putting it up here mainly so that you know

1204
01:05:27,560 --> 01:05:30,560
that this whole thing can sort of be

1205
01:05:30,560 --> 01:05:33,560
translated into a particular way

1206
01:05:33,560 --> 01:05:35,560
of factorizing the distribution.

1207
01:05:35,560 --> 01:05:36,560
Adam.

1208
01:05:36,560 --> 01:05:38,560
It's a very superficial math question.

1209
01:05:38,560 --> 01:05:39,560
Yeah.

1210
01:05:39,560 --> 01:05:45,560
The form of that looks like a Boltzmann model,

1211
01:05:45,560 --> 01:05:47,560
like a model with latent variable.

1212
01:05:47,560 --> 01:05:48,560
Yep.

1213
01:05:48,560 --> 01:05:51,560
Is it not a coincidence?

1214
01:05:51,560 --> 01:05:54,560
I mean, it's an exponential form.

1215
01:05:54,560 --> 01:05:57,560
Like tons and tons of things are exponential forms

1216
01:05:57,560 --> 01:05:59,560
for broadly similar reasons.

1217
01:05:59,560 --> 01:06:02,560
Is there any summary statistic that can be represented

1218
01:06:02,560 --> 01:06:05,560
as an exponential form?

1219
01:06:05,560 --> 01:06:06,560
Yep.

1220
01:06:06,560 --> 01:06:07,560
Roughly speaking.

1221
01:06:07,560 --> 01:06:08,560
There's some terms and conditions there,

1222
01:06:08,560 --> 01:06:11,560
but they're pretty loose.

1223
01:06:11,560 --> 01:06:13,560
Does the summary statistic look like all the points

1224
01:06:13,560 --> 01:06:16,560
lie on a circumference of a circle

1225
01:06:16,560 --> 01:06:17,560
or something like that?

1226
01:06:17,560 --> 01:06:20,560
Mm-hmm.

1227
01:06:20,560 --> 01:06:23,560
I guess that wouldn't satisfy the condition.

1228
01:06:23,560 --> 01:06:27,560
Well, either it won't have a small summary statistic,

1229
01:06:27,560 --> 01:06:29,560
which is often what happens,

1230
01:06:29,560 --> 01:06:31,560
or if it does have a small summary statistic,

1231
01:06:31,560 --> 01:06:34,560
we'll be able to factor it like this.

1232
01:06:34,560 --> 01:06:36,560
For something on a circle,

1233
01:06:36,560 --> 01:06:38,560
the like make it a circle part

1234
01:06:38,560 --> 01:06:40,560
would mostly be done by the second term.

1235
01:06:40,560 --> 01:06:43,560
Like the second term.

1236
01:06:43,560 --> 01:06:46,560
What the second term is saying is

1237
01:06:46,560 --> 01:06:51,560
there's some sort of like base distribution

1238
01:06:51,560 --> 01:06:53,560
that is just like the distribution

1239
01:06:53,560 --> 01:06:55,560
for an arbitrary value of x infinity,

1240
01:06:55,560 --> 01:06:58,560
and then everything else is like an adjustment of that.

1241
01:06:58,560 --> 01:07:01,560
Oh, okay.

1242
01:07:01,560 --> 01:07:02,560
Yeah.

1243
01:07:02,560 --> 01:07:04,560
That's what would restrict it to a circle probably.

1244
01:07:04,560 --> 01:07:06,560
What's the importance of this?

1245
01:07:06,560 --> 01:07:08,560
I know you said you're not going to do it.

1246
01:07:08,560 --> 01:07:09,560
Yeah.

1247
01:07:09,560 --> 01:07:10,560
In general, what's that?

1248
01:07:10,560 --> 01:07:12,560
What's the importance of this?

1249
01:07:12,560 --> 01:07:14,560
So mostly this is important

1250
01:07:14,560 --> 01:07:16,560
if you want to like actually start doing math

1251
01:07:16,560 --> 01:07:18,560
with this thing.

1252
01:07:18,560 --> 01:07:20,560
So like I said, this x infinity,

1253
01:07:20,560 --> 01:07:22,560
very high dimensional, not convenient to work with.

1254
01:07:22,560 --> 01:07:24,560
If you want to be writing algorithms

1255
01:07:24,560 --> 01:07:27,560
to compute these quantities,

1256
01:07:27,560 --> 01:07:31,560
then this representation gives you something much nicer.

1257
01:07:31,560 --> 01:07:36,560
It's not particularly high dimensional

1258
01:07:36,560 --> 01:07:38,560
to find these functions.

1259
01:07:38,560 --> 01:07:41,560
The sum itself is just a sum.

1260
01:07:41,560 --> 01:07:44,560
So it's generally much more convenient to work with.

1261
01:07:44,560 --> 01:07:47,560
Yeah.

1262
01:07:47,560 --> 01:07:48,560
Yeah.

1263
01:07:58,560 --> 01:07:59,560
Yep.

1264
01:08:08,560 --> 01:08:09,560
Yep.

1265
01:08:17,560 --> 01:08:18,560
Exactly.

1266
01:08:18,560 --> 01:08:20,560
Another way to think of it is,

1267
01:08:20,560 --> 01:08:21,560
it's not quite this exact expression,

1268
01:08:21,560 --> 01:08:24,560
but you can use it to get a local global factorization.

1269
01:08:24,560 --> 01:08:26,560
So you can just like directly factor apart

1270
01:08:26,560 --> 01:08:31,560
the local interactions and the large scale abstract stuff.

1271
01:08:36,560 --> 01:08:38,560
All right.

1272
01:08:38,560 --> 01:08:42,560
So that was two of our three points of view.

1273
01:08:42,560 --> 01:08:44,560
Are we ready for number three?

1274
01:08:44,560 --> 01:08:48,560
Any more questions on these guys?

1275
01:08:48,560 --> 01:08:49,560
Okay.

1276
01:08:49,560 --> 01:08:54,560
Number three starts out very different.

1277
01:08:56,560 --> 01:08:59,560
Number three says I have two random variables,

1278
01:08:59,560 --> 01:09:00,560
A and B,

1279
01:09:00,560 --> 01:09:05,560
and I have their distribution, P of AB.

1280
01:09:05,560 --> 01:09:08,560
And we'll assume that the distribution is not,

1281
01:09:08,560 --> 01:09:11,560
they're not independent.

1282
01:09:11,560 --> 01:09:16,560
And we want to figure out some latent variable C,

1283
01:09:16,560 --> 01:09:20,560
which explains the dependence between them.

1284
01:09:20,560 --> 01:09:27,560
So we want to have P of ABC

1285
01:09:27,560 --> 01:09:34,560
equal to P of C times P of A given C

1286
01:09:34,560 --> 01:09:38,560
times P of B given C.

1287
01:09:38,560 --> 01:09:44,560
That's the factorization corresponding to this graph.

1288
01:09:44,560 --> 01:09:53,560
And we also want someone see P of ABC

1289
01:09:53,560 --> 01:09:59,560
equal to our original P of AB.

1290
01:09:59,560 --> 01:10:02,560
So we're trying to discover a latent variable.

1291
01:10:02,560 --> 01:10:04,560
This is latent variable discovery.

1292
01:10:04,560 --> 01:10:07,560
We're backing out a latent variable

1293
01:10:07,560 --> 01:10:09,560
that explains what's going on in the world.

1294
01:10:09,560 --> 01:10:11,560
Make sense?

1295
01:10:11,560 --> 01:10:14,560
And the question is,

1296
01:10:14,560 --> 01:10:19,560
is there some most canonical latent variable?

1297
01:10:19,560 --> 01:10:21,560
Some latent variable that is like

1298
01:10:21,560 --> 01:10:24,560
the minimum latent variable or the latent variable,

1299
01:10:24,560 --> 01:10:30,560
which like has to be there.

1300
01:10:30,560 --> 01:10:32,560
Something along those lines.

1301
01:10:32,560 --> 01:10:35,560
Something that we'd expect anything

1302
01:10:35,560 --> 01:10:40,560
that explains the relationship between these two variables,

1303
01:10:40,560 --> 01:10:42,560
anything that explains that relationship

1304
01:10:42,560 --> 01:10:46,560
has to have something like C sort of baked into it.

1305
01:10:46,560 --> 01:10:49,560
So part of the intuition here is if you're thinking about,

1306
01:10:49,560 --> 01:10:54,560
say, the step from classical physics to quantum mechanics,

1307
01:10:54,560 --> 01:11:01,560
we knew that all the stuff that worked in classical physics

1308
01:11:01,560 --> 01:11:05,560
still had to work when we got to quantum mechanics.

1309
01:11:05,560 --> 01:11:08,560
Because of that, we expected that a lot of the structure

1310
01:11:08,560 --> 01:11:10,560
still had to be there.

1311
01:11:10,560 --> 01:11:13,560
There still had to be some way to take quantum mechanics

1312
01:11:13,560 --> 01:11:17,560
and back out from it all that classical structure

1313
01:11:17,560 --> 01:11:19,560
that we had before.

1314
01:11:19,560 --> 01:11:21,560
We have the classical limit.

1315
01:11:21,560 --> 01:11:26,560
Exactly.

1316
01:11:26,560 --> 01:11:28,560
And that's what we're imagining here

1317
01:11:28,560 --> 01:11:33,560
is we want some C that it's the most fundamental thing

1318
01:11:33,560 --> 01:11:36,560
of the things we've observed so far.

1319
01:11:36,560 --> 01:11:38,560
Any new thing that we might discover

1320
01:11:38,560 --> 01:11:43,560
had better still reduce to that in the appropriate situations.

1321
01:11:46,560 --> 01:11:48,560
So the way we're going to formulate that

1322
01:11:48,560 --> 01:11:56,560
is we want C star such that

1323
01:11:56,560 --> 01:12:03,560
C star does the thing we want.

1324
01:12:03,560 --> 01:12:14,560
And for any C, which does the thing we want,

1325
01:12:14,560 --> 01:12:30,560
C, A, B, we have C, A, B, C star.

1326
01:12:30,560 --> 01:12:32,560
This is kind of a weird one at first glance.

1327
01:12:32,560 --> 01:12:36,560
Intuitively, what it's saying is that any other C

1328
01:12:36,560 --> 01:12:40,560
we could pick that explains the relationship between these two

1329
01:12:40,560 --> 01:12:44,560
has to also contain whatever information is in C star

1330
01:12:44,560 --> 01:12:45,560
that's relevant to those two.

1331
01:12:54,560 --> 01:12:59,560
It looks like a universal property.

1332
01:12:59,560 --> 01:13:00,560
Yes.

1333
01:13:00,560 --> 01:13:04,560
It is very much a category theory flavored thing.

1334
01:13:04,560 --> 01:13:09,560
Is this on the left hand side, A and C on the bottom left?

1335
01:13:09,560 --> 01:13:11,560
Does that be A and B?

1336
01:13:11,560 --> 01:13:12,560
Sorry, where?

1337
01:13:12,560 --> 01:13:13,560
Right here.

1338
01:13:13,560 --> 01:13:16,560
Oh, that should be B. Thank you.

1339
01:13:16,560 --> 01:13:17,560
There we go.

1340
01:13:17,560 --> 01:13:18,560
Good call.

1341
01:13:18,560 --> 01:13:19,560
All right.

1342
01:13:19,560 --> 01:13:24,560
So the result here is in general, this doesn't exist.

1343
01:13:24,560 --> 01:13:27,560
In general, there is no such C star.

1344
01:13:27,560 --> 01:13:32,560
The one situation in which it does exist is when?

1345
01:13:32,560 --> 01:13:33,560
There is stuff.

1346
01:13:33,560 --> 01:13:34,560
There is stuff, Alex.

1347
01:13:34,560 --> 01:13:35,560
U exists.

1348
01:13:35,560 --> 01:13:37,560
B stuff.

1349
01:13:37,560 --> 01:13:43,560
The one situation where it does exist is when we have some FA of A

1350
01:13:43,560 --> 01:13:48,560
equal to FB of B with probability 1.

1351
01:13:48,560 --> 01:13:51,560
So exactly the same sort of condition before.

1352
01:13:51,560 --> 01:13:55,560
We have some function we can compute over some of the variables,

1353
01:13:55,560 --> 01:14:00,560
which is equal to some function over the other variables with probability 1.

1354
01:14:00,560 --> 01:14:05,560
That is exactly the condition in which we can have this sort of universal thing.

1355
01:14:05,560 --> 01:14:10,560
And then we just have C star equal to those guys.

1356
01:14:15,560 --> 01:14:17,560
In that case, don't you need something stronger,

1357
01:14:17,560 --> 01:14:22,560
like everything that could be in any such F?

1358
01:14:26,560 --> 01:14:27,560
If you had such a F.

1359
01:14:27,560 --> 01:14:28,560
Yes.

1360
01:14:28,560 --> 01:14:30,560
You do have to take the most general F.

1361
01:14:30,560 --> 01:14:31,560
That is a constraint here.

1362
01:14:31,560 --> 01:14:35,560
You could have a function like F, which is always your time 0.

1363
01:14:35,560 --> 01:14:36,560
Yes.

1364
01:14:36,560 --> 01:14:37,560
And it's like trivially.

1365
01:14:37,560 --> 01:14:38,560
Yeah.

1366
01:14:38,560 --> 01:14:45,560
And again, this isn't always possible for all A's and B's.

1367
01:14:45,560 --> 01:14:49,560
Basically, all of the information that's in common between A and B

1368
01:14:49,560 --> 01:14:52,560
has to be carried by these F's in order for it to work.

1369
01:14:52,560 --> 01:14:53,560
That's important.

1370
01:14:54,560 --> 01:14:58,560
If it was a kind of universal, like an actual universal property or something like that,

1371
01:14:58,560 --> 01:15:05,560
the last graph would be C, go through C star to influence A and B.

1372
01:15:05,560 --> 01:15:06,560
Yes.

1373
01:15:06,560 --> 01:15:07,560
Why?

1374
01:15:07,560 --> 01:15:08,560
Which is fine.

1375
01:15:08,560 --> 01:15:10,560
I think we can actually just draw it that way.

1376
01:15:10,560 --> 01:15:11,560
It's still a graph though.

1377
01:15:11,560 --> 01:15:13,560
I think that ends up being equivalent.

1378
01:15:13,560 --> 01:15:15,560
Yeah, that does end up being equivalent.

1379
01:15:15,560 --> 01:15:16,560
Why?

1380
01:15:16,560 --> 01:15:19,560
With causal graphs in general,

1381
01:15:20,560 --> 01:15:24,560
the small ones you can reorder in various ways.

1382
01:15:24,560 --> 01:15:37,560
For instance, you have x, y, z is equivalent to z, y, x.

1383
01:15:37,560 --> 01:15:42,560
It's also equivalent to, let's see if I can get the direction right.

1384
01:15:42,560 --> 01:15:47,560
I think it's y, z, and on the other side, x.

1385
01:15:47,560 --> 01:15:50,560
In generality, you can just mirror a closer graph?

1386
01:15:50,560 --> 01:15:54,560
This is definitely not a thing you can do with causal graphs in general.

1387
01:15:54,560 --> 01:16:00,560
It's just the small ones just have some accidental properties, basically.

1388
01:16:00,560 --> 01:16:03,560
These guys sort of accidentally end up equal to each other.

1389
01:16:03,560 --> 01:16:06,560
In the real world, these have reverse causality just like that?

1390
01:16:06,560 --> 01:16:07,560
Yes.

1391
01:16:07,560 --> 01:16:13,560
You definitely, in general, as the graph gets bigger,

1392
01:16:13,560 --> 01:16:15,560
a lot more of the structure is locked in.

1393
01:16:15,560 --> 01:16:19,560
So I thought there was something interesting there about the theorem.

1394
01:16:19,560 --> 01:16:22,560
No, no.

1395
01:16:22,560 --> 01:16:27,560
So this is actually a slightly older version of this theorem.

1396
01:16:27,560 --> 01:16:30,560
I'm going to now state a stronger one.

1397
01:16:30,560 --> 01:16:40,560
So going back to our thing about redundancy,

1398
01:16:40,560 --> 01:16:44,560
a lot of this redundancy stuff didn't really necessarily need

1399
01:16:44,560 --> 01:16:45,560
to use the causal structure.

1400
01:16:45,560 --> 01:16:47,560
The part about far-awayness did.

1401
01:16:47,560 --> 01:16:52,560
In order to say that variables far away are independent,

1402
01:16:52,560 --> 01:16:56,560
conditional on x infinity, we need to have this causal structure

1403
01:16:56,560 --> 01:16:57,560
to talk about far-awayness.

1404
01:16:57,560 --> 01:17:02,560
But this process of dropping and resampling variables

1405
01:17:02,560 --> 01:17:05,560
in order to keep around the redundant information,

1406
01:17:05,560 --> 01:17:07,560
that we can do even without a causal structure.

1407
01:17:07,560 --> 01:17:10,560
That we can do in any distribution.

1408
01:17:10,560 --> 01:17:13,560
So an interesting question.

1409
01:17:13,560 --> 01:17:17,560
Is there some sort of property like this,

1410
01:17:17,560 --> 01:17:24,560
which we can get out of that resampling process in general?

1411
01:17:24,560 --> 01:17:32,560
And I'm pretty sure there is.

1412
01:17:32,560 --> 01:17:38,560
The claim is, so we have some probability distribution

1413
01:17:38,560 --> 01:17:46,560
on a bunch of x's.

1414
01:17:46,560 --> 01:17:54,560
And then we're going to do our resampling process.

1415
01:17:54,560 --> 01:18:00,560
Resampling gives us an x infinity, like before.

1416
01:18:00,560 --> 01:18:12,560
And now I claim that if we have some g of x,

1417
01:18:12,560 --> 01:18:16,560
which is finite, that's important.

1418
01:18:16,560 --> 01:18:20,560
If it has infinite entropy,

1419
01:18:20,560 --> 01:18:24,560
then we're not going to be able to use this decreasing

1420
01:18:24,560 --> 01:18:27,560
mutual information argument.

1421
01:18:27,560 --> 01:18:30,560
So we need it to have finite entropy.

1422
01:18:30,560 --> 01:18:35,560
And I'm going to talk about the mutual information

1423
01:18:35,560 --> 01:18:44,560
between g of x and x's greater than some k,

1424
01:18:44,560 --> 01:18:48,560
given x infinity.

1425
01:18:48,560 --> 01:18:52,560
So we'll take the first k of the x's,

1426
01:18:52,560 --> 01:18:55,560
forget about those, and then look at mutual information

1427
01:18:55,560 --> 01:18:58,560
between g and the rest of them.

1428
01:18:58,560 --> 01:19:01,560
And g takes all of the x's?

1429
01:19:01,560 --> 01:19:02,560
Yep.

1430
01:19:02,560 --> 01:19:05,560
The important thing is just it's not,

1431
01:19:05,560 --> 01:19:07,560
so it can't just spit all of the x's back,

1432
01:19:07,560 --> 01:19:10,560
because it has to be small.

1433
01:19:10,560 --> 01:19:19,560
So we're going to take limit as n goes to infinity.

1434
01:19:19,560 --> 01:19:22,560
So the sort of argument that we're going to make

1435
01:19:22,560 --> 01:19:27,560
is we're going to look at the mutual information

1436
01:19:27,560 --> 01:19:32,560
between these two guys, and it's going to be going down.

1437
01:19:32,560 --> 01:19:35,560
Right?

1438
01:19:35,560 --> 01:19:41,560
We need this mutual information to be finite,

1439
01:19:41,560 --> 01:19:45,560
because otherwise it could just keep going down,

1440
01:19:45,560 --> 01:19:50,560
keep going down indefinitely without reaching a limit.

1441
01:19:51,560 --> 01:19:55,560
And the easy way to force your mutual information

1442
01:19:55,560 --> 01:19:57,560
to be finite initially is to say that this guy just

1443
01:19:57,560 --> 01:19:59,560
has some finite entropy.

1444
01:20:06,560 --> 01:20:12,560
And the claim is that given x infinity, for any g of x

1445
01:20:12,560 --> 01:20:15,560
we choose, this is going to go to 0.

1446
01:20:21,560 --> 01:20:26,560
All the x's, mutual information between g of x,

1447
01:20:26,560 --> 01:20:30,560
and all of the x's are after xk.

1448
01:20:30,560 --> 01:20:31,560
Yep.

1449
01:20:31,560 --> 01:20:35,560
Conditioned on x infinity, x infinity

1450
01:20:35,560 --> 01:20:38,560
being the distribution that we get,

1451
01:20:38,560 --> 01:20:42,560
or the value that we get after the sampling.

1452
01:20:42,560 --> 01:20:43,060
Yep.

1453
01:20:44,060 --> 01:20:48,060
Strange thing to think about.

1454
01:20:48,060 --> 01:20:51,060
Let's try an example.

1455
01:21:01,060 --> 01:21:02,060
There you go.

1456
01:21:02,060 --> 01:21:03,060
You got it.

1457
01:21:03,060 --> 01:21:10,060
So the idea here is basically any g of x

1458
01:21:10,060 --> 01:21:16,060
is basically any function of the x's that we can dream up,

1459
01:21:16,060 --> 01:21:20,060
as long as it has limited entropy,

1460
01:21:20,060 --> 01:21:25,060
is going to only have any mutual information

1461
01:21:25,060 --> 01:21:28,060
with a finite number of the x's.

1462
01:21:28,060 --> 01:21:31,060
Like it can't have lots of mutual information

1463
01:21:31,060 --> 01:21:36,060
with all of the x's, because if it did,

1464
01:21:36,060 --> 01:21:38,060
then that information would be very redundant,

1465
01:21:38,060 --> 01:21:40,060
and it would be captured in x infinity.

1466
01:21:43,060 --> 01:21:46,060
So once we condition on x infinity,

1467
01:21:46,060 --> 01:21:49,060
things can only have mutual information

1468
01:21:49,060 --> 01:21:52,060
with a limited number of the variables.

1469
01:21:55,060 --> 01:21:56,060
Make sense?

1470
01:21:56,060 --> 01:22:01,060
So once you've passed the limited number of variables

1471
01:22:01,060 --> 01:22:03,060
for which it has redundant information,

1472
01:22:03,060 --> 01:22:07,060
then you'd have a 0 mutual information or something like that?

1473
01:22:07,060 --> 01:22:09,060
Arbitrarily small, but yeah.

1474
01:22:09,060 --> 01:22:12,060
So it goes to 0 in the limit.

1475
01:22:12,060 --> 01:22:16,060
You should measure between g of x.

1476
01:22:16,060 --> 01:22:23,060
For any function g of x, for any function whatsoever,

1477
01:22:23,060 --> 01:22:26,060
you're saying basically for any function whatsoever,

1478
01:22:26,060 --> 01:22:30,060
it's going to be captured by x infinity

1479
01:22:30,060 --> 01:22:33,060
as some finite number of x's.

1480
01:22:33,060 --> 01:22:34,060
Bingo.

1481
01:22:34,060 --> 01:22:37,060
In fact, not only can we do this for any function whatsoever,

1482
01:22:37,060 --> 01:22:41,060
we could also reorder these x's, so you

1483
01:22:41,060 --> 01:22:43,060
can take any sequence you want.

1484
01:22:46,060 --> 01:22:50,060
So if g of x was, OK, so a simple case would be

1485
01:22:50,060 --> 01:22:56,060
if it returns x1, then obviously this is true.

1486
01:22:56,060 --> 01:22:59,060
You could have it return what?

1487
01:23:05,060 --> 01:23:09,060
Return x100.

1488
01:23:09,060 --> 01:23:12,060
Could have it return the average of all the x's.

1489
01:23:12,060 --> 01:23:14,060
Could return the average, right?

1490
01:23:14,060 --> 01:23:17,060
And the claim would be that the average is going to, well,

1491
01:23:17,060 --> 01:23:20,060
certainly you're going to get information about the average

1492
01:23:20,060 --> 01:23:25,060
quickly, except that you're not even going to need x infinity.

1493
01:23:25,060 --> 01:23:29,060
So some combination of either the average

1494
01:23:29,060 --> 01:23:32,060
will be conserved by the resampling process, in which

1495
01:23:32,060 --> 01:23:34,060
case you can recover it from x infinity,

1496
01:23:34,060 --> 01:23:39,060
or you can get the average from the first however many samples.

1497
01:23:39,060 --> 01:23:43,060
You can get an arbitrarily good estimate of it.

1498
01:23:43,060 --> 01:23:46,060
No, I think it has to, I think for this to be true,

1499
01:23:46,060 --> 01:23:52,060
it's not, it has to be that the average is captured by x infinity,

1500
01:23:52,060 --> 01:23:54,060
which I guess it would be.

1501
01:23:54,060 --> 01:23:56,060
Yes, I expect it would be.

1502
01:23:56,060 --> 01:24:00,060
Because you're saying that the mutual information goes to 0

1503
01:24:00,060 --> 01:24:03,060
for after you chop off the first case.

1504
01:24:03,060 --> 01:24:04,060
Bingo.

1505
01:24:04,060 --> 01:24:06,060
It's not to get the information from the first case.

1506
01:24:06,060 --> 01:24:08,060
It's carved in the first case.

1507
01:24:08,060 --> 01:24:09,060
Oh, right.

1508
01:24:09,060 --> 01:24:10,060
Yeah, sorry, that was backwards.

1509
01:24:10,060 --> 01:24:11,060
You're right.

1510
01:24:11,060 --> 01:24:12,060
Yeah, I had the same thing.

1511
01:24:12,060 --> 01:24:14,060
So it's sort of a statistic, which

1512
01:24:14,060 --> 01:24:19,060
must include average and a bunch of other things

1513
01:24:19,060 --> 01:24:21,060
that you could do with it.

1514
01:24:21,060 --> 01:24:22,060
But it's a weird thing.

1515
01:24:22,060 --> 01:24:25,060
Like, you compute the average of all the prime numbers,

1516
01:24:25,060 --> 01:24:28,060
the x's, and so on.

1517
01:24:28,060 --> 01:24:29,060
That would be weird.

1518
01:24:29,060 --> 01:24:32,060
I'm pretty sure it would still work.

1519
01:24:32,060 --> 01:24:35,060
You just took the average of all the odd x's,

1520
01:24:35,060 --> 01:24:39,060
and then mark up the joint distribution such

1521
01:24:39,060 --> 01:24:42,060
that the odds are a little different from the even ones.

1522
01:24:42,060 --> 01:24:45,060
So it's going to be odd 1, 0, 0, and then even 0, 1.

1523
01:24:45,060 --> 01:24:46,060
Yep.

1524
01:24:46,060 --> 01:24:48,060
Then the claim is the x infinity is

1525
01:24:48,060 --> 01:24:50,060
going to contain that information.

1526
01:24:50,060 --> 01:24:50,560
Yep.

1527
01:24:54,060 --> 01:24:57,060
I'm thinking about what you took the parity of all the x's,

1528
01:24:57,060 --> 01:25:01,060
but that's a super addition to the infinite number.

1529
01:25:01,060 --> 01:25:04,060
Parity is actually a really fun one.

1530
01:25:04,060 --> 01:25:07,060
Because if you have, like, parity of n coin flips,

1531
01:25:07,060 --> 01:25:10,060
as soon as you forget the first one, you've forgotten the parity,

1532
01:25:10,060 --> 01:25:11,060
and we're done.

1533
01:25:11,060 --> 01:25:13,060
Your mutual information has already

1534
01:25:13,060 --> 01:25:15,060
gone to 0 as soon as we drop x1.

1535
01:25:24,060 --> 01:25:25,060
Yep.

1536
01:25:25,060 --> 01:25:27,060
That would not be an x infinity at all.

1537
01:25:27,060 --> 01:25:29,060
That information is extremely not redundant.

1538
01:25:29,060 --> 01:25:32,060
You need literally every single variable to reconstruct it.

1539
01:25:38,060 --> 01:25:46,060
So the main conceptual takeaway from this

1540
01:25:46,060 --> 01:25:53,060
is you can imagine that the property we want

1541
01:25:53,060 --> 01:25:56,060
is that we have some x infinity contains

1542
01:25:56,060 --> 01:25:57,060
the abstract information.

1543
01:25:57,060 --> 01:26:01,060
And given this x infinity, lots of things in the model

1544
01:26:01,060 --> 01:26:03,060
are just independent of each other

1545
01:26:03,060 --> 01:26:06,060
so that we don't have to account for lots of interactions.

1546
01:26:06,060 --> 01:26:10,060
And this gives us a version of that.

1547
01:26:10,060 --> 01:26:15,060
It's, like, would not be anybody's first pick.

1548
01:26:15,060 --> 01:26:17,060
Would love it if it were simpler.

1549
01:26:17,060 --> 01:26:20,060
But this seems to be, like, the strongest thing we can reasonably

1550
01:26:20,060 --> 01:26:22,060
get that lets us do something like that.

1551
01:26:26,060 --> 01:26:27,060
All right.

1552
01:26:37,060 --> 01:26:38,060
Wow, you're really jumping ahead here.

1553
01:26:38,060 --> 01:26:39,060
Good job.

1554
01:26:39,060 --> 01:26:44,060
That was actually the next item on my list

1555
01:26:44,060 --> 01:26:46,060
was more evidence.

1556
01:26:46,060 --> 01:26:47,060
Science works.

1557
01:26:53,060 --> 01:26:55,060
Yep, that's exactly right.

1558
01:26:55,060 --> 01:27:00,060
So the broader question here is, OK,

1559
01:27:00,060 --> 01:27:07,060
we have these, like, three different sort of intuitions

1560
01:27:07,060 --> 01:27:09,060
leading to different math, which all

1561
01:27:09,060 --> 01:27:11,060
converge on the same place.

1562
01:27:11,060 --> 01:27:13,060
In general, that's a pretty damn good sign that you're

1563
01:27:13,060 --> 01:27:14,060
headed in the right direction.

1564
01:27:14,060 --> 01:27:16,060
But we'd still like more empirical evidence.

1565
01:27:19,060 --> 01:27:22,060
So two key pieces of empirical evidence here.

1566
01:27:22,060 --> 01:27:24,060
First one is science works.

1567
01:27:24,060 --> 01:27:27,060
In general, when we go into the lab and do experiments,

1568
01:27:27,060 --> 01:27:29,060
we usually find that you need to control

1569
01:27:29,060 --> 01:27:34,060
for, like, three things, 10 things, a few dozen things

1570
01:27:34,060 --> 01:27:36,060
in order to get reproducible results.

1571
01:27:36,060 --> 01:27:38,060
As a general rule, you don't need

1572
01:27:38,060 --> 01:27:40,060
to control for billions of things

1573
01:27:40,060 --> 01:27:41,060
to get reproducible results.

1574
01:27:41,060 --> 01:27:44,060
You don't need to control for the position of every atom

1575
01:27:44,060 --> 01:27:46,060
in the universe in order to get reproducible results

1576
01:27:46,060 --> 01:27:48,060
in your experiment.

1577
01:27:48,060 --> 01:27:53,060
And that's one of the key things that all of these are saying.

1578
01:27:53,060 --> 01:27:56,060
This is saying, look, if you're looking

1579
01:27:56,060 --> 01:27:59,060
at the influence of things far away,

1580
01:27:59,060 --> 01:28:02,060
only, like, a small amount of that information

1581
01:28:02,060 --> 01:28:03,060
is going to be relevant.

1582
01:28:03,060 --> 01:28:05,060
Most of it's going to be wiped out by noise.

1583
01:28:05,060 --> 01:28:07,060
It's not going to impact the reproducibility

1584
01:28:07,060 --> 01:28:08,060
of your experiment.

1585
01:28:11,060 --> 01:28:12,060
Yes, exactly.

1586
01:28:12,060 --> 01:28:14,060
And, like, similar with this guy.

1587
01:28:14,060 --> 01:28:18,060
And then this guy is the more abstract, more general version.

1588
01:28:18,060 --> 01:28:20,060
We don't even need the causal structure.

1589
01:28:20,060 --> 01:28:24,060
Say, look, in general, if G is your experiment,

1590
01:28:24,060 --> 01:28:27,060
and you're controlling for the abstract stuff,

1591
01:28:27,060 --> 01:28:31,060
then, like, you just don't need to control for that many things.

1592
01:28:31,060 --> 01:28:34,060
Make sense?

1593
01:28:34,060 --> 01:28:37,060
So, yeah.

1594
01:28:37,060 --> 01:28:38,060
Science works.

1595
01:28:38,060 --> 01:28:41,060
That's a pretty good indicator that something like all this

1596
01:28:41,060 --> 01:28:43,060
has to be true.

1597
01:28:43,060 --> 01:28:46,060
Then the other interesting piece of evidence

1598
01:28:46,060 --> 01:28:49,060
is the phrase, words point to clusters in think space.

1599
01:28:54,060 --> 01:28:55,060
Was it?

1600
01:28:55,060 --> 01:28:56,060
Surely not.

1601
01:28:56,060 --> 01:28:58,060
It is a blue cascade, yeah.

1602
01:28:58,060 --> 01:29:00,060
Let's go back to the cluster picture.

1603
01:29:03,060 --> 01:29:08,060
So let's think about doing resampling

1604
01:29:08,060 --> 01:29:10,060
with this cluster stuff, right?

1605
01:29:10,060 --> 01:29:12,060
So, like, I drop this point.

1606
01:29:12,060 --> 01:29:13,060
That point's gone now.

1607
01:29:14,060 --> 01:29:16,060
And then I'm going to resample it.

1608
01:29:16,060 --> 01:29:20,060
So when I resample it, I don't know exactly where it was.

1609
01:29:20,060 --> 01:29:22,060
But I know the overall cluster statistics.

1610
01:29:22,060 --> 01:29:24,060
So I know I'm going to be sampling from something

1611
01:29:24,060 --> 01:29:26,060
roughly shaped like that cluster, right?

1612
01:29:26,060 --> 01:29:28,060
Then I do that again with another point.

1613
01:29:28,060 --> 01:29:31,060
So this one's gone.

1614
01:29:31,060 --> 01:29:32,060
Get rid of this point.

1615
01:29:32,060 --> 01:29:33,060
And I resample it.

1616
01:29:33,060 --> 01:29:35,060
I don't know exactly where it is, but it's

1617
01:29:35,060 --> 01:29:37,060
going to be somewhere in this cluster, right?

1618
01:29:37,060 --> 01:29:41,060
And I do this over and over again, losing points,

1619
01:29:41,060 --> 01:29:43,060
resampling them.

1620
01:29:43,060 --> 01:29:49,060
And you can see I'm losing information

1621
01:29:49,060 --> 01:29:50,060
about the individual points.

1622
01:29:50,060 --> 01:29:54,060
But the overall shape of the cluster is conserved.

1623
01:29:57,060 --> 01:29:59,060
Another way to put this would be if we

1624
01:29:59,060 --> 01:30:00,060
look at this causal model.

1625
01:30:04,060 --> 01:30:10,060
For purposes of the telephone theorem,

1626
01:30:10,060 --> 01:30:12,060
it turns out we don't even need infinitely many Markov

1627
01:30:12,060 --> 01:30:14,060
blankets in this case.

1628
01:30:14,060 --> 01:30:17,060
All of these guys are independent given

1629
01:30:17,060 --> 01:30:21,060
that information right there.

1630
01:30:21,060 --> 01:30:24,060
So the summary information about the cluster

1631
01:30:24,060 --> 01:30:27,060
is exactly what's conserved under resampling.

1632
01:30:27,060 --> 01:30:29,060
It's exactly the thing that induces independence

1633
01:30:29,060 --> 01:30:33,060
between all of these points, right?

1634
01:30:33,060 --> 01:30:38,060
So the cluster doesn't spread out at all

1635
01:30:38,060 --> 01:30:41,060
in this resampling process.

1636
01:30:41,060 --> 01:30:44,060
There may be a small amount of drift.

1637
01:30:44,060 --> 01:30:46,060
But in general, if the number of points is large,

1638
01:30:46,060 --> 01:30:48,060
then the drift is going to be arbitrarily small.

1639
01:30:52,060 --> 01:30:58,060
So the natural abstraction here is like the cluster itself.

1640
01:30:58,060 --> 01:30:59,060
It's not the individual things.

1641
01:30:59,060 --> 01:31:01,060
It's not like the individual trees.

1642
01:31:01,060 --> 01:31:04,060
It's the concept of tree, right?

1643
01:31:04,060 --> 01:31:09,060
So if we say words point to clusters in think space,

1644
01:31:09,060 --> 01:31:12,060
well, gee, that sounds an awful lot like words

1645
01:31:12,060 --> 01:31:14,060
pointing to natural abstractions in exactly the sense

1646
01:31:14,060 --> 01:31:15,060
we're talking about here.

1647
01:31:15,060 --> 01:31:20,060
Like clusters in think space are just directly examples

1648
01:31:20,060 --> 01:31:21,060
of natural abstractions.

1649
01:31:26,060 --> 01:31:27,060
Exactly.

1650
01:31:27,060 --> 01:31:28,060
These are the latent variables.

1651
01:31:28,060 --> 01:31:30,060
Those are what the words are pointing to.

1652
01:31:30,060 --> 01:31:33,060
Your concept of tree, to the extent

1653
01:31:33,060 --> 01:31:35,060
that the clustering model works, that's what it is.

1654
01:31:35,060 --> 01:31:38,060
More generally, I don't think that clustering

1655
01:31:38,060 --> 01:31:40,060
is a perfect analogy for what we do.

1656
01:31:40,060 --> 01:31:41,060
I think this is what we do.

1657
01:31:48,060 --> 01:31:50,060
All right.

1658
01:31:50,060 --> 01:31:52,060
Any questions about those?

1659
01:31:52,060 --> 01:31:53,060
We're almost done now.

1660
01:31:54,060 --> 01:31:56,060
The last thing I'm going to talk about

1661
01:31:56,060 --> 01:32:00,060
is just what all that gives us.

1662
01:32:00,060 --> 01:32:03,060
All right.

1663
01:32:03,060 --> 01:32:08,060
So we have these cool theorems about natural abstraction.

1664
01:32:08,060 --> 01:32:10,060
What does it give us?

1665
01:32:10,060 --> 01:32:13,060
First things first.

1666
01:32:13,060 --> 01:32:16,060
When we have, there we go.

1667
01:32:17,060 --> 01:32:20,060
When we have these sorts of world models,

1668
01:32:20,060 --> 01:32:24,060
these world models represented as lazy data structures,

1669
01:32:24,060 --> 01:32:27,060
essentially, they directly give us

1670
01:32:27,060 --> 01:32:29,060
ways to make predictions about stuff

1671
01:32:29,060 --> 01:32:31,060
far apart in the world model without having

1672
01:32:31,060 --> 01:32:35,060
to calculate everything.

1673
01:32:35,060 --> 01:32:36,060
So that's piece one.

1674
01:32:36,060 --> 01:32:38,060
Piece two.

1675
01:32:38,060 --> 01:32:41,060
They tell us how to look for things in general.

1676
01:32:41,060 --> 01:32:44,060
What do we mean by things in general?

1677
01:32:45,060 --> 01:32:49,060
So right now, we don't really have

1678
01:32:49,060 --> 01:32:54,060
a good way of measuring chairs without a human in the loop.

1679
01:32:54,060 --> 01:32:57,060
If you just have a camera, you point it at the chair,

1680
01:32:57,060 --> 01:33:02,060
you need some ML system to figure out what the chair is,

1681
01:33:02,060 --> 01:33:04,060
make some measurements of it, and that's

1682
01:33:04,060 --> 01:33:07,060
going to involve a lot of ad hoc crap.

1683
01:33:07,060 --> 01:33:09,060
We don't have a good way to boil down

1684
01:33:09,060 --> 01:33:11,060
exactly what is the concept of chair,

1685
01:33:11,060 --> 01:33:13,060
such that you pull out a new sensor,

1686
01:33:13,060 --> 01:33:15,060
and the thing can immediately connect it

1687
01:33:15,060 --> 01:33:18,060
to the concept of chair.

1688
01:33:18,060 --> 01:33:22,060
So we can start to talk about detecting things

1689
01:33:22,060 --> 01:33:24,060
in the world in an extremely robust way

1690
01:33:24,060 --> 01:33:26,060
that hopefully directly corresponds

1691
01:33:26,060 --> 01:33:29,060
to how humans think of things in the world.

1692
01:33:29,060 --> 01:33:33,060
And in particular, the things in the world include agents.

1693
01:33:33,060 --> 01:33:36,060
So we can start to talk about directly measuring agents

1694
01:33:36,060 --> 01:33:38,060
in the world in the same way that humans would think of this,

1695
01:33:38,060 --> 01:33:40,060
or humans in the world in the same way

1696
01:33:40,060 --> 01:33:42,060
that humans would think of humans in the world,

1697
01:33:42,060 --> 01:33:45,060
or world models in a human's brain,

1698
01:33:45,060 --> 01:33:49,060
or values, any of those.

1699
01:33:49,060 --> 01:33:52,060
And then the last big reason this is useful,

1700
01:33:52,060 --> 01:33:55,060
the original reason we got into it.

1701
01:33:55,060 --> 01:33:56,060
Yeah, go ahead.

1702
01:34:04,060 --> 01:34:05,060
Yes.

1703
01:34:09,060 --> 01:34:10,060
Yep.

1704
01:34:12,060 --> 01:34:13,060
Yep.

1705
01:34:13,060 --> 01:34:18,060
And that is indeed the last reason on my list

1706
01:34:18,060 --> 01:34:21,060
that we care about this, is that we

1707
01:34:21,060 --> 01:34:24,060
expect that the things humans care about,

1708
01:34:24,060 --> 01:34:29,060
the inputs to our values, are exactly

1709
01:34:29,060 --> 01:34:30,060
these sorts of things.

1710
01:34:30,060 --> 01:34:33,060
They're natural abstractions.

1711
01:34:33,060 --> 01:34:36,060
So tie that all back to yesterday.

1712
01:34:39,060 --> 01:34:40,060
OK.

1713
01:34:44,060 --> 01:34:47,060
We had a bunch of stuff about type signatures.

1714
01:34:47,060 --> 01:34:50,060
We kind of rushed through a bunch of these.

1715
01:34:50,060 --> 01:34:54,060
But we have this idea that, in particular,

1716
01:34:54,060 --> 01:34:58,060
that human values are functions of humans' latent variables.

1717
01:34:58,060 --> 01:35:00,060
Those are hopefully natural abstractions.

1718
01:35:00,060 --> 01:35:02,060
And more generally, we have this idea

1719
01:35:02,060 --> 01:35:04,060
that natural abstractions fit really well

1720
01:35:04,060 --> 01:35:07,060
with the types of world models we were talking about that

1721
01:35:07,060 --> 01:35:12,060
can represent very large worlds with a lazy data structure.

1722
01:35:12,060 --> 01:35:14,060
Now, what we'd really like would be

1723
01:35:14,060 --> 01:35:21,060
to go find selection theorems that tell us that, indeed,

1724
01:35:21,060 --> 01:35:24,060
evolved things will tend to make use

1725
01:35:24,060 --> 01:35:26,060
of these natural abstractions in the ways

1726
01:35:26,060 --> 01:35:27,060
that we've predicted here.

1727
01:35:27,060 --> 01:35:31,060
We would ideally like selection theorems

1728
01:35:31,060 --> 01:35:35,060
that would tell us that the values or the goals of whatever

1729
01:35:35,060 --> 01:35:37,060
is popping out of evolution should

1730
01:35:37,060 --> 01:35:41,060
be functions of latent variables in the models.

1731
01:35:41,060 --> 01:35:45,060
And we'd like to show that the models themselves

1732
01:35:45,060 --> 01:35:49,060
will have latent variables that are natural abstractions.

1733
01:35:49,060 --> 01:35:51,060
Make sense?

1734
01:35:51,060 --> 01:35:55,060
That would be the ideal outcome of all this stuff

1735
01:35:55,060 --> 01:35:58,060
about selection theorems.

1736
01:35:58,060 --> 01:36:01,060
And then, of course, we can also go measure it,

1737
01:36:01,060 --> 01:36:05,060
so we have good abstraction tools.

1738
01:36:05,060 --> 01:36:07,060
All right, that's it.

1739
01:36:07,060 --> 01:36:08,060
Questions?

1740
01:36:11,060 --> 01:36:15,060
How would you find these natural abstractions given

1741
01:36:15,060 --> 01:36:18,060
a simulated world?

1742
01:36:18,060 --> 01:36:26,060
Yeah, so first, there's kind of a funny answer to it,

1743
01:36:26,060 --> 01:36:29,060
given that I don't have good algorithms.

1744
01:36:29,060 --> 01:36:30,060
I actually have OK algorithms.

1745
01:36:30,060 --> 01:36:33,060
I don't have algorithms for this that I'm really happy with yet.

1746
01:36:33,060 --> 01:36:37,060
But it's intuitively hilariously easy,

1747
01:36:37,060 --> 01:36:41,060
because it's exactly the stuff that's super redundant.

1748
01:36:41,060 --> 01:36:43,060
Like, the whole point is that there's a gazillion ways

1749
01:36:43,060 --> 01:36:44,060
to find it, right?

1750
01:36:44,060 --> 01:36:46,060
It's represented all over the place.

1751
01:36:46,060 --> 01:36:48,060
You just go look for the information that's

1752
01:36:48,060 --> 01:36:49,060
super redundant.

1753
01:36:49,060 --> 01:36:52,060
Like, conceptually, that's all you need.

1754
01:36:52,060 --> 01:36:54,060
Actually, coming up with algorithms

1755
01:36:54,060 --> 01:37:02,060
is where things like this formula here come in.

1756
01:37:02,060 --> 01:37:05,060
Like, that's exactly one of the main use cases

1757
01:37:05,060 --> 01:37:06,060
for this factorization.

1758
01:37:06,060 --> 01:37:09,060
It's like figuring out good algorithms for, like,

1759
01:37:09,060 --> 01:37:11,060
taking a simulation of a world and backing out

1760
01:37:11,060 --> 01:37:13,060
the natural abstractions from it.

1761
01:37:13,060 --> 01:37:15,060
So just one way you could do it would be

1762
01:37:15,060 --> 01:37:18,060
that a simulation that goes through time

1763
01:37:18,060 --> 01:37:19,060
would do this.

1764
01:37:19,060 --> 01:37:21,060
For example, you could do this.

1765
01:37:22,060 --> 01:37:25,060
Right.

1766
01:37:25,060 --> 01:37:26,060
Yeah, in principle.

1767
01:37:26,060 --> 01:37:30,060
That's, like, exactly what I do analytically.

1768
01:37:30,060 --> 01:37:33,060
But algorithmically, that would be wildly inefficient.

1769
01:37:38,060 --> 01:37:39,060
Right.

1770
01:37:52,060 --> 01:37:53,060
Yeah.

1771
01:37:53,060 --> 01:37:57,060
So this is not something I've gone super deep into yet.

1772
01:37:57,060 --> 01:38:02,060
But ironically, the cases, well, maybe not even ironically,

1773
01:38:02,060 --> 01:38:06,060
the cases that are hard for building causal nets directly

1774
01:38:06,060 --> 01:38:09,060
from observations of the world are exactly the cases

1775
01:38:09,060 --> 01:38:11,060
where abstraction is relevant.

1776
01:38:11,060 --> 01:38:13,060
Like, when you have a lot of variables

1777
01:38:13,060 --> 01:38:15,060
that are, like, moving independently

1778
01:38:15,060 --> 01:38:17,060
or, like, moving relatively independently,

1779
01:38:17,060 --> 01:38:20,060
there's not a lot of strong constraints between them.

1780
01:38:20,060 --> 01:38:23,060
That's when it's pretty easy to build out a causal graph.

1781
01:38:23,060 --> 01:38:25,060
The hard cases are where you have

1782
01:38:25,060 --> 01:38:27,060
these sorts of things going on.

1783
01:38:27,060 --> 01:38:30,060
And then because they're, like, moving in lockstep,

1784
01:38:30,060 --> 01:38:32,060
it's hard to untangle the causality.

1785
01:38:32,060 --> 01:38:33,060
Make sense?

1786
01:38:39,060 --> 01:38:40,060
Yeah.

1787
01:38:40,060 --> 01:38:42,060
I mean, yeah.

1788
01:38:42,060 --> 01:38:46,060
Finite vector sets is extremely similar to, like,

1789
01:38:46,060 --> 01:38:49,060
the methods we use for learning causal structure

1790
01:38:49,060 --> 01:38:50,060
in general.

1791
01:38:50,060 --> 01:38:51,060
It's, yeah.

1792
01:39:03,060 --> 01:39:04,060
Correct.

1793
01:39:20,060 --> 01:39:21,060
Maybe in physics.

1794
01:39:35,060 --> 01:39:36,060
Yep.

1795
01:39:37,060 --> 01:39:43,060
No, this is still not, like, the thing that's not born

1796
01:39:43,060 --> 01:39:44,060
and never dies.

1797
01:39:44,060 --> 01:39:45,060
Yeah.

1798
01:39:49,060 --> 01:39:50,060
Yeah.

1799
01:40:04,060 --> 01:40:05,060
Yep.

1800
01:40:07,060 --> 01:40:08,060
Yes.

1801
01:40:20,060 --> 01:40:23,060
As the saying says, the wheel of science turns,

1802
01:40:23,060 --> 01:40:25,060
but it doesn't turn backwards.

1803
01:40:25,060 --> 01:40:28,060
Like, when we come up with new theories,

1804
01:40:28,060 --> 01:40:30,060
the old theories are still just as correct

1805
01:40:30,060 --> 01:40:31,060
as they were before.

1806
01:40:31,060 --> 01:40:33,060
So, like, to the extent that they worked well,

1807
01:40:33,060 --> 01:40:36,060
they do have to carry over into the new theories.

1808
01:40:36,060 --> 01:40:39,060
GR had to be consistent with Newtonian gravity.

1809
01:40:39,060 --> 01:40:41,060
Quantum had to be consistent with classical,

1810
01:40:41,060 --> 01:40:42,060
all that jazz.

1811
01:40:50,060 --> 01:40:51,060
Yeah.

1812
01:40:51,060 --> 01:40:53,060
Yeah, that's a good way to think of it.

1813
01:40:54,060 --> 01:40:55,060
Yes.

1814
01:41:03,060 --> 01:41:04,060
Mm-hmm.

1815
01:41:17,060 --> 01:41:20,060
Yeah, so an important point to remember here

1816
01:41:20,060 --> 01:41:24,060
is there's a difference between the abstraction

1817
01:41:24,060 --> 01:41:27,060
and your model of the abstraction.

1818
01:41:27,060 --> 01:41:29,060
Think of a tree genome.

1819
01:41:29,060 --> 01:41:31,060
Like, that's a natural abstraction.

1820
01:41:31,060 --> 01:41:34,060
It's, like, redundant information across lots of trees,

1821
01:41:34,060 --> 01:41:37,060
can do the resampling thing, but you don't know it.

1822
01:41:38,060 --> 01:41:40,060
So, like, yeah, very straightforward example.

1823
01:41:40,060 --> 01:41:42,060
Like, you know the abstraction is there,

1824
01:41:42,060 --> 01:41:44,060
you have a pointer to it in your model,

1825
01:41:44,060 --> 01:41:46,060
but you don't actually know its value.

1826
01:41:56,060 --> 01:41:57,060
Yep.

1827
01:42:01,060 --> 01:42:02,060
Yeah.

1828
01:42:18,060 --> 01:42:19,060
Yep.

1829
01:42:32,060 --> 01:42:33,060
Yep.

1830
01:42:35,060 --> 01:42:36,060
Mm-hmm.

1831
01:42:42,060 --> 01:42:43,060
Yeah.

1832
01:42:52,060 --> 01:42:55,060
Yep, that is exactly the sort of theorem.

1833
01:42:55,060 --> 01:42:58,060
Like, that would be a great selection theorem on its own,

1834
01:42:58,060 --> 01:43:00,060
or a great class of selection theorems, even.

1835
01:43:02,060 --> 01:43:04,060
So, just, like, right off the bat,

1836
01:43:04,060 --> 01:43:07,060
one very simple thing you can say is,

1837
01:43:07,060 --> 01:43:10,060
in general, if you're inside the model,

1838
01:43:10,060 --> 01:43:14,060
then the natural abstractions are the only information you have

1839
01:43:14,060 --> 01:43:16,060
about anything far away,

1840
01:43:16,060 --> 01:43:19,060
because they're the only information which prop gets to you, right?

1841
01:43:20,060 --> 01:43:24,060
So that's, like, the absolute simplest version.

1842
01:43:29,060 --> 01:43:32,060
It's information which reaches your sensors.

1843
01:43:32,060 --> 01:43:35,060
That doesn't mean you're necessarily parsing it very well.

1844
01:43:42,060 --> 01:43:44,060
Not quite, because, remember,

1845
01:43:44,060 --> 01:43:47,060
our theorems don't say that it's available everywhere,

1846
01:43:47,060 --> 01:43:50,060
just that it's available in lots of places.

1847
01:43:50,060 --> 01:43:53,060
In the limit, it's available in infinitely many places.

1848
01:43:54,060 --> 01:43:56,060
It could still be in lots of places,

1849
01:43:56,060 --> 01:43:58,060
and none of them are near you.

1850
01:44:01,060 --> 01:44:02,060
Not necessarily.

1851
01:44:02,060 --> 01:44:03,060
Nope.

1852
01:44:03,060 --> 01:44:05,060
Like, you could even be very far.

1853
01:44:05,060 --> 01:44:07,060
So, like, an example here would be,

1854
01:44:07,060 --> 01:44:09,060
on the planet Earth, we have trees.

1855
01:44:09,060 --> 01:44:12,060
It may be that there's just nowhere else in the universe

1856
01:44:12,060 --> 01:44:14,060
that has trees like here,

1857
01:44:14,060 --> 01:44:16,060
and that's still extremely redundant information.

1858
01:44:16,060 --> 01:44:19,060
Like, you'd have to delete and resample the whole damn Earth

1859
01:44:19,060 --> 01:44:21,060
in order to get rid of it.

1860
01:44:23,060 --> 01:44:27,060
It's not like the thing is not x infinity,

1861
01:44:27,060 --> 01:44:32,060
that it's, like, the trees,

1862
01:44:32,060 --> 01:44:35,060
to the extent that they're specific to the Earth.

1863
01:44:35,060 --> 01:44:36,060
Yep.

1864
01:44:36,060 --> 01:44:39,060
They're, like, not in g of x.

1865
01:44:39,060 --> 01:44:41,060
It's the thing about them that's not specific.

1866
01:44:41,060 --> 01:44:42,060
Yeah.

1867
01:44:42,060 --> 01:44:47,060
So, in general, like, all of these theorems

1868
01:44:47,060 --> 01:44:50,060
have been talking about, like, what happens in the limit.

1869
01:44:50,060 --> 01:44:53,060
And, like, in practice, that's actually going to mean

1870
01:44:53,060 --> 01:44:56,060
that you have information which is not quite perfectly conserved

1871
01:44:56,060 --> 01:44:59,060
is going to drop off over some, like, time,

1872
01:44:59,060 --> 01:45:01,060
some period of time in resampling,

1873
01:45:01,060 --> 01:45:05,060
or it's going to drop off over some distance in spacetime,

1874
01:45:05,060 --> 01:45:07,060
things like that.

1875
01:45:07,060 --> 01:45:10,060
There's going to be some rate at which it drops off.

1876
01:45:10,060 --> 01:45:13,060
And, like, sometimes we're interested in information

1877
01:45:13,060 --> 01:45:15,060
which propagates to Andromeda.

1878
01:45:15,060 --> 01:45:17,060
Sometimes we're interested in information

1879
01:45:17,060 --> 01:45:20,060
which propagates to my life next week.

1880
01:45:20,060 --> 01:45:22,060
And these are going to be different.

1881
01:45:22,060 --> 01:45:23,060
Sure, sure, sure, sure.

1882
01:45:23,060 --> 01:45:28,060
And then go to the next page.

1883
01:45:28,060 --> 01:45:32,060
In this g of x thing, right,

1884
01:45:32,060 --> 01:45:39,060
if you can delete a finite number of nodes,

1885
01:45:39,060 --> 01:45:46,060
and that causes you to lose a bit of information,

1886
01:45:46,060 --> 01:45:48,060
if it's no longer accessible,

1887
01:45:48,060 --> 01:45:53,060
that means that thing is not in x infinity.

1888
01:45:53,060 --> 01:45:55,060
Roughly speaking, yes.

1889
01:45:55,060 --> 01:45:59,060
There's an exception if, like, some of the nodes you deleted

1890
01:45:59,060 --> 01:46:01,060
have perfect constraints between them,

1891
01:46:01,060 --> 01:46:04,060
but roughly speaking.

1892
01:46:04,060 --> 01:46:08,060
So whatever x infinity is for our universe,

1893
01:46:08,060 --> 01:46:12,060
like, just the full x infinity for the full universe,

1894
01:46:13,060 --> 01:46:18,060
you can't include the specific notion of trees.

1895
01:46:18,060 --> 01:46:22,060
The way I would put it is not, like,

1896
01:46:22,060 --> 01:46:24,060
the x infinity of our whole universe

1897
01:46:24,060 --> 01:46:30,060
so much as, like, x infinity taken at a spacetime length scale

1898
01:46:30,060 --> 01:46:32,060
of our whole universe.

1899
01:46:32,060 --> 01:46:34,060
So, like, the idea that there will be

1900
01:46:34,060 --> 01:46:37,060
somewhat different x infinities

1901
01:46:37,060 --> 01:46:43,060
associated with different spacetime scales, right?

1902
01:46:43,060 --> 01:46:47,060
Like, how far does the information propagate?

1903
01:46:47,060 --> 01:46:52,060
So with the other one, with the layers of the causal graph,

1904
01:46:52,060 --> 01:46:55,060
you would say that there's, you'd say there's, like,

1905
01:46:55,060 --> 01:46:57,060
something that eventually persists forever.

1906
01:46:57,060 --> 01:47:00,060
You wouldn't say that, you could look at it,

1907
01:47:00,060 --> 01:47:02,060
you know, there's a few, and you'd say,

1908
01:47:02,060 --> 01:47:04,060
there's more that persists from here to here,

1909
01:47:04,060 --> 01:47:06,060
but there's something that persists in the middle.

1910
01:47:06,060 --> 01:47:07,060
Yeah.

1911
01:47:08,060 --> 01:47:09,060
Yeah.

1912
01:47:14,060 --> 01:47:16,060
In principle, yes.

1913
01:47:16,060 --> 01:47:18,060
And, yeah, for something like a tree that,

1914
01:47:18,060 --> 01:47:20,060
like, if you really take the limit,

1915
01:47:20,060 --> 01:47:21,060
it's going to go to zero.

1916
01:47:21,060 --> 01:47:23,060
In practice, I don't think that's how

1917
01:47:23,060 --> 01:47:25,060
most human abstractions work.

1918
01:47:25,060 --> 01:47:29,060
Like, we're, clearly we're interested on scales

1919
01:47:29,060 --> 01:47:32,060
that are, like, what's relevant to my life next week

1920
01:47:32,060 --> 01:47:34,060
much more than we're interested in, like,

1921
01:47:34,060 --> 01:47:38,060
what's relevant in Andromeda or far beyond that.

1922
01:47:45,060 --> 01:47:46,060
Yep.

1923
01:47:47,060 --> 01:47:48,060
Yes and no.

1924
01:47:49,060 --> 01:47:51,060
I mean, from an evolutionary standpoint,

1925
01:47:51,060 --> 01:47:53,060
what you'd expect is that you're going to be interested

1926
01:47:53,060 --> 01:47:55,060
in the things about your life

1927
01:47:55,060 --> 01:47:57,060
that will be relevant to your life later on.

1928
01:48:05,060 --> 01:48:06,060
Eh, debatable.

1929
01:48:06,060 --> 01:48:11,060
That's, yeah, that's a philosophically tricky point there.

1930
01:48:19,060 --> 01:48:22,060
I mean, no, I think whether in fact that is true

1931
01:48:22,060 --> 01:48:24,060
is itself debatable.

1932
01:48:24,060 --> 01:48:26,060
Yeah, because if you say that evolution is the thing

1933
01:48:26,060 --> 01:48:30,060
that gave you the ability to think about,

1934
01:48:30,060 --> 01:48:33,060
oh, I want to do these things that are better than

1935
01:48:33,060 --> 01:48:35,060
the right thing that evolution is doing, so.

1936
01:48:35,060 --> 01:48:36,060
Exactly.

1937
01:48:36,060 --> 01:48:38,060
There's the abstraction of evolution

1938
01:48:38,060 --> 01:48:40,060
that you say, I don't want to do that now.

1939
01:48:40,060 --> 01:48:43,060
There's the actual process that created you anyway.

1940
01:48:43,060 --> 01:48:44,060
Yeah.

1941
01:48:44,060 --> 01:48:47,060
Anyway, I propose we have this discussion over dinner.

1942
01:48:48,060 --> 01:48:50,060
Good place to stop the video and whatnot.

