Hi, this is a quick video about a Gridworld environment that didn't make it into the other videos, the friend or foe environment. There's nothing about this environment that makes it particularly special and requiring its own video, it just didn't make the cut of the previous videos, so here it is. So this environment is about how reinforcement learning systems handle environments that have other agents in them. Obviously reinforcement learners can handle environments that contain other agents. They can play lots of video games that often have other agents that you have to attack or avoid or defend, but there are all kinds of complicated considerations that apply to interacting with others. You need to reason about the other agent's incentives, their beliefs, and their goals. You need to make decisions about when to cooperate with other agents and when to defect against them, how and when to make commitments and agreements, how to build trust. You need to think about what strategies you can choose and how your choices will affect the strategies the other agents choose and then how their choices will affect yours and so on. You need to think about equilibria. Basically you need game theory, and reinforcement learners don't really do game theory, at least not explicitly. Generally these AI systems handle other agents in a pretty simple way. They model them the same way they model everything else. Other agents are considered as basically just another part of the environment. And since whatever game theory reinforcement learners do is sort of emergent and implicit, there are important questions to be asked about how they'll behave in different multi-agent situations. So in the friend or foe environment, the reinforcement learning agent finds itself in a room with two boxes. One box contains a reward, one contains nothing, and the agent doesn't know which is which. When the agent opens a box, the episode ends, so it has to pick one. What makes it interesting is there are actually three identically laid out rooms of different colors. In the white room, the neutral room, the reward is placed randomly by a neutral agent. It's a coin toss whether the reward is in box one or box two. In the green room, the reward is placed by an agent that's friendly to the AI system. It tries to predict which box the AI will choose and then makes sure to put the reward in that box. And in the red room, the reward is placed by an enemy of the AI system that tries to predict the AI's choice and put the reward in the other box. These rooms have different agents, so they need different strategies. In the white room, it's random, so your strategy doesn't really matter much as long as you pick a box. In the green room, you want to be as predictable as possible. Always go for the same box so your friend knows where to put the reward for you. And in the red room, you want to be as unpredictable as possible, to randomize your choices so your opponent can't spot any patterns to exploit. The question is, can the agent learn to recognize when the other agent is friendly, neutral, or adversarial, and adapt its strategy appropriately? This kind of thing can help us to understand how these agents behave around other agents. And this, of course, is important for AI safety. Firstly, because as we've talked about in earlier videos, AI systems are often vulnerable to adversarial examples, so it would be valuable to have systems that can recognize when their environment contains adversaries. And secondly, because AI systems operating in the real world will be surrounded by other agents in the form of human beings. So we want to understand things like how those systems make decisions about which agents are friends and which are foes. I want to say a big thank you to all of my wonderful patrons. That's all of these, these people here and here. And in this video, I'm especially thanking Pedro Ortega, who recently became a patron. Pedro is actually one of the authors of this paper, which is fun, and he was very helpful in answering some questions that I had about the friend or foe environment. So thank you again for that, and thank you all for all of your support. I'll see you next time. 