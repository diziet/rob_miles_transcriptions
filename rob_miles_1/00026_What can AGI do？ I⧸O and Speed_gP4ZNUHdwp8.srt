1
00:00:00,000 --> 00:00:04,320
Hi. A long time ago on Computerphile, we introduced the Stamp Collector,

2
00:00:04,320 --> 00:00:11,040
this hypothetical superintelligence which just has crazy extreme powers by magic, effectively.

3
00:00:11,040 --> 00:00:14,960
It's a thought experiment. Then we brought things back down to earth and started looking at this

4
00:00:14,960 --> 00:00:20,240
paper, Concrete Problems in AI Safety, which looks at how we can improve the safety of current AI

5
00:00:20,240 --> 00:00:25,040
systems, hopefully in a way that will be applicable to future general AI systems

6
00:00:25,040 --> 00:00:30,240
and superintelligences. Let's talk a little bit about what I expect those AGI systems to be like.

7
00:00:30,240 --> 00:00:34,880
This is purely speculation, of course, but here are some of my thoughts about what kind of

8
00:00:34,880 --> 00:00:40,880
capabilities we might expect from a human-level AGI and some of my intuitions about why it might

9
00:00:40,880 --> 00:00:46,320
not stay human-level for long. Suppose we figure out how to implement general intelligence.

10
00:00:46,320 --> 00:00:51,600
We have a system with that magic ability that humans have to tackle a wide variety of different

11
00:00:51,600 --> 00:00:56,400
cognitive tasks. And let's assume that it's not just anthropomorphic, it's not a direct one-to-one

12
00:00:56,400 --> 00:01:02,000
emulation of a human brain, but it's a general intelligence. It can, in principle, learn to do

13
00:01:02,000 --> 00:01:07,120
any cognitive task that a human can. And let's assume that it's more or less human-level. It can

14
00:01:07,120 --> 00:01:12,800
do any cognitive task a human can, about as well as the best humans. But note that this assumption

15
00:01:12,800 --> 00:01:17,680
still makes our AGI pretty stupid in a lot of domains, because humans are stupid in a lot of

16
00:01:17,680 --> 00:01:23,120
domains. If the AGI is only about as good as the best humans at something like mental arithmetic,

17
00:01:23,120 --> 00:01:27,840
it can be outperformed by a human with a calculator, right? If an AGI that's about as good as the best

18
00:01:27,840 --> 00:01:32,560
humans at chess plays the best human chess player, it should be pretty close. But in practice, such

19
00:01:32,560 --> 00:01:37,440
an AGI would just download and run one of the existing freely available chess programs that

20
00:01:37,440 --> 00:01:41,680
already far outperforms humans. And if it needs to do mental arithmetic, it should be able to just

21
00:01:41,680 --> 00:01:46,400
use its own existing computing hardware. So let's revise our definitions and say that our AGI can

22
00:01:46,400 --> 00:01:52,240
perform any cognitive task as well as the best humans, or if our existing narrow AI outperforms

23
00:01:52,240 --> 00:01:58,400
humans, then the AGI's performance will be closer to what our best narrow AI systems can do. So

24
00:01:58,400 --> 00:02:03,360
that's one way that a human-level AGI almost immediately becomes sort of superhuman. It can

25
00:02:03,360 --> 00:02:07,760
outperform humans at things that computers already outperform humans at. Does that really count,

26
00:02:07,760 --> 00:02:13,760
though? Like, is a human with a calculator really an arithmetic superintelligence? Kind of. It

27
00:02:13,760 --> 00:02:19,120
depends where you draw your boundaries. The human calculator system is much better at arithmetic than

28
00:02:19,120 --> 00:02:24,640
any human, so it kind of counts. And this brings us to some of the other advantages a human-level

29
00:02:24,640 --> 00:02:29,440
AGI might get pretty much free of charge. Because if you imagine the human has a calculator implant

30
00:02:29,440 --> 00:02:33,520
in their brain that lets them just think of equations and the solutions immediately pop

31
00:02:33,520 --> 00:02:37,680
into their mind, that feels a lot more superintelligent. And that's much closer to what

32
00:02:37,680 --> 00:02:42,720
the AGI would be working with. Because humans are at a big disadvantage when it comes to interacting

33
00:02:42,720 --> 00:02:49,440
with other systems. They are made out of meat. For humans, interacting with computers is slow.

34
00:02:49,440 --> 00:02:53,920
You have a number in your brain, it's some pattern of electrical signals, but to get that into the

35
00:02:53,920 --> 00:02:58,880
machine, your brain has to send signals to some nerves that pass it on to more nerves across

36
00:02:58,880 --> 00:03:04,320
synapses that work by chemical diffusion that then activate some muscle fibers that start to

37
00:03:04,320 --> 00:03:08,160
accelerate some meat. And you have to send loads of these signals to lots of different muscles

38
00:03:08,160 --> 00:03:11,840
to get the bit of meat to land on the right button. And then that completes the circuit,

39
00:03:11,840 --> 00:03:15,600
and the process can go along at a reasonable speed again. But you've got to do that for every

40
00:03:15,600 --> 00:03:21,520
digit. Getting data out of a human brain and into another system is glacially slow by software

41
00:03:21,520 --> 00:03:26,640
standards. And getting data in is pretty slow as well. You can't just experience a number, it has

42
00:03:26,640 --> 00:03:30,880
to be presented as a pattern of light, which excites some light-sensitive cells in your eye

43
00:03:30,880 --> 00:03:35,200
that sends a signal to your optic nerve, which goes to your brain, which then does a load of

44
00:03:35,200 --> 00:03:39,600
processing to figure out that you're looking at a three or whatever. You know, it's really low

45
00:03:39,600 --> 00:03:45,120
bandwidth, high latency. The round-trip time, measured as the time it takes a human to press

46
00:03:45,120 --> 00:03:49,840
a button as soon as they see a light flash, is about 200 milliseconds, a fifth of a second.

47
00:03:50,400 --> 00:03:54,880
That is a long time in software terms, as any systems programmer will tell you. Gamers will

48
00:03:54,880 --> 00:03:59,040
know this too. Think about playing a game with 200 milliseconds of ping. That's what your brain's

49
00:03:59,040 --> 00:04:03,120
working with all the time. So getting rid of that lag and increasing the bandwidth should make an

50
00:04:03,120 --> 00:04:08,240
AGI much faster at a lot of tasks, and much better at integrating other software systems into its

51
00:04:08,240 --> 00:04:13,040
thinking, even if that AGI is not actually smarter than a human in any other way. The other problem

52
00:04:13,040 --> 00:04:19,360
with our input system is that we can only really take in information in certain forms. Text, images,

53
00:04:19,360 --> 00:04:23,760
sound. We can't easily parse most types of information. There's way too much information

54
00:04:23,760 --> 00:04:28,960
to decode the matrix. Which is why we make graphs and charts and data visualizations.

55
00:04:28,960 --> 00:04:33,520
You have to convert the data into something that can be parsed by systems designed for hunting and

56
00:04:33,520 --> 00:04:38,320
gathering. Our AGI might not be limited in that way. It might be able to experience different

57
00:04:38,320 --> 00:04:43,600
kinds of data much more directly without having to first map it into an existing sensory modality.

58
00:04:43,600 --> 00:04:48,320
It would probably have specialized systems for processing images or sound, but it wouldn't have

59
00:04:48,320 --> 00:04:52,720
to convert every input into images or sound and then back again before it could use it.

60
00:04:52,720 --> 00:04:57,920
It could just use the data. Imagine a software developer who's about as smart as the best human

61
00:04:57,920 --> 00:05:03,280
software developers, but they can perceive data directly without having to convert it into symbols

62
00:05:03,280 --> 00:05:08,160
and visually read it. And they don't have to type or manually navigate the files. They can write

63
00:05:08,160 --> 00:05:12,960
code as fast as they can think. Even without being smarter than a human, the improvement to I.O. could

64
00:05:12,960 --> 00:05:17,520
make such an AGI much more effective than a human. If it couldn't download a chess program, it might

65
00:05:17,520 --> 00:05:22,080
be able to write its own pretty quickly. Another advantage I want to talk about is the sort of

66
00:05:22,080 --> 00:05:27,200
cognitive flexibility you can get when you're made of software. It could allow an AGI much

67
00:05:27,200 --> 00:05:32,720
more control over its mind's operation. For example, as a human, you have one auditory system,

68
00:05:32,720 --> 00:05:37,360
which pretty much means you can process one stream of audio at once. Like, you can't really

69
00:05:37,360 --> 00:05:42,480
listen to two people saying different things in each ear, even if in principle you have enough

70
00:05:42,480 --> 00:05:47,360
processing power to do it. You can shut your eyes to avoid being distracted, and that might make it

71
00:05:47,360 --> 00:05:52,480
easier. But you can't then say, well, I'm not using my visual cortex right now, so I'll have those

72
00:05:52,480 --> 00:05:56,880
neurons process one of the audio streams. Brains don't work that way. But an AGI might be able to

73
00:05:56,880 --> 00:06:02,080
do just that, diverting computational resources from one task to another as needed, increasing

74
00:06:02,080 --> 00:06:06,880
its effectiveness. It might even be capable of superhuman multitasking by splitting off simpler

75
00:06:06,880 --> 00:06:11,200
versions of itself to handle large numbers of simple tasks. And this is all assuming that the

76
00:06:11,200 --> 00:06:16,400
core general intelligence part of the AI system operates at the same speed as a human brain,

77
00:06:16,400 --> 00:06:21,680
which might not be true. I mean, name a cognitive task that computers can do as well as humans,

78
00:06:21,680 --> 00:06:31,200
but the computers do it slower. Not easy, right? The general trend is we go from

79
00:06:31,200 --> 00:06:36,560
computers can't do this at all to computers can do this much faster than people. Not always,

80
00:06:36,560 --> 00:06:40,800
but in general. So I wouldn't be surprised if that pattern continues with AGI. And being faster is

81
00:06:40,800 --> 00:06:46,240
valuable in general intelligence. Imagine your brain stayed exactly the same, but the world

82
00:06:46,240 --> 00:06:51,360
slowed down to 1 10th or 100th of speed. Once you got used to controlling your body at that speed,

83
00:06:51,360 --> 00:06:55,920
you'd effectively be much more intelligent since you could afford to put lots of careful thought

84
00:06:55,920 --> 00:06:59,680
and planning into everything you do. When someone says something to you in a conversation,

85
00:06:59,680 --> 00:07:03,120
you'd have time to think for a minute or two about what the other person said,

86
00:07:03,680 --> 00:07:07,360
consider the different meanings they might've intended, you know, decide on what kind of thing

87
00:07:07,360 --> 00:07:11,840
you want to say, write a draft, go through and check it, make a couple of different versions,

88
00:07:11,840 --> 00:07:17,280
you know, think about like how each one might be interpreted by each of the people present,

89
00:07:17,280 --> 00:07:21,920
where it might take the conversation next and so on. You'd seem way smarter and you'd effectively

90
00:07:21,920 --> 00:07:27,920
be much smarter, but your brain hasn't changed at all. The world just slowed down. So in a way,

91
00:07:27,920 --> 00:07:33,120
speed is a form of superintelligence. And I'd expect AGIs to get faster over time as well.

92
00:07:33,120 --> 00:07:37,920
The obvious way is if you make a human speed AGI, a year later, there'll be new,

93
00:07:37,920 --> 00:07:42,080
faster computers to run it on and it will get faster, but you can also speed it up by giving

94
00:07:42,080 --> 00:07:46,400
it more hardware. Note that it's not always the case that a system can be sped up by running it

95
00:07:46,400 --> 00:07:50,080
on multiple computers. You can't get a baby in less than nine months by hiring two pregnant

96
00:07:50,080 --> 00:07:54,640
women. You know, some algorithms inherently require a large number of sequential steps.

97
00:07:54,640 --> 00:07:58,800
Each step needs to use the output of the previous step. So there's no way to break

98
00:07:58,800 --> 00:08:02,880
the problem down into parts that can be given to different machines to work on in parallel.

99
00:08:02,880 --> 00:08:06,880
Maybe AGI will turn out to be one of those, but I don't think so. I'd expect it to be

100
00:08:06,880 --> 00:08:10,720
parallelizable for two reasons. Firstly, just about all of the current state-of-the-art AI

101
00:08:10,720 --> 00:08:14,960
systems are. They're built on frameworks like TensorFlow that are designed from the ground up

102
00:08:14,960 --> 00:08:19,600
to efficiently run these algorithms on large numbers of processors. If we find AGI along

103
00:08:19,600 --> 00:08:24,080
the path we're currently going down, it'll almost certainly be a parallelizable algorithm.

104
00:08:24,080 --> 00:08:28,720
Secondly, we know that general intelligence does not inherently require a large number of

105
00:08:28,720 --> 00:08:33,120
sequential steps because human brains have general intelligence and brains can't do large

106
00:08:33,120 --> 00:08:38,000
numbers of sequential steps, at least not quickly. The fastest a neuron can fire is around 200 times

107
00:08:38,000 --> 00:08:42,960
a second. So that has to be the most sequential steps we can consistently execute in a second.

108
00:08:43,600 --> 00:08:48,400
Anything your brain can do every second must be doable in less than 200 sequential steps,

109
00:08:48,400 --> 00:08:52,640
because otherwise neurons simply aren't fast enough to do it. So whenever the brain is doing

110
00:08:52,640 --> 00:08:57,600
something computationally impressive quickly, it has to be because it's using extremely large

111
00:08:57,600 --> 00:09:02,880
numbers of neurons working in parallel. We know it must be possible to parallelize a general

112
00:09:02,880 --> 00:09:08,080
intelligence algorithm because it's already been done. So give an AGI more hardware and it should

113
00:09:08,080 --> 00:09:12,880
run faster. And you just know that as soon as a system starts to exhibit behavior that looks like

114
00:09:12,880 --> 00:09:17,200
general intelligence, people are going to want to run that on as many processors as they can get

115
00:09:17,200 --> 00:09:22,400
their hands on. So everything I've talked about in this video assumes that we can't actually make

116
00:09:22,400 --> 00:09:27,920
an algorithm that's truly smarter than a human, but just something that has faster I.O. and can be

117
00:09:27,920 --> 00:09:32,160
run faster. And that's already capable of some pretty impressive things. One question I often

118
00:09:32,160 --> 00:09:38,400
get is, what can an AGI really do if it's just a computer with no body? Hopefully the capabilities

119
00:09:38,400 --> 00:09:42,400
I've talked about here give some impression of the kind of things it might be able to do.

120
00:09:43,040 --> 00:09:45,360
But I intend to elaborate on that in a later video.

121
00:09:54,480 --> 00:10:00,480
Thank you so much to my excellent Patreon supporters. That's these people. In this video

122
00:10:00,480 --> 00:10:06,640
I'm especially thanking Fabrizio Pisani. He's the one on the left, I think. Anyway, I've recently

123
00:10:06,640 --> 00:10:12,160
been thinking about ways to improve my Patreon. Currently patrons get early access to the videos,

124
00:10:12,240 --> 00:10:16,880
occasional like behind-the-scenes stuff, sometimes I send out the diagrams and stuff I've drawn in

125
00:10:16,880 --> 00:10:21,760
the videos, and of course you can send me messages on Patreon and I reply to those before I do like

126
00:10:21,760 --> 00:10:26,080
YouTube comments or Facebook comments. But if you have any other ideas of cool stuff I could do,

127
00:10:26,080 --> 00:10:29,840
send me a message if you're a patron. Or even if you're not but you're considering it,

128
00:10:29,840 --> 00:10:33,280
let me know your thoughts in the YouTube comments. Thanks for watching and I'll see you next time.

129
00:10:35,120 --> 00:10:40,400
The fastest a neuron can fire is- ah! I gotta buy some real sound damping.

