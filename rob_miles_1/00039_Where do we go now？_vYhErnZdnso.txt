Okay, so let's get right to it. Most of you are probably here because you've seen my videos on the Computerphile channel, but on the off chance that you haven't, or you haven't seen them all, or you don't remember them all, I mean the first one was like four years ago, I thought the first video should go through the existing stuff, get everybody up to speed, and also talk about the various directions that this channel could go next. So while we're going through the videos so far, be thinking about what kind of things you're interested in, and what kind of things you would want to see more of, and leave me comments so I can decide what to do next. Also, everyone should be subscribed to Computerphile if you're interested in this kind of thing. Firstly because it's a great channel, and secondly because I plan to continue making videos there in addition to these ones. Okay, so the first two videos I made were about sort of machine learning basics, just concepts like optimization, and the idea that we can think of intelligence as optimization, we can think of intelligent systems as systems which optimize a particular function over a particular space. The second video is just explaining what's meant by a space in this context. People who are familiar with machine learning stuff will know this, but if not, check it out. I could make more machine learning basics videos going through the fundamentals of how some of the algorithms work and some of the sort of core concepts of the field, although I feel as though those are probably fairly well covered elsewhere, like on Computerphile. But if people are interested in seeing more of that kind of content from me, let me know. Okay, then the third video, the holy grail of AI, is where the ideas and the hair start to get really interesting. It's where we start talking about the difference between the type of AI that we have now, and the type of science fiction AI that we think of, sort of human level true AI. And we talk about the concept of generality, the idea of having a single optimizing system, which is able to operate in a wide variety of different domains, rather than these narrow domain specific intelligences that we have now. From there, we go on to the deadly truth of AI, where I start to talk about super intelligence, and the way that a very powerful intelligence can be very dangerous, even giving a fairly innocuous seeming goal, like collecting stamps. There are all kinds of areas we could go into from that video. For example, we know that just saying collect as many stamps as you can is a very bad function to give this type of agent. But what type of function might actually work? What might be safe? We could also look at containment. If you have an agent like the stamp collector, is there any safe way to run it without being completely confident that you've chosen the right objective function for it? So the next video is AI self-improvement, which is about the possibility that an artificial intelligence could improve its own code. That really only touched on the on the surface of that. There's a lot we can talk about there in terms of how likely this is, how possible this is, what the timescales might be for it happening, all kinds of questions there to look into if people are interested. So then we have the Asimov's laws don't work video, which, you know, I feel like I was too unkind to Asimov in this video. I came across a bit too dismissive, but I stand by the content of the thing. Asimov's laws don't work as a solution to this problem, never really did, and were never really meant to. The field has moved on and they're not really relevant anymore, so I don't really, I don't want to make more videos about that. The next relevant video was the one titled AI safety, which was sort of a response to Dr Holden's video, Dr Holden at Cambridge, who has another video on Computerphile, which you also should definitely watch. That video touches on a few different subjects. I think the one that has the most potential to be built on is the question of predicting future technology and the various problems associated with that, so if you want to see more about the difficulties in predicting AI, we can make more stuff about that. Right, the next video was called AI's game playing challenge, which is mostly about Go. We made that video because at that time DeepMind's system, AlphaGo, had just beaten the world champion, and that video is about the general way that AI go about solving these kinds of perfect information board games and why Go is so difficult and why it was such a huge challenge and such a huge achievement for DeepMind. There was originally going to be a follow-up video to that one about how it actually works in some detail, which we never got around to shooting, and there is a pretty good one on Computerphile as well, but I can talk more about that if people want more insight into how AlphaGo works. And the last two, General AI won't want you to fix it, and the stop button problem kind of go together. They're about one of the more concrete problems people are working on right now in AI safety, which is just if you have a system, a general intelligence that you've given an objective to, how do you design it in such a way that it will accept being shut down and modified? Because by default, general intelligences are incentivized to prevent themselves from being modified, from having their utility functions modified specifically. We could go into more detail on that. Some of the other approaches people have proposed maybe go slightly more technical than the Computerphile videos. I also made some videos unrelated to artificial intelligence, like the first one I made was actually about public key cryptography. If you'd like an intuitive understanding of how public key cryptography works, how it allows you to communicate privately with people without first agreeing on a shared secret to use as a key, check that video out. I can do more crypto stuff if people are interested, but I think that that's fairly well served elsewhere on YouTube, but let me know in the comments. There was also the Code Golf video where I explained the concept of the game of Code Golf, and I gave a very short program I wrote that made music which looks like this. I can't remember how many characters it is, 240 something I think? Anyway, it looks like this and sounds like the background music. It's been the background music the whole time. I never really fully explained how that code works in detail. If you want a video on that, let me know. Another thing I'm thinking of doing is taking a current research paper and just going through it bit by bit so that over a series of videos you get hopefully as full an understanding of it as you would from reading the whole paper. There are a couple of candidates. The foremost I think is Concrete Problems in AI Safety, which is often recommended as a good introductory paper, so if people would like to see that, leave a comment. I could do stuff about the work I did as a PhD student about artificial immune systems, which is only tangentially related but I think it's really interesting, or completely unrelated stuff. I once made a robot that deliberately blinds people with a laser. I'm currently working on a game that you play using only your eyebrows. I made this battle axe, which is also an electric ukulele. Uh, maybe I should make a side channel for this stuff. Anyway, where do we go now? Let me know what you think in the comments. 