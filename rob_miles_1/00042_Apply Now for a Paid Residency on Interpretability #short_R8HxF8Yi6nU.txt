Modern language models can write poems, explain jokes, and convince people that they're sentient. But we have almost no idea how they work. Like, what are they doing internally? If that bothers you, you might want to apply to Remix, a neural network interpretability residency run by Redwood Research. If accepted, you'll build on recent progress in interpretability research to reverse-engineer the mechanisms that models use to generate language. This is a small and new field, so it's very possible that you could uncover something important and surprising. The paid research program takes place in Berkeley, California in December or January, depending on your availability. If you're interested, look up Redwood Research Remix and apply right now, because the deadline is November 13th. 