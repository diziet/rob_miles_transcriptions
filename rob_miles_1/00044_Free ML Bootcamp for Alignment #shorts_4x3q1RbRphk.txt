Hey, you know how nobody really understands how to ensure the AI systems we build are safe and aligned with human values? Are you someone who maybe would like to try to work on that problem, but you don't know enough about machine learning? Well, an AI safety organization called Redwood Research is running a machine learning boot camp specifically for people interested in AI alignment It's called MLab and it's an all expenses paid in-person boot camp in Berkeley, California between August the 15th and September the 2nd They're looking for people to participate and also for potential teaching assistance And they're open to students or people who are already working I might actually be there myself if the timing works out And last time they ran this boot camp Redwood Research ended up hiring several of the participants So it might actually be a way into a career in AI safety If you're interested look up Redwood MLab 2 and apply now because the deadline is this Friday, May 27th 