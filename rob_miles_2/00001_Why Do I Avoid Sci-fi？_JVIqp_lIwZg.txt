There's a kind of frustrating conversation I sometimes find myself having where someone will say to me, you're always talking about how if we have artificial intelligence systems with very powerful general purpose capabilities, but their goals aren't well aligned with ours, that could go very badly. And you always leave this very vague. My question is specifically what would happen, right? It's just a piece of software on a computer. I have a very hard time imagining how something like that could actually be dangerous. Like what could it actually do? You never talk about specifically what the AI would do. And it's true. I do tend to leave that aspect fairly open. And that's deliberate. It's for a couple of reasons. First is any specific story I can tell you about how an AI system could do a lot of damage is going to sound like science fiction. In fact, it's going to be a specific story about technology that doesn't currently exist. So it's going to be science fiction by definition. And this causes a lot of people to dismiss what you're saying. Unfortunately, the actual thing that ends up happening with future technology is also going to sound like science fiction. So we're in this unfortunate situation where in order to tell whether something's actually going to happen, you have to do something cleverer than identify its literary genre. But since not everyone is there, I try to avoid specific scenarios. The second reason is even if you have someone who accepts that the future is going to seem like science fiction, if you give a specific example, they will tend to quibble with the specifics of that example. They'll say, oh, but I don't think that an AI system could actually do that. Or perhaps they'll accept that an AI system could do it, but then they'll be thinking of like things that we could do as humans that might counteract that. And this is all kind of beside the point. It's like imagine you find yourself talking to an amateur chess player who's discovered an opening that they're very proud of, that they've been able to use very successfully against all of their other amateur chess player friends. And they say, okay, great. This is it. I'm going to bet my life savings that I can beat Magnus Carlsen. And you would want to say to them, I don't think this is a good idea. I'm pretty sure you're going to lose. And they might reply, well, what's Magnus Carlsen going to do? This opening is really good. I can't think of any move that he could make whereby he could beat me. And it's very difficult to respond to that because I'm not a chess player. I don't know what move Magnus Carlsen is going to make, but I do know he's going to beat you. And it's kind of natural to be suspicious when I'm just telling you that you'll lose and I'm not able to name any specific course of action by which that might happen. But that is the situation we find ourselves in. If you really press me, I might give some move or some strategy that maybe Carlsen could make that might beat you. But it's very plausible that either you would find a way to get around that strategy or you would doubt that Carlsen would actually be able to carry it out because I've specified it too vaguely. I haven't given the specific moves. You can imagine how this could be a pretty frustrating conversation where we're arguing back and forth about possible moves and possible counter moves. And we could do that all day. It doesn't get at the actual point, which is that you just cannot expect to win against a superior opponent. Thankfully, this whole situation is not inevitable because we get to build the AI system. The challenge is in building an AI system that isn't playing against us. It's much more difficult than it sounds, but by no means impossible. And that's the task of AI alignment research. 