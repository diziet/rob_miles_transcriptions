1
00:00:00,000 --> 00:00:02,000
Que la lumiÃ¨re soit...

2
00:00:03,360 --> 00:00:05,360
C'est de l'or.

3
00:00:07,800 --> 00:00:14,640
Okay, hi everyone. This is going to be a really quick video. A Computerphile video just came out about language models and

4
00:00:14,960 --> 00:00:16,960
GPT-2 and stuff like that and

5
00:00:17,600 --> 00:00:21,480
people were asking about actually running the model and what that looks like and

6
00:00:22,000 --> 00:00:27,840
that was something that we had planned to do in the recording session for Computerphile, but we didn't get around to so

7
00:00:28,520 --> 00:00:31,680
that's what this video is. And I thought a fun thing to do would be to

8
00:00:32,360 --> 00:00:34,360
generate some fake YouTube comments

9
00:00:34,760 --> 00:00:37,560
like Mike did. So that's what we're gonna do.

10
00:00:37,560 --> 00:00:42,520
This I think is gonna be a video for my second channel because it's just a quick random little project.

11
00:00:42,680 --> 00:00:46,660
If you're interested in this kind of thing, random machine learning stuff and different projects,

12
00:00:46,880 --> 00:00:48,880
then do subscribe to this channel.

13
00:00:48,920 --> 00:00:53,560
Otherwise, if you're interested in my main like AI safety stuff, then you want to subscribe to my main channel.

14
00:00:53,560 --> 00:00:55,120
I'll put a link in the description to that.

15
00:00:55,120 --> 00:00:59,920
So, how are we gonna do it? Well, we've got the code. It's just on github.

16
00:01:00,080 --> 00:01:04,540
You can get it and then we downloaded the 345 million parameter model.

17
00:01:05,320 --> 00:01:07,820
This I've slightly modified the

18
00:01:08,680 --> 00:01:09,760
generate

19
00:01:09,760 --> 00:01:16,880
interactive samples file just so that instead of looping it just takes the raw tokens that you can specify it here.

20
00:01:16,880 --> 00:01:19,360
It just makes it slightly easier to specify a whole bunch of text.

21
00:01:19,440 --> 00:01:25,140
So now we need to give it something that will tell GPT-2 that what we want it to generate is

22
00:01:25,960 --> 00:01:32,760
YouTube comments. So basically we have to give it some YouTube comments. So let's just do that. Here's the video.

23
00:01:33,200 --> 00:01:35,200
We can come in here

24
00:01:35,560 --> 00:01:37,840
and just pull out the comments.

25
00:01:41,600 --> 00:01:43,600
Let's actually

26
00:01:44,000 --> 00:01:46,720
zoom in a bit to make this easier for everybody to read.

27
00:01:47,720 --> 00:01:54,080
Giant. So what we can do is first off, we've got to get rid of all of these and then we're going to do

28
00:01:55,800 --> 00:01:59,840
a go with the dollar sign, find all of those and

29
00:02:01,640 --> 00:02:03,600
then

30
00:02:03,600 --> 00:02:05,600
there.

31
00:02:06,520 --> 00:02:08,840
So here I'm just putting a symbol at the beginning.

32
00:02:10,560 --> 00:02:12,560
Something like that.

33
00:02:12,920 --> 00:02:17,200
This is one of those things where you could think that the thing to do would be to write a script

34
00:02:19,000 --> 00:02:22,520
or talk to the YouTube API or something like that.

35
00:02:23,840 --> 00:02:27,120
But by the time you're done doing that

36
00:02:28,520 --> 00:02:30,520
you can have just done it manually.

37
00:02:30,760 --> 00:02:33,280
There we are. We're done. Took a couple of minutes.

38
00:02:34,320 --> 00:02:38,760
So this is our sample text. So we've taken up taken away anything

39
00:02:39,400 --> 00:02:44,280
extraneous and we put this specific string here that lets it know this is a new comment each time.

40
00:02:44,280 --> 00:02:46,640
Oh, right. And then at the end we need to say

41
00:02:49,480 --> 00:02:53,160
now it's your turn, right? Generate from that.

42
00:02:54,680 --> 00:02:57,360
So let's give that to the model here.

43
00:03:02,240 --> 00:03:07,640
Now it's your turn. GPT-2, you generate some stuff. We're going to generate 150 tokens

44
00:03:08,400 --> 00:03:16,520
for samples. Let's have 10 samples using the 345 million parameter model and let's go.

45
00:03:17,080 --> 00:03:20,520
One minute seven seconds later. Ah, here we are.

46
00:03:22,200 --> 00:03:24,200
So sample one.

47
00:03:24,480 --> 00:03:30,800
What a wonderful one sentence speech that sums up the rest of the paper at over five minutes and five seconds long to be precise.

48
00:03:32,520 --> 00:03:37,520
Like that's a plausible comment. That could be a comment. This one is all question marks.

49
00:03:37,760 --> 00:03:40,640
This person is very, very confused by the video.

50
00:03:41,840 --> 00:03:45,960
Transformers, transforming a human face. This will be a video after this one.

51
00:03:47,680 --> 00:03:50,840
Are we going to have a video about how to use transformers on human faces?

52
00:03:51,680 --> 00:03:55,400
Could do. Here's a link to a PDF on the archive.

53
00:03:56,080 --> 00:04:03,680
Probably not a valid link. I know, but what of transforming a human face? Because no, stop trying to transform human faces.

54
00:04:03,680 --> 00:04:05,200
You're scaring me.

55
00:04:05,200 --> 00:04:10,240
Okay, here's a new comment. If you would like to use any of the models, the source of the scripts or how to implement these

56
00:04:10,240 --> 00:04:15,840
models, please contact me at usg.dave.mccormackstudios.co.uk. I'll help you with all the code

57
00:04:15,840 --> 00:04:19,040
you'll need for a proper application and we will send you access to the models.

58
00:04:20,480 --> 00:04:22,880
I mean like that could be a real comment.

59
00:04:24,040 --> 00:04:28,440
Why would I use it? I already did some work using it on some other parts.

60
00:04:30,640 --> 00:04:34,600
Doesn't quite work. We're about to start. Can you please get on the phone with Michael Scott?

61
00:04:36,200 --> 00:04:44,200
New sample. It's pretty amazing what this guy got up to. He really needs a better set of headphones as he had problems with the sound quality.

62
00:04:46,200 --> 00:04:52,800
So this is fun. This token is the special end of text token, which has been specially defined.

63
00:04:53,800 --> 00:04:59,080
So that means that here it now thinks that it's hit the end of the document and it's like starting a new document.

64
00:05:00,080 --> 00:05:06,080
A bill to allow concealed carrier firearms into schools has earned heavy criticism from some local groups and a Republican presidential candidate.

65
00:05:07,080 --> 00:05:11,080
Opponents of the Senate version of the bill say it would prohibit schools from providing guns to students.

66
00:05:14,080 --> 00:05:19,080
That sounds like a good bill. I don't want to get political, but I don't think schools should be providing guns to students.

67
00:05:20,080 --> 00:05:26,080
Yeah, so basically once it hits here, I've asked it to generate 150 tokens and it's run out of stuff to say.

68
00:05:27,080 --> 00:05:31,080
So it's now just starting afresh, completely unprimed and just generating some text in English.

69
00:05:32,080 --> 00:05:35,080
And it's apparently an article about a bill about guns.

70
00:05:36,080 --> 00:05:41,080
Here's a new YouTube comment. For most people in our age group, they cannot read or pronounce human.

71
00:05:41,080 --> 00:05:49,080
Is there some sort of AI that allows humans such as you to learn from human speech and give the correct answer without the need for words or a computer to do it for you?

72
00:05:50,080 --> 00:05:54,080
I'm really looking forward to reading more on the topic. I really like your research.

73
00:05:55,080 --> 00:06:03,080
Thanks. Are we really going to learn to think this way without a computer? The Internet has changed so drastically.

74
00:06:04,080 --> 00:06:07,080
It has. I'm fascinated by all of this and this video.

75
00:06:07,080 --> 00:06:15,080
I'm fascinated by all of this and this video. Are you working on AI models that are not based in an artificial environment and have the ability to learn the human language?

76
00:06:18,080 --> 00:06:22,080
I mean, like that. That's a legit comment.

77
00:06:23,080 --> 00:06:28,080
I am very tired about the computer files who are complaining about me being boring.

78
00:06:29,080 --> 00:06:33,080
A model of human cognition based on deep neural network with the following properties.

79
00:06:34,080 --> 00:06:39,080
It requires too much time. Think two hours for each argument. It doesn't need two hours. It was a while to sit there, but.

80
00:06:40,080 --> 00:06:43,080
Oh, God, I'm arguing with a machine. What is happening?

81
00:06:45,080 --> 00:06:47,080
This is more like a carnivorous matrix.

82
00:06:48,080 --> 00:06:52,080
I just looked over these two examples and I'm a bit of a carnivorous matrix freak.

83
00:06:53,080 --> 00:06:54,080
OK.

84
00:06:55,080 --> 00:06:59,080
I'm sure there are lots of people in the comments who are really fond of the attention and logic are two different things.

85
00:07:00,080 --> 00:07:02,080
What matters are the probabilities bit.

86
00:07:03,080 --> 00:07:04,080
I mean, that is.

87
00:07:05,080 --> 00:07:07,080
I never said that. That does sound like something I would say.

88
00:07:08,080 --> 00:07:09,080
Attention and logic are two different things.

89
00:07:10,080 --> 00:07:13,080
I find this stuff interesting. Have you read some of the comments on these papers?

90
00:07:14,080 --> 00:07:15,080
I am very interested.

91
00:07:15,080 --> 00:07:17,080
That's a standard computer file comment.

92
00:07:18,080 --> 00:07:23,080
This paper is very hard to summarize, but in general, the results that are presented are generally very interesting.

93
00:07:25,080 --> 00:07:30,080
Thank you. The question that is so annoying is why is so many people talking about this stuff on TV?

94
00:07:32,080 --> 00:07:36,080
It's YouTube, man. You don't have to watch. You can watch a different YouTube channel.

95
00:07:37,080 --> 00:07:42,080
Well, it's very sad to see because there are so many people talking about this stuff on TV.

96
00:07:43,080 --> 00:07:47,080
Well, it's very sad to see because I thought all people would care about being involved with computers,

97
00:07:48,080 --> 00:07:51,080
being able to do real tasks like typing out a speech or writing a new piece of text.

98
00:07:52,080 --> 00:07:57,080
It's such a strange topic that there's always an argument about the relative utility of computers versus humans.

99
00:07:58,080 --> 00:08:03,080
In any case, why do all these people think you have to be super stupid just to type up this thing?

100
00:08:04,080 --> 00:08:08,080
I have no doubt it would be fun to work out how it makes sense to get as accurate a reading as possible,

101
00:08:09,080 --> 00:08:12,080
given how the human brain compilates the information.

102
00:08:16,080 --> 00:08:19,080
I don't remember why you would want to use such a very clever model.

103
00:08:23,080 --> 00:08:24,080
Tough it.

104
00:08:25,080 --> 00:08:26,080
All right.

105
00:08:28,080 --> 00:08:29,080
My cat's got opinions.

106
00:08:30,080 --> 00:08:33,080
My cat's got opinions. Do you want to be involved, Tough?

107
00:08:35,080 --> 00:08:36,080
No.

108
00:08:41,080 --> 00:08:44,080
A proud parent here. My son knows his way around the house.

109
00:08:46,080 --> 00:08:50,080
This model is an interesting one. The first two ideas seem somewhat familiar, but we want to know the fir...

110
00:08:51,080 --> 00:08:52,080
Tough it.

111
00:08:53,080 --> 00:08:54,080
I'm filming.

112
00:08:55,080 --> 00:08:56,080
Fine.

113
00:08:56,080 --> 00:09:01,080
This model is an interesting one. The first two ideas seem somewhat familiar, but we want to know the first one or the second word.

114
00:09:02,080 --> 00:09:03,080
Sounds not so clever.

115
00:09:04,080 --> 00:09:07,080
This is a problem because it involves the concept of the attention is all you need,

116
00:09:08,080 --> 00:09:12,080
but the first sentence would look very complicated and strange to anyone who doesn't know a few words from a few books.

117
00:09:13,080 --> 00:09:15,080
I wonder if the algorithm had its origin in computer games.

118
00:09:16,080 --> 00:09:21,080
So the first few words are very simple and don't give you much to work with, and so on and so on.

119
00:09:22,080 --> 00:09:24,080
It doesn't make sense, but it...

120
00:09:25,080 --> 00:09:28,080
Not all comments make sense, so it's accurate.

121
00:09:30,080 --> 00:09:32,080
It's not a transhumanist project at all.

122
00:09:33,080 --> 00:09:36,080
Is this a documentary on the technology behind my robot friend?

123
00:09:37,080 --> 00:09:41,080
It does not mean. Don't ask me to be a producer or anything. There's nothing to add to this.

124
00:09:43,080 --> 00:09:46,080
I feel my brain is in a box, just like your brain in my box.

125
00:09:47,080 --> 00:09:49,080
I'm not a researcher. Sorry for asking.

126
00:09:50,080 --> 00:09:53,080
How many times do we need to say to you that you are funny?

127
00:09:55,080 --> 00:09:59,080
Rob, do you have a robot friend, please? I mean, I've had that comment before.

128
00:10:02,080 --> 00:10:09,080
Yeah, so that was GPT-2 generated YouTube comments on the most recent beautiful video with me in it.

129
00:10:11,080 --> 00:10:12,080
I hope you enjoyed it.

130
00:10:12,080 --> 00:10:18,080
Subscribe to this channel if you want more of this kind of thing, or to my main channel if you want actual AI safety content.

131
00:10:19,080 --> 00:10:20,080
Alright, thanks, bye.

132
00:10:42,080 --> 00:10:49,080
I guess I'm making a video in a huge hurry because the computerphile video just came out and I want to publish something at the same time, which is what happened this time.

133
00:10:50,080 --> 00:10:54,080
But I want to say again, thank you all so much for all of your support. It means a lot to me.

